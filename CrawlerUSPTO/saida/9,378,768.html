<html><head>
<base target="_top"/>
<title>United States Patent: 9378768</title></head>
<!---BUF1=9378768
BUF7=2016
BUF8=29950
BUF9=/1/
BUF51=9
---->
<body bgcolor="#FFFFFF">
<a name="top"></a>
<center>
<img alt="[US Patent &amp; Trademark Office, Patent Full Text and Image Database]" src="/netaicon/PTO/patfthdr.gif"/>
<br/>
<table>
<tbody><tr><td align="center">
<a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
<a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
<a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
</td></tr>
<tr><td align="center">
   <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=182&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=3&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=182&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=4&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=182&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=5&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=181&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=4&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=183&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=4&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

<a href="#bottom"><img alt="[Bottom]" border="0" src="/netaicon/PTO/bottom.gif" valign="middle"/></a>
</td></tr>
   <tr><td align="center">
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D182%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D4%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209378768"><img alt="[
View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9378768&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D182%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D4%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209378768">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09378768&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D182%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D4%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>

   </td></tr>
</tbody></table>
</center>
<table width="100%">
<tbody><tr><td align="left" width="50%"> </td>
<td align="right" valign="bottom" width="50%"><font size="-1">( <strong>182</strong></font> <font size="-2">of</font> <strong><font size="-1">7895</font></strong> <font size="-1">)</font></td></tr></tbody></table>
<hr/>
   <table width="100%">
   <tbody><tr>	<td align="left" width="50%"><b>United States Patent </b></td>
   <td align="right" width="50%"><b>9,378,768</b></td>
   </tr>
     <tr><td align="left" width="50%"><b>
         Wu
,   et al.</b>
     </td>
     <td align="right" width="50%"> <b>
     June 28, 2016
</b></td>
     </tr>
     </tbody></table>
       <hr/>
       <font size="+1">Methods and systems for media file management
</font><br/>
       <br/><center><b>Abstract</b></center>
       <p> Methods and systems for media file management are provided. A music file
     is provided. The music file is analyzed to obtain a frequency spectrum
     corresponding to the music file, and at least one beat point on the time
     line is detected for the music file based on the frequency spectrum.
     Media data is generated for a plurality of media files in the electronic
     device based on the music file and a theme defining effects or
     transitions between the media files, wherein the sequence of the
     respective effects or transitions, and the corresponding media files
     which are selected for the respective effects or transitions are
     determined according to the at least one beat point of the music file.
</p>
       <hr/>
<table width="100%"> <tbody><tr> <th align="left" scope="row" valign="top" width="10%">Inventors:</th> <td align="left" width="90%">
 <b>Wu; Jing-Lung</b> (Taoyuan, <b>TW</b>)<b>, Chueh; Hsin-Ti</b> (Taoyuan, <b>TW</b>)<b>, Wu; Jenn-Wein</b> (Taoyuan, <b>TW</b>)<b>, Lee; Lo-Chien</b> (Taoyuan, <b>TW</b>)<b>, Chen; Wen-Yuan</b> (Taoyuan, <b>TW</b>) </td> </tr>
<tr><th align="left" scope="row" valign="top" width="10%">Applicant: </th><td align="left" width="90%"> <table> <tbody><tr> <th align="center" scope="column">Name</th> <th align="center" scope="column">City</th> <th align="center" scope="column">State</th> <th align="center" scope="column">Country</th> <th align="center" scope="column">Type</th> </tr> <tr> <td> <b><br/>HTC Corporation</b> </td><td> <br/>Taoyuan, Taoyuan County </td><td align="center"> <br/>N/A </td><td align="center"> <br/>TW </td> <td align="left"> </td> </tr> </tbody></table>
<!-- AANM>
~AANM HTC Corporation
~AACI Taoyuan, Taoyuan County
~AAST N/A
~AACO TW
</AANM -->
</td></tr>
<tr> <th align="left" scope="row" valign="top" width="10%">Assignee:</th>
<td align="left" width="90%">

<b>HTC CORPORATION</b>
 (Taoyuan, 
<b>TW</b>)
<br/>

</td>
</tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Family ID:
       </th><td align="left" width="90%">
       <b>1000001938170
</b></td></tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Appl. No.:
       </th><td align="left" width="90%">
       <b>14/050,591</b></td></tr>
       <tr><th align="left" scope="row" valign="top" width="10%">Filed:
       </th><td align="left" width="90%">
       <b>October 10, 2013</b></td></tr>
     </tbody></table>
<hr/> <center><b>Prior Publication Data</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Document Identifier</u></b></th><th align="center" scope="col"><b><u>Publication Date</u></b></th></tr><tr><td align="center"> </td><td align="center"> US 20140364982 A1</td><td align="center">Dec 11, 2014</td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table>
<hr/> <center><b>Related U.S. Patent Documents</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col" width="7%"></th><th scope="col"></th><th scope="col"></th> <th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Application Number</u></b></th><th align="center" scope="col"><b><u>Filing Date</u></b></th><th align="center" scope="col"><b><u>Patent Number</u></b></th><th align="center" scope="col"><b><u>Issue Date</u></b></th></tr><tr><td align="center"> </td><td align="center">61833018</td><td align="center">Jun 10, 2013</td><td align="center"></td><td align="center"></td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table><td< td=""></td<><td< td=""></td<>     <hr/>
<p> <table width="100%"> <tbody><tr><td align="left" valign="top" width="30%"><b>Current U.S. Class:</b></td> <td align="right" valign="top" width="70%"><b>1/1</b> </td></tr> 
       <tr><td align="left" valign="top" width="30%"><b>Current CPC Class: </b></td>
       <td align="right" valign="top" width="70%">G11B 27/038 (20130101); G06F 17/30026 (20130101); G06F 17/30778 (20130101)</td></tr>
         <tr><td align="left" valign="top" width="30%"><b>Current International Class: </b></td>
         <td align="right" valign="top" width="70%">G06F 17/00 (20060101); G06F 17/30 (20060101); G11B 27/038 (20060101)</td></tr>
     </tbody></table>
</p><hr/><center><b>References Cited  <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2Fsearch-adv.htm&amp;r=0&amp;f=S&amp;l=50&amp;d=PALL&amp;Query=ref/9378768">[Referenced By]</a></b></center>       <hr/>
       <center><b>U.S. Patent Documents</b></center>
<table width="100%"> <tbody><tr><th scope="col" width="33%"></th> <th scope="col" width="33%"></th> <th scope="col" width="34%"></th></tr> <tr> <td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7518053">7518053</a></td><td align="left">
April 2009</td><td align="left">
Jochelson et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030205124&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0205124</a></td><td align="left">
November 2003</td><td align="left">
Foote et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070261537&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0261537</a></td><td align="left">
November 2007</td><td align="left">
Eronen et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080249644&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0249644</a></td><td align="left">
October 2008</td><td align="left">
Jehan</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090049979&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0049979</a></td><td align="left">
February 2009</td><td align="left">
Naik et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090249945&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0249945</a></td><td align="left">
October 2009</td><td align="left">
Yamashita et al.</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
       <i>Primary Examiner:</i> Flanders; Andrew C
<br/>
       <i>Attorney, Agent or Firm:</i> <coma>Birch, Stewart, Kolasch &amp; Birch, LLP
<br/>
       <hr/>
       <center><b><i>Parent Case Text</i></b></center>
       <hr/>
       <br/><br/>CROSS REFERENCE TO RELATED APPLICATIONS
<br/><br/> This application claims the benefit of U.S. Provisional Application No.
     61/833,018 filed Jun. 10, 2013, the entirety of which is incorporated by
     reference herein.
         <hr/>
<center><b><i>Claims</i></b></center> <hr/> <br/><br/>What is claimed is: <br/><br/> 1.  A method for media file management for use in an electronic device, comprising: providing a music file;  analyzing the music file to obtain a frequency spectrum
corresponding to the music file;  detecting at least one beat point on the time line for the music file based on the frequency spectrum;  and generating media data, which is played for a plurality of media files in the electronic device based on the
music file and a theme defining effects or transitions between the media files, wherein a sequence of the respective effects or transitions, and the corresponding media files, which are used for producing the media data and selected for the respective
effects or transitions, are determined according to the at least one beat point of the music file.
<br/><br/> 2.  The method of claim 1, further comprising analyzing the media files to obtain the theme for the media files.
<br/><br/> 3.  The method of claim 2, wherein the step of analyzing the media files is performed by detecting faces in the respective media files, checking position information corresponding to the respective media files, checking exposure time of the
respective media files, or checking taken time or date, or sharpness of the respective media files.
<br/><br/> 4.  The method of claim 1, further comprising generating the media data according to a script file corresponding to the music file, wherein the script file defines characteristics which are defined according to tempos, melody, beats, cord, or
chorus of the music file.
<br/><br/> 5.  The method of claim 1, wherein the media files comprises images, videos, music, or texts.
<br/><br/> 6.  A system for media file management for use in an electronic device, comprising: a storage unit comprising a plurality of media files, and a music file;  and a processing unit analyzing the music file to obtain a frequency spectrum
corresponding to the music file, detecting at least one beat point on the time line for the music file based on the frequency spectrum, and generating media data, which is played for the media files based on the music file and a theme defining effects or
transitions between the media files, wherein a sequence of the respective effects or transitions, and the corresponding media files, which are used for producing the media data and selected for the respective effects or transitions, are determined
according to the at least one beat point of the music file.
<br/><br/> 7.  The system of claim 6, wherein the processing unit further analyzes the media files to obtain the theme for the media files.
<br/><br/> 8.  The system of claim 7, wherein the processing unit analyzes the media files by detecting faces in the respective media files, checking position information corresponding to the respective media files, checking exposure time of the respective
media files, or checking taken time or date, or sharpness of the respective media files.
<br/><br/> 9.  The system of claim 6, wherein the processing unit generates the media data further according to a script file corresponding to the music file, wherein the script file defines characteristics which are defined according to tempos, melody,
beats, cord, or chorus of the music file.
<br/><br/> 10.  The system of claim 6, wherein the media files comprises images, videos, music, or texts.
<br/><br/> 11.  A non-transitory machine-readable storage medium comprising a computer program, which, when executed, causes a device to perform a method for media file management, wherein the method comprises: providing a music file;  analyzing the music
file to obtain a frequency spectrum corresponding to the music file;  detecting at least one beat point on the time line for the music file based on the frequency spectrum;  and generating media data, which is played for a plurality of media files in the
electronic device based on the music file and a theme defining effects or transitions between the media files, wherein a sequence of the respective effects or transitions, and the corresponding media files, which are used for producing the media data and
selected for the respective effects or transitions, are determined according to the at least one beat point of the music file. <hr/> <center><b><i>Description</i></b></center> <hr/> <br/><br/>BACKGROUND OF THE INVENTION
<br/><br/> 1.  Field of the Invention
<br/><br/> The disclosure relates generally to methods and systems for media file management, and, more particularly to methods and systems for music analysis, and generating and/or presenting media data for a group of media files with effect management
based on the analysis result.
<br/><br/> 2.  Description of the Related Art
<br/><br/> Recently, portable devices, such as handheld devices, have become more and more technically advanced and multifunctional.  For example, a handheld device may have telecommunications capabilities, e-mail message capabilities, an advanced address
book management system, a media playback system, and various other functions.  Due to increased convenience and functions of the devices, these devices have become necessities of life.
<br/><br/> Currently, a handheld device may provide image capturing (picture-taking) capabilities operating like a digital camera, and picture takers can use the image capturing (picture-taking) capabilities of the device to take images and/or videos.  Due
to the convenient function, taking pictures with handheld device has become a very common behavior.
<br/><br/> Generally, the files of images and/or videos are classified into folders which are managed by a file management system of the device.  Conventionally, users can distinguish between the folders according to the folder names.  In some cases, it is
difficult to locate a specific folder when a large amount of folders are in the device.  Currently, a thumbnail corresponding to one or few images in a folder can be shown on the icon corresponding to the folder, thereby helping users to distinguish
between the folders.  However, the thumbnail corresponding to one or few images cannot show the complete picture of the folder.  It is still hard to locate a specific folder when a large amount of folders are in the device.
<br/><br/>BRIEF SUMMARY OF THE INVENTION
<br/><br/> Methods and systems for media file management are provided.
<br/><br/> In an embodiment of a method for media file management, a music file is provided.  The music file is analyzed to obtain a frequency spectrum corresponding to the music file, and at least one beat point on the time line is detected for the music
file based on the frequency spectrum.  Then, media data is generated for a plurality of media files in the electronic device based on the music file and a theme defining effects or transitions between the media files, wherein the sequence of the
respective effects or transitions, and the corresponding media files which are selected for the respective effects or transitions are determined according to the at least one beat point of the music file.
<br/><br/> An embodiment of a system for media data management comprises a storage unit and a processing unit.  The storage unit comprises a plurality of media files, and a music file.  The processing unit analyzes the music file to obtain a frequency
spectrum corresponding to the music file, and detects at least one beat point on the time line for the music file based on the frequency spectrum.  The processing unit generates media data for the media files based on the music file and a theme defining
effects or transitions between the media files, wherein the sequence of the respective effects or transitions, and the corresponding media files which are selected for the respective effects or transitions are determined according to the at least one
beat point of the music file.
<br/><br/> In some embodiments, the media files are analyzed to obtain the theme for the media files.  In some embodiments, the step of analyzing the media files is performed by detecting faces in the respective media files, checking position information
corresponding to the respective media files, checking exposure time of the respective media files, or checking taken time or date, or sharpness of the respective media files.
<br/><br/> In some embodiments, the media data is generated further according to a script file corresponding to the music file, wherein the script file defines characteristics which are defined according to tempos, melody, beats, cord, or chorus of the
music file.
<br/><br/> Methods for media file management may take the form of a program code embodied in a tangible media.  When the program code is loaded into and executed by a machine, the machine becomes an apparatus for practicing the disclosed method.
<br/><br/>BRIEF DESCRIPTION OF THE DRAWINGS
<br/><br/> The invention will become more fully understood by referring to the following detailed description with reference to the accompanying drawings, wherein:
<br/><br/> FIG. 1 is a schematic diagram illustrating an embodiment of a system for media file management of the invention;
<br/><br/> FIG. 2 is a flowchart of an embodiment of a method for media file management of the invention;
<br/><br/> FIG. 3 is a flowchart of an embodiment of a method for generating media data of the invention; and
<br/><br/> FIGS. 4-6 are flowcharts of further embodiments of the method for generating media data of the invention.
<br/><br/>DETAILED DESCRIPTION OF THE INVENTION
<br/><br/> Methods and systems for media file management are provided.
<br/><br/> FIG. 1 is a schematic diagram illustrating an embodiment of a system for media file management of the invention.  The system for media file management 100 can be used in an electronic device, such as a computer, or a portable device, such as a
digital camera, a handheld device such as a mobile phone, a smart phone, a PDA (Personal Digital Assistant), a GPS (Global Positioning System), or any picture-taking device.
<br/><br/> The system for media file management 100 comprises a storage unit 110 and a processing unit 120.  The storage unit 110 comprises a plurality of media files 111, such as images, videos, music, and/or texts.  In some embodiments, the texts may be
from comments corresponding to the respective media file, such as image or video from at least one social network.  It is understood that, in some embodiments, the system for media file management 100 can also comprise an image capture unit (not shown in
FIG. 1).  The image capture unit may be a CCD (Charge Coupled Device) or a CMOS (Complementary Metal-Oxide Semiconductor), placed at the imaging position for objects inside the electronic device.  The image capture unit can capture the media files.  It
is also understood that, in some embodiments, the system for media file management 100 can also comprise an engine (not shown in FIG. 1), which can simultaneously provide at least one video of n seconds and m images in n seconds.  In an example, n=4 and
m=20.  It is noted that, the engine may be inside or outside the electronic device.  It is also understood that, in some embodiments, the system for media file management 100 can also comprise a display unit (not shown in FIG. 1).  The display unit can
display related figures and interfaces, and related data, such as the media files 111.  It is understood that, in some embodiments, the display unit may be a screen integrated with a touch-sensitive device (not shown).  The touch-sensitive device has a
touch-sensitive surface comprising sensors in at least one dimension to detect contact and movement of an input tool, such as a stylus or finger on the touch-sensitive surface.  That is, users can directly input related data via the display unit. 
Additionally, the storage unit 110 can also comprise at least one music file 112.  It is noted that, in the present invention, each music file may correspond to a script file, wherein the script file defines characteristics which can be defined according
to tempos, melody, beats, cord, or chorus of the music file, and media data can be generated according to the script file.  Additionally, in the present invention, a theme defines type or classification for media files is provided.  Namely, media files
111 can be analyzed to locate a specific theme.  The theme can define effects and/or transitions between the media files.  The processing unit 120 can control related components of the system for media file management 100, process the music file and the
media files, and perform the methods for media file management, which will be discussed further in the following paragraphs.
<br/><br/> FIG. 2 is a flowchart of an embodiment of a method for media file management of the invention.  The method for media file management can be used in an electronic device, such as a computer, or a portable device, such as a digital camera, a
handheld device such as a mobile phone, a smart phone, a PDA, a GPS, or any picture-taking device.  In the embodiment, media data is produced for media files.
<br/><br/> In step S210, a music file is provided.  It is understood that, in some embodiments, the music file can be provided or selected by users via a user interface.  In step S220, the music file is analyzed to obtain a frequency spectrum corresponding
to the music file.  It is understood that, in some embodiments, the waveform of the music file can be applied with a transformation, such as the FFT (Fast F Fourier Transform) to obtain the frequency spectrum corresponding to the music file.  In step
S230, at least one beat point on the time line is detected for the music file based on the frequency spectrum.  One beat point is detected that whenever the spectrum difference from this point and another point is higher than some threshold, where the
point here refers to the average of several audio samples.  It is understood that, in some embodiments, an interface can be provided to display the detected beat points.  After the at least one beat point on the time line is detected, in step S240, media
data is generated for a plurality of media files in the electronic device based on the music file and a theme.  It is noted again, the theme can define effects or transitions between media files.  In the generation of media data, the sequence of the
respective effects or transitions can be determined according to the beat points of the music file, and the corresponding media files which should be selected for the respective effects or transitions can be determined according to the beat points of the
music file.  For example, the sequence is like T E E T T E T .  . . , which represents transition, effect, effect, transition, transition, effect, and transition at each specific timestamp according the beat points of the music file.  After the
generation of the media data, the sequence is use to determine the timestamp to apply transition or effect.  The generation of the media data is further discussed later.
<br/><br/> FIG. 3 is a flowchart of an embodiment of a method for generating media data of the invention.
<br/><br/> In step S310, a plurality of media files are analyzed to obtain a theme.  Similarly, in some embodiments, the media files comprise images, videos, music, and/or texts.  In some embodiments, an engine can simultaneously provide at least one video
of n seconds and m images in n seconds.  In an example, n=4 and m=20.  It is noted that, the engine may be inside or outside the electronic device.  It is understood that, in some embodiments, the theme can be a specific type or classification for the
media files.  For example, the theme may be Family related, Travel related, Party/Night out related, or others.  The theme can define effects and/or transitions between the media files.  It is noted that, the media files can be analyzed based on the
content and/or the metadata of the media files to know the corresponding theme.  In an example, faces can be detected in the respective media files.  The detected faces can be compared with photos in the phone book and social network tags.  It can be
known that if the analyzed media files are suitable for family or not.  In another example, the position information, such as GPS location corresponding to the respective media files can be checked to determine whether the GPS location is far from user's
usual stay or the position information can link to be a route.  If so, it can be identified as a travel theme.  In a further example, the exposure time of the respective media files can be checked to determine whether the respective media files are
captured in a dark location, such as a pub.  Similarly, the GPS location of the respective media files can be checked to know whether the location is a pub or a famous spot for people to get together.  If so, it can be identified as a Party/Night out
theme.  Further, the taken date/time of the respective media file can be used as well for theme analysis.  It is noted that, the above theme and analysis manners are only examples of the embodiments, and the present invention is not limited thereto.  In
step S320, media data is produced using the media files according to the theme and a script file corresponding to the music file.  As described, the script file may define characteristics which are defined according to tempos, melody, beats, cord, or
chorus of the music file.  Also, the theme can define effects and/or transitions between the media files.  During the generation of media data, effects, such as spot light, color effect, ken burns, and others and/or transitions, such as fade in/out,
rotation, zoom in/out, and others are generated between the media files, and/or applied to the media files.  It is understood that, in some embodiments, the sequence of the respective effects or transitions can be determined according to the beat points
of the music file, and the corresponding media files which should be selected for the respective effects or transitions can be determined according to the beat points of the music file.  Further, in some embodiments, the effects and/or transitions are
aligned with the script file, such that the effects and/or the transitions can occur at the right timing.  It is noted that, in some embodiments, the content for the effect and/or transition is real-time generated when the media data is played.
<br/><br/> FIGS. 4-6 are flowcharts of further embodiments of the method for generating media data of the invention.
<br/><br/> In FIG. 4, in step S410, specific media files are selected from the media files.  It is understood that, in some embodiments, the selection can be performed based on contents of the respective media files, comments corresponding to the
respective media files from at least one social network, position information corresponding to the respective media files, and/or historical behaviors, such as a view frequency, a share frequency, related data recorded when the respective media file is
captured, and/or a zoom frequency corresponding to the respective media files.  For example, the most frequently-watched/shared/zoomed items can be selected, the most commented photos/videos on a social network, such as <b><i>FACEBOOK</i></b> can be selected, all
files in a group, which is grouped by time or location will be selected a candidates for a source of movie, the photos/videos which contain people information, such as face and smile for a certain theme, such as the family theme are selected, the photos
with specific faces by face recognition linked to phone book's photos or social network tag, such as <b><i>Facebook,</i></b> which can be selected to create a family theme, the images which GPS location can link to a route are selected, the slow motion video for slow
tempo music and vice versa are selected, and/or the contents by date and put into an order of dates can be selected.  Further, blur photos and abnormal exposure photos are filtered.  In some examples, the statistics data from recorder's sensors stored in
the meta data of the media file can be checked to know the behavior of recorder when it is shooting.  This statistics data can be used to extract/trim a meaningful video period, such as stable period video cut.  Also, the taken date or time of the
respective media file can be also used for selection.  It is understood that, the selection rules can be various according to different requirements and applications.  Above rules are only examples of the embodiment, and the present invention is not
limited thereto.  The selected media files can be used to produce the media data.
<br/><br/> In FIG. 5, in step S510, the media files are trimmed to obtain the trimmed media files.  In some embodiments, the periods that faces show up, at least one object is moving, and/or people is speaking are kept in the trimmed video.  In some
embodiments, the respective video is trimmed based on the script file, such that the trimmed video is aligned with the characteristics defined in the script file.  Further, a blur video period will be filtered by checking the data stored in metadata. 
That data is statistics data obtained from sensors, like G-sensor Gyro when recording.  Similarly, the trimming rules can be various according to different requirements and applications.  Above rules are only examples of the embodiment, and the present
invention is not limited thereto.  The trimmed media files can be used to produce the media data.
<br/><br/> In FIG. 6, in step S610, a background audio of the respective media file is mixed with a specific music, wherein when a human speech exists in the video, the volume of the specific music within the corresponding specific period is lowered and
mixed with the background audio of the media file.
<br/><br/> It is understood that, in some embodiments, when the media files are been viewed, the media data is real-time generated for the media files.  The generated media data or a representative of the media data can be displayed for browsing.  It is
understood that, in some embodiments, a frame buffer used for storing the media data can be refreshed after each frame of the media data is rendered.  That is, the real-time generated media data is removed after it was played.  The media data is not
stored as a file in the memory.  In other words, image frames of the media data are not actually composed to form a media file until users trigger an instruction to export all image frames of the media data.  In some embodiments, the media data can be
removed once the management/viewing of the media files is completed.  However, in some embodiments, the media data can be also actually stored in the memory of the electronic device for further use.
<br/><br/> Therefore, the methods and systems for media file management of the present invention can detect beat points of a music file, and generate and/or present media data for a group of media files with effect management based on the detected beat
points, thereby assisting user to navigate the media files in the electronic device.
<br/><br/> Methods for media file management, may take the form of a program code (i.e., executable instructions) embodied in tangible media, such as floppy diskettes, CD-ROMS, hard drives, or any other machine-readable storage medium, wherein, when the
program code is loaded into and executed by a machine, such as a computer, the machine thereby becomes an apparatus for practicing the methods.  The methods may also be embodied in the form of a program code transmitted over some transmission medium,
such as electrical wiring or cabling, through fiber optics, or via any other form of transmission, wherein, when the program code is received and loaded into and executed by a machine, such as a computer, the machine becomes an apparatus for practicing
the disclosed methods.  When implemented on a general-purpose processor, the program code combines with the processor to provide a unique apparatus that operates analogously to application specific logic circuits.
<br/><br/> While the invention has been described by way of example and in terms of preferred embodiment, it is to be understood that the invention is not limited thereto.  Those who are skilled in this technology can still make various alterations and
modifications without departing from the scope and spirit of this invention.  Therefore, the scope of the present invention shall be defined and protected by the following claims and their equivalent.
<br/><br/><center><b>* * * * *</b></center>
<hr/>
   <center>
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09378768&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D182%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D4%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>
   <table>
   <tbody><tr><td align="center"><a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D182%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D4%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209378768"><img alt="[View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9378768&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D182%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D4%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209378768">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
     <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=182&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=3&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=182&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=4&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=182&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=5&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=181&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=4&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=183&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=4&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

   <a href="#top"><img alt="[Top]" border="0" src="/netaicon/PTO/top.gif" valign="middle"/></a>
   </td></tr>
   </tbody></table>
   <a name="bottom"></a>
   <a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
   </center>

</coma></body></html>