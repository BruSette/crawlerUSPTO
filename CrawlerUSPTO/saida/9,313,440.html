<html><head>
<base target="_top"/>
<title>United States Patent: 9313440</title></head>
<!---BUF1=9313440
BUF7=2016
BUF8=90120
BUF9=/1/
BUF51=9
---->
<body bgcolor="#FFFFFF">
<a name="top"></a>
<center>
<img alt="[US Patent &amp; Trademark Office, Patent Full Text and Image Database]" src="/netaicon/PTO/patfthdr.gif"/>
<br/>
<table>
<tbody><tr><td align="center">
<a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
<a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
<a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
</td></tr>
<tr><td align="center">
   <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=804&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=16&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=804&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=804&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=18&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=803&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=805&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

<a href="#bottom"><img alt="[Bottom]" border="0" src="/netaicon/PTO/bottom.gif" valign="middle"/></a>
</td></tr>
   <tr><td align="center">
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D804%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209313440"><img alt="[
View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9313440&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D804%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209313440">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09313440&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D804%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D17%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>

   </td></tr>
</tbody></table>
</center>
<table width="100%">
<tbody><tr><td align="left" width="50%"> </td>
<td align="right" valign="bottom" width="50%"><font size="-1">( <strong>804</strong></font> <font size="-2">of</font> <strong><font size="-1">7895</font></strong> <font size="-1">)</font></td></tr></tbody></table>
<hr/>
   <table width="100%">
   <tbody><tr>	<td align="left" width="50%"><b>United States Patent </b></td>
   <td align="right" width="50%"><b>9,313,440</b></td>
   </tr>
     <tr><td align="left" width="50%"><b>
         Gilson
,   et al.</b>
     </td>
     <td align="right" width="50%"> <b>
     April 12, 2016
</b></td>
     </tr>
     </tbody></table>
       <hr/>
       <font size="+1">Remote control activation based on predicted events
</font><br/>
       <br/><center><b>Abstract</b></center>
       <p> Systems and methods for predicting trigger events, such as an
     advertisement during a video program, and activating a remote control
     device in response to the prediction are described. By activating the
     remote control device at a particular time, the remote control device may
     save energy when listening for data from one or more terminal devices.
     The time to activate the remote control may be based on one or more
     factors, including the current presentation position and/or presentation
     speed of the video program. A remote control device may take additional
     actions the next time it listens for data, including illuminating
     backlights, turning on a display, displaying content on the display,
     interacting with other devices, etc.
</p>
       <hr/>
<table width="100%"> <tbody><tr> <th align="left" scope="row" valign="top" width="10%">Inventors:</th> <td align="left" width="90%">
 <b>Gilson; Ross</b> (Philadelphia, PA)<b>, Sallas; Michael</b> (Havertown, PA) </td> </tr>
<tr><th align="left" scope="row" valign="top" width="10%">Applicant: </th><td align="left" width="90%"> <table> <tbody><tr> <th align="center" scope="column">Name</th> <th align="center" scope="column">City</th> <th align="center" scope="column">State</th> <th align="center" scope="column">Country</th> <th align="center" scope="column">Type</th> </tr> <tr> <td> <b><br/>Comcast Cable Communications, LLC</b> </td><td> <br/>Philadelphia </td><td align="center"> <br/>PA </td><td align="center"> <br/>US </td> <td align="left"> </td> </tr> </tbody></table>
<!-- AANM>
~AANM Comcast Cable Communications, LLC
~AACI Philadelphia
~AAST PA
~AACO US
</AANM -->
</td></tr>
<tr> <th align="left" scope="row" valign="top" width="10%">Assignee:</th>
<td align="left" width="90%">

<b>Comcast Cable Communications, LLC</b>
 (Philadelphia, 
PA)
<br/>

</td>
</tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Family ID:
       </th><td align="left" width="90%">
       <b>51525784
</b></td></tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Appl. No.:
       </th><td align="left" width="90%">
       <b>13/804,559</b></td></tr>
       <tr><th align="left" scope="row" valign="top" width="10%">Filed:
       </th><td align="left" width="90%">
       <b>March 14, 2013</b></td></tr>
     </tbody></table>
<hr/> <center><b>Prior Publication Data</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Document Identifier</u></b></th><th align="center" scope="col"><b><u>Publication Date</u></b></th></tr><tr><td align="center"> </td><td align="center"> US 20140267931 A1</td><td align="center">Sep 18, 2014</td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table>
     <hr/>
<p> <table width="100%"> <tbody><tr><td align="left" valign="top" width="30%"><b>Current U.S. Class:</b></td> <td align="right" valign="top" width="70%"><b>1/1</b> </td></tr> 
       <tr><td align="left" valign="top" width="30%"><b>Current CPC Class: </b></td>
       <td align="right" valign="top" width="70%">H04N 5/4403 (20130101); H04N 21/4126 (20130101); H04N 21/42209 (20130101); H04N 21/44008 (20130101); H04N 21/4436 (20130101); H04N 21/812 (20130101); H04N 2005/441 (20130101); H04N 2005/4444 (20130101)</td></tr>
         <tr><td align="left" valign="top" width="30%"><b>Current International Class: </b></td>
         <td align="right" valign="top" width="70%">G05B 11/01 (20060101); H04N 21/422 (20110101); H04N 21/44 (20110101); H04N 21/443 (20110101); H04N 21/41 (20110101); H04N 5/44 (20110101); H04N 21/81 (20110101)</td></tr>
       <tr><td align="left" valign="top" width="30%"><b>Field of Search: </b></td>
       <td align="right" valign="top" width="70%">
       







 ;340/12.22,12.23,12.24,12.25,12.26,12.27,12.28,12.3
       </td></tr>
     </tbody></table>
</p><hr/><center><b>References Cited  <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2Fsearch-adv.htm&amp;r=0&amp;f=S&amp;l=50&amp;d=PALL&amp;Query=ref/9313440">[Referenced By]</a></b></center>       <hr/>
       <center><b>U.S. Patent Documents</b></center>
<table width="100%"> <tbody><tr><th scope="col" width="33%"></th> <th scope="col" width="33%"></th> <th scope="col" width="34%"></th></tr> <tr> <td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5511000">5511000</a></td><td align="left">
April 1996</td><td align="left">
Kaloi</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6278499">6278499</a></td><td align="left">
August 2001</td><td align="left">
Darbee et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6903655">6903655</a></td><td align="left">
June 2005</td><td align="left">
Stefanik</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7154428">7154428</a></td><td align="left">
December 2006</td><td align="left">
de Clercq et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7394782">7394782</a></td><td align="left">
July 2008</td><td align="left">
Davis</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7546120">7546120</a></td><td align="left">
June 2009</td><td align="left">
Ulvenes</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7928705">7928705</a></td><td align="left">
April 2011</td><td align="left">
Hooijschuur</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8560875">8560875</a></td><td align="left">
October 2013</td><td align="left">
Shen</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8855470">8855470</a></td><td align="left">
October 2014</td><td align="left">
Stern</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20040268413&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2004/0268413</a></td><td align="left">
December 2004</td><td align="left">
Reid</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20050188246&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2005/0188246</a></td><td align="left">
August 2005</td><td align="left">
Emberty</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070014264&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0014264</a></td><td align="left">
January 2007</td><td align="left">
Davis</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070185968&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0185968</a></td><td align="left">
August 2007</td><td align="left">
White</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080298770&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0298770</a></td><td align="left">
December 2008</td><td align="left">
Noguchi</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090230934&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0230934</a></td><td align="left">
September 2009</td><td align="left">
Hooijschuur</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090320056&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0320056</a></td><td align="left">
December 2009</td><td align="left">
Wu</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
       <center><b>Foreign Patent Documents</b></center>
<table width="100%"> <tbody><tr><td></td><th scope="col"></th> <td></td><th scope="col"></th> <td></td><th scope="col"></th></tr> <tr> <td align="left">
</td><td align="left">9200560</td><td></td><td align="left">
Mar 1992</td><td></td><td align="left">
GB</td></tr><tr><td align="left">
</td><td align="left">2263182</td><td></td><td align="left">
Jul 1993</td><td></td><td align="left">
GB</td></tr><tr><td align="left">
</td><td align="left">2263182</td><td></td><td align="left">
Jul 1993</td><td></td><td align="left">
IL</td></tr><tr><td align="left">
</td><td align="left">02305070</td><td></td><td align="left">
Dec 1990</td><td></td><td align="left">
JP</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
<table width="90%">   <tbody><tr><td><align="left"><br/>DOCSIS, Wikipedia, en.wikipedia.org/wiki/DOCSIS, printed Feb. 26, 2013, pp. 1-5. cited by applicant
.<br/>GreenPeak Technologies, "Ultra Low Power Wireless Control Networks," www.greenpeak.com/Technology/Technology.html, printed Jan. 23, 2013, p. 1. cited by applicant
.<br/>HomePlug, Wikipedia, en.wikipedia.org/wiki/HomePlug, printed Feb. 26, 2013, pp. 1-7. cited by applicant
.<br/>MoCA: Multimedia over Coax Alliance, "The standard for Home Entertainment Networking," www.mocalliance.org, printed Feb. 26, 2013, pp. 1-2. cited by applicant
.<br/>Power line communication, Wikipedia, en.wikipedia.org/wiki/Power.sub.--line.sub.--communication, printed Feb. 26, 2013, pp. 1-9. cited by applicant
.<br/>ZigBee Alliance, ZigBee RF4CE Overview, printed Jan. 23, 2013, .COPYRGT. 2013 ZigBee Alliance, p. 1. cited by applicant. </align="left"></td></tr> </tbody></table><br/><center><b>Other References</b></center> <br/>
       <i>Primary Examiner:</i> McNally; Kerri
<br/>
       <i>Attorney, Agent or Firm:</i> <coma>Banner &amp; Witcoff, Ltd.
<br/>
         <hr/>
<center><b><i>Claims</i></b></center> <hr/> <br/><br/>We claim: <br/><br/> 1.  A method comprising: identifying a content item being presented by a device;  determining, by a computing device, a time for a remote control device to transition from a standby
state to an active state, wherein the determining is based in part on an estimate of a presentation time of a trigger event occurring during presentation of the content item;  and transmitting, to the remote control device, identification of the
determined time for the remote control device to transition from the standby state to the active state.
<br/><br/> 2.  The method of claim 1, wherein the remote control device is configured to listen for data from the device during the active state, wherein the content item comprises a television program, and wherein the presentation time of the trigger
event comprises a start time of a television commercial presented during presentation of the television program.
<br/><br/> 3.  The method of claim 1, wherein determining the time for the remote control device to transition from the standby state to the active state is based on a current presentation time of the content item and the estimate of the presentation time
of the trigger event.
<br/><br/> 4.  The method of claim 3, wherein the content item comprises an episode of a television program, and wherein the estimate of the presentation time of the trigger event is based on the time of a trigger event occurring in at least one previous
episode of the television program.
<br/><br/> 5.  The method of claim 3, wherein determining the time for the remote control device to transition from the standby state to the active state is further based on a current presentation speed of the content item being presented by the device.
<br/><br/> 6.  The method of claim 1, further comprising: at the determined time for the remote control device to transition from the standby state to the active state, transmitting, to the remote control device, a command to illuminate a backlight of the
remote control device.
<br/><br/> 7.  The method of claim 1, wherein the presentation time of the trigger event comprises a start time of an advertisement presented during presentation of the content item, the method further comprising: at the determined time for the remote
control device to transition from the standby state to the active state, transmitting, to the remote control device, advertisement data that supplements the presented advertisement.
<br/><br/> 8.  The method of claim 1, wherein the content item comprises a video program, and wherein the presentation time of the trigger event comprises a start time of a commercial presented during presentation of the video program, the method further
comprising: at the determined time for the remote control device to transition from the standby state to the active state, determining whether presentation of the commercial has started;  and if the presentation of the commercial has started,
transmitting, to the remote control device, data for generating a second commercial on a display of the remote control device.
<br/><br/> 9.  The method of claim 1, wherein the presentation time of the trigger event comprises the time of a commercial, the method further comprising: at the determined time for the remote control device to transition from the standby state to the
active state, determining whether presentation of the commercial has started;  and if the presentation of the commercial has not started, determining a second time for the remote control device to transition from the standby state to the active state
based on a new estimate of the presentation time of the commercial.
<br/><br/> 10.  A method comprising: receiving, at a communication device, identification of a time for the communication device to transition from a standby state to an active state, wherein the communication device is configured to listen for data from a
terminal device during the active state, and wherein the time for the communication device to transition from the standby state to the active state is based in part on an estimate of a presentation time of a trigger event occurring during presentation of
a content item on a display of the terminal device;  storing, by the communication device, the identification of the time to transition from the standby state to the active state;  transitioning the communication device from the standby state to the
active state at the identified time;  and during the active state, transmitting, by the communication device to the terminal device, a request for data and listening for data from the terminal device.
<br/><br/> 11.  The method of claim 10, further comprising: illuminating a backlight of the communication device at the identified time.
<br/><br/> 12.  The method of claim 10, while listening for data from the terminal device, receiving supplemental data from the terminal device;  and displaying the supplemental data on a display of the communication device.
<br/><br/> 13.  The method of claim 12, wherein the supplemental data corresponds to an advertisement presented on the display of the terminal device.
<br/><br/> 14.  The method of claim 10, further comprising: prior to the receiving step, transitioning the communication device from the standby state to the active state, wherein the receiving occurs during the active state;  and after the storing step,
transitioning the communication device from the active state to the standby state.
<br/><br/> 15.  The method of claim 14, wherein the transition that occurs prior to the receiving step is in response to user actuation of a button on the communication device.
<br/><br/> 16.  The method of claim 10, further comprising: receiving, at the communication device, a command from a user that modifies a presentation speed of the content item presented on the display of the terminal device;  and in response to receiving
the command that modifies the presentation speed, transmitting, by the communication device, a message to recalculate the time for the communication device to transition from the standby state to the active state.
<br/><br/> 17.  The method of claim 10, wherein the communication device comprises a device configured to function as a two-way television remote control.
<br/><br/> 18.  The method of claim 10, wherein the communication device comprises a mobile phone configured to control presentation of content on the terminal device.
<br/><br/> 19.  A method comprising: determining a presentation time of a trigger event occurring during presentation of a content item;  determining, based on the presentation time of the trigger event, a time for a communication device to transition from
a standby state to an active state;  and transmitting, to the communication device, identification of the determined time for the communication device to transition from the standby state to the active state.
<br/><br/> 20.  The method of claim 19, wherein the communication device is configured to listen for data from a display device during the active state, wherein the content item comprises a television program, and wherein the presentation of the trigger
event comprises a start time of a television commercial presented during presentation of the television program. <hr/> <center><b><i>Description</i></b></center> <hr/> <br/><br/>BACKGROUND
<br/><br/> Portable television remote controls are typically powered by batteries with limited life spans.  Some remote controls can receive information from external devices, such as televisions or set-top boxes.  In order to save battery life, remote
controls can poll for information from external devices at predefined times.  For example, a remote control might only listen for information only immediately after the user has used the remote control to send a command.  One problem with this solution
is that external devices may desire to send information to the remote control even when the remote control is not being used by the user.  Another solution is for the remote control to listen for information at predefined intervals (e.g., every 5
minutes, 20 minutes).  If the predefined interval is too short, however, the remote control battery may drain too quickly.  If the predefined interval is too long, the remote control may miss information transmitted by external devices or receive
information that is too old if the external device buffers the information until the remote polls it.
<br/><br/>SUMMARY
<br/><br/> This summary is not intended to identify critical or essential features of the disclosures herein, but instead merely summarizes certain features and variations thereof.  Other details and features will also be described in the sections that
follow.
<br/><br/> In one aspect, provided is a system that improves the lifespan of a remote control device's power source (such as a battery) by more efficiently listening for data from terminal devices based on predictions of trigger events, such as the start
of a commercial.  Some of the various features described herein relate to a method of activating a remote control device based on predicted events, such as the start of a commercial and/or a system, computer readable medium, and/or apparatus configured
to perform the method.
<br/><br/> A method described herein may comprise identifying a content item, such as a television program, being presented by a device, such as a terminal device.  A computing device may determine a time for a remote control device (e.g., a television
remote control, mobile phone, etc.), which may be configured to operate with the terminal device, to transition from a standby state to an active state.  During the active state, the remote control device may be configured to listen for data from the
terminal device.  The determining may be based in part on an estimate of a presentation time of a trigger event occurring during presentation of the content item, which may comprise the time of a commercial and/or a start time of a television commercial
presented during presentation of the television program.  The method may further comprise transmitting, to the remote control device, identification of the determined time for the remote control device to transition from the standby state to the active
state.
<br/><br/> In some aspects, determining the time for the remote control device to transition from the standby state to the active state may be based on a current presentation time of the content item and the estimate of the presentation time of the trigger
event.  Furthermore, the content item may comprise an episode of a television program, and the estimate of the presentation time of the trigger event may be based on the time of a trigger event occurring in at least one previous episode of the television
program.  Additionally or alternatively, determining the time for the remote control device to transition from the standby state to the active state may further be based on a current presentation speed of the content item being presented by the terminal
device.
<br/><br/> Various actions may be taken by the terminal device, remote control device, or other computing device at the determined time for the remote control device to transition from the standby state to the active state.  For example, a command to
illuminate a backlight of the remote control device may be transmitted to the remote control device.  The presentation time of the trigger event may comprise the start time of an advertisement and/or commercial presented during presentation of the
content item.  The content item may comprise a video program.  At the determined time for the remote control device to transition from the standby state to the active state, advertisement data that supplements the presented advertisement may be
transmitted to the remote control device.  Additionally or alternatively, it may be determined whether presentation of the commercial has started at the determined time for the remote control device to transition from the standby state to the active
state.  If the presentation of the commercial has started, data for generating a second commercial on a display of the remote control device may be transmitted to the remote control device.  If the presentation of the commercial has not started, a second
time for the remote control device to transition from the standby state to the active state based on a new estimate of the presentation time of the commercial may be determined.
<br/><br/> A method described herein may comprise receiving, at a communication device (e.g., a two-way communication device), identification of a time for the communication device to transition from a standby state to an active state.  The communication
device may be configured to listen for data from a terminal device during the active state.  The communication device may store the identification of the time to transition from the standby state to the active state.  At the identified time, the
communication device may transition from the standby state to the active state, and after transitioning to the active state, the communication device may listen for data from the terminal device.  The communication device may be configured to transmit a
request for data to the terminal device prior to listening for data from the terminal device during the active state.
<br/><br/> In some aspects, the communication device may comprise at least one of a device configured to function as a television remote control and a mobile phone configured to control presentation of content on the terminal device.  A backlight of the
communication device may be illuminated at the identified time.  Additionally or alternatively, the device may receive supplemental data from the terminal device while listening for data from the terminal device, and the supplemental data may be
displayed on a display of the communication device.  The supplemental data may correspond to an advertisement presented on a display of the terminal device.
<br/><br/> In some aspects, prior to receiving identification of the time for the communication device to transition from the standby state to the active state (the second time), the communication device may have previously transitioned from the standby
state to the active state (the first time).  Furthermore, the receiving of the identification of the time may occur while the communication device is in the active state the first time.  After storing the identification of the time to transition from the
standby state to the active state, the communication device may transition from the active state back to the standby state to save power.  The transition that occurs prior to the receiving step may be in response to user actuation of a button on the
communication device.
<br/><br/> In some aspects, the communication device may receive a command from a user that modifies a presentation speed of a content item presented on a display of the terminal device.  In response to receiving the command, the communication device may
transmit a message to recalculate the time for the communication device to transition from the standby state to the active state.
<br/><br/> A method described herein may comprise determining, by a computing device, when an advertisement is scheduled to be presented relative to a segment of a video program presented by a terminal device.  A time for a user device to listen for data
from the terminal device may be set to be one of the start time and the end time of the advertisement.  The time for the user device to listen for data may be transmitted to the user device.  While the user device is listening for data from the terminal
device, data corresponding to the advertisement may be transmitted from the terminal device to the user device.  This data may be used to generate a display of a second advertisement on a display of the user device. <br/><br/>BRIEF DESCRIPTION OF THE
DRAWINGS
<br/><br/> Some features herein are illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings and in which like reference numerals refer to similar elements.
<br/><br/> FIG. 1 illustrates an example information access and distribution network.
<br/><br/> FIG. 2 illustrates an example hardware and software platform on which various elements described herein can be implemented.
<br/><br/> FIG. 3 illustrates an example method of listening for data from a terminal device according to one or more illustrative aspects of the disclosure.
<br/><br/> FIG. 4 illustrates an example method of determining the next time to listen for data from the terminal device based on a predicted event according to one or more illustrative aspects of the disclosure.
<br/><br/> FIG. 5 illustrates an example method of listening for data from the terminal device at the determined next time to listen according to one or more illustrative aspects of the disclosure.
<br/><br/>DETAILED DESCRIPTION
<br/><br/> FIG. 1 illustrates an example information access and distribution network 100 on which many of the various features described herein may be implemented.  Network 100 may be any type of information distribution network, such as satellite,
telephone, cellular, wireless, etc. One example may be an optical fiber network, a coaxial cable network or a hybrid fiber/coax (HFC) distribution network.  Such networks 100 use a series of interconnected communication links 101 (e.g., coaxial cables,
optical fibers, wireless connections, etc.) to connect multiple premises, such as homes 102, to a local office (e.g., a central office or headend 103).  The local office 103 may transmit downstream information signals onto the links 101, and each home
102 may have a receiver used to receive and process those signals.
<br/><br/> There may be one link 101 originating from the local office 103, and it may be split a number of times to distribute the signal to various homes 102 in the vicinity (which may be many miles) of the local office 103.  Although the term home is
used by way of example, locations 102 may be any type of user premises, such as businesses, institutions, etc. The links 101 may include components not illustrated, such as splitters, filters, amplifiers, etc. to help convey the signal clearly.  Portions
of the links 101 may also be implemented with fiber-optic cable, while other portions may be implemented with coaxial cable, other links, or wireless communication paths.
<br/><br/> The local office 103 may include an interface 104, which may be a termination system (TS), such as a cable modem termination system (CMTS), which may be a computing device configured to manage communications between devices on the network of
links 101 and backend devices such as servers 105-107 (to be discussed further below).  The interface 104 may be as specified in a standard, such as, in an example of an HFC-type network, the Data Over Cable Service Interface Specification (DOCSIS)
standard, published by Cable Television Laboratories, Inc.  (a.k.a.  CableLabs), or it may be a similar or modified device instead.  The interface 104 may be configured to place data on one or more downstream channels or frequencies to be received by
devices, such as modems at the various homes 102, and to receive upstream communications from those modems on one or more upstream frequencies.  The local office 103 may also include one or more network interfaces 108, which can permit the local office
103 to communicate with various other external networks 109.  These networks 109 may include, for example, networks of Internet devices, telephone networks, cellular telephone networks, fiber optic networks, local wireless networks (e.g., WiMAX),
satellite networks, and any other desired network, and the network interface 108 may include the corresponding circuitry needed to communicate on the network 109, and to other devices on the network such as a cellular telephone network and its
corresponding cell phones (e.g., cell phone 117).
<br/><br/> As noted above, the local office 103 may include a variety of servers 105-107 that may be configured to perform various functions.  For example, the local office 103 may include a push notification server 105.  The push notification server 105
may generate push notifications to deliver data and/or commands to the various homes 102 in the network (or more specifically, to the devices in the homes 102 that are configured to detect such notifications).  The local office 103 may also include a
data server 106.  The data server 106 may be one or more computing devices that are configured to provide data to users in the homes.  This data may be, for example, video on demand movies, television programs, songs, text listings, etc. The data server
106 may include software to validate user identities and entitlements, locate and retrieve requested data, encrypt the data, and initiate delivery (e.g., streaming) of the data to the requesting user and/or device.
<br/><br/> The local office 103 may also include one or more application servers 107.  An application server 107 may be a computing device configured to offer any desired service, and may run various languages and operating systems (e.g., servlets and JSP
pages running on Tomcat/MySQL, OSX, BSD, Ubuntu, Redhat, HTML5, JavaScript, AJAX and COMET).  For example, an application server may be responsible for collecting data such as television program listings information and generating a data download for
electronic program guide listings.  Another application server may be responsible for monitoring user viewing habits and collecting that information for use in selecting advertisements.  Another application server may be responsible for formatting and
inserting advertisements in a video stream being transmitted to the homes 102.
<br/><br/> An example home 102a may include an interface 120.  The interface may comprise a device 110, such as a modem, which may include transmitters and receivers used to communicate on the links 101 and with the local office 103.  The device 110 may
be, for example, a coaxial cable modem (for coaxial cable links 101), a fiber interface node (for fiber optic links 101), or any other desired modem device.  The device 110 may be connected to, or be a part of, a gateway interface device 111.  The
gateway interface device 111 may be a computing device that communicates with the device 110 to allow one or more other devices in the home to communicate with the local office 103 and other devices beyond the local office.  The gateway 111 may be a
set-top box (STB), digital video recorder (DVR), computer server, or any other desired computing device.  The gateway 111 may also include (not shown) local network interfaces to provide communication signals to devices in the home, such as televisions
112, additional STBs 113, personal computers 114, laptop computers 115, wireless devices 116 (wireless laptops and netbooks, mobile phones, mobile televisions, personal digital assistants (PDA), etc.), and any other desired devices.  Examples of the
local network interfaces include Multimedia Over Coax Alliance (MoCA) interfaces, Ethernet interfaces, universal serial bus (USB) interfaces, wireless interfaces (e.g., IEEE 802.11), Bluetooth interfaces, and others.
<br/><br/> The devices in the home also include a remote control device having two-way communication capabilities.  In general, two-way communication devices may both receive and transmit data.  The remote control device may comprise a television remote
control configured to transmit data to a terminal device (e.g., an STB, DVR, television, etc.) and also receive data from the terminal device (or other terminal devices).  For example, the remote control device may transmit data to a terminal device and
receive data from the same terminal device.  Additionally or alternatively, the remote control device may transmit data and receive data from different terminal devices (e.g., transmit data to a television and receive data from an STB).
<br/><br/> The wireless devices 116 (e.g., a mobile phone) may function as the remote control device.  A mobile phone may be programmed to transmit data, such as commands, to the terminal device (e.g., an STB) and also receive data, such as content or
return commands, from the terminal device (or other terminal devices).  For example, the mobile phone may include an application configured to generate a display of a remote control interface.  The display may be similar to the interface of a television
remote control, (e.g., having up/down/left/right buttons, a number pad, a settings button, etc.).  One or more advertisements may also be generated and displayed on a display of the mobile phone or television remote control.
<br/><br/> The remote control device (e.g., the television remote control, mobile phone, or other portable device) may communicate with the terminal device using a local network (e.g., a wireless connection, such as RF or IR, or wired connection in the
home 102a), an external network (e.g., a cellular network, a fiber optic network, a coaxial network, etc.), or any combination thereof.  For example, the remote control device may transmit user-generated commands to the STB using an IR or RF link in the
home 102a.  Alternatively, the remote control device may transmit the command to an external computing device configured to process and/or act on the command using an external link, such as a cellular network.  The external computing device may
subsequently cause the terminal device to act on the command (e.g., switch channels, display a menu, change user interface settings, etc.) by communicating with the terminal device using the same external link (e.g., cellular link) or another external
network link (e.g., fiber optic link, coaxial link, etc.).
<br/><br/> FIG. 2 illustrates general hardware and software elements that can be used to implement any of the various computing devices (e.g., terminal devices, remote control devices, etc.) discussed herein.  The computing device 200 may include one or
more processors 201, which may execute instructions of a computer program to perform any of the features described herein.  The instructions may be stored in any type of computer-readable medium or memory, to configure the operation of the processor 201. For example, instructions may be stored in a read-only memory (ROM) 202, random access memory (RAM) 203, hard drive, removable media 204, such as a Universal Serial Bus (USB) drive, compact disk (CD) or digital versatile disk (DVD), floppy disk drive, or
any other desired electronic storage medium.  Instructions may also be stored in an attached (or internal) hard drive 205.  The computing device 200 may include one or more output devices, such as a display 206 (or an external television), and may
include one or more output device controllers 207, such as a video processor.  There may also be one or more user input devices 208, such as a remote control, keyboard, mouse, touch screen, microphone, etc. The computing device 200 may also include one
or more network interfaces, such as input/output circuits 209 (such as a network card) to communicate with an external network 210.  The network interface may be a wired interface, wireless interface, or a combination of the two.  In some embodiments,
the interface 209 may include a modem (e.g., a cable modem), and network 210 may include the communication links 101 discussed above, the external network 109, an in-home network, a provider's wireless, coaxial, fiber, or hybrid fiber/coaxial
distribution system (e.g., a DOCSIS network), or any other desired network.
<br/><br/> The system and methods described herein may be used to schedule the next time a remote control device should listen for data from one or more terminal devices.  The scheduled time may correspond to the occurrence or predicted occurrence of a
trigger event, such as the start of an advertisement during presentation (e.g., playback) of a content item, such as a video program.  The scheduled time may be determined based on one or more factors, such as the current presentation position and
presentation speed of the video program, an estimate of the presentation position of the next trigger event, and/or the confidence that the trigger event will occur at the estimated presentation position.  Alternatively, if the time of the trigger event
is known, the remote control device may listen for data at or near that known time.  In addition to listening for data, the remote control device may take additional actions at the scheduled time, such as illuminating backlights, activating a display,
buffering content, displaying content on the display, interacting with other devices, etc.
<br/><br/> One benefit of the concepts described herein includes the ability to predict when users might use the remote control device (e.g., pressing mute during presentation of an advertisement) and facilitate convenient use of the remote control device,
such as by illuminating backlights for buttons that the user might use.  Furthermore, the battery life of the remote control device may be extended by selectively activating the remote control device rather than activating the remote at predefined
intervals (e.g., 5 minutes, 20 minutes).  An additional benefit includes the ability to display content that has been transmitted from a terminal device on a display of the remote control device.  For example, a second advertisement that supplements the
advertisement displayed by the terminal device may be displayed on the remote control device.
<br/><br/> FIG. 3 illustrates an example method of listening for data from a terminal device according to one or more illustrative aspects of the disclosure.  The steps illustrated in FIG. 3 may be performed, for example, by a remote control device or
other user device.  In step 305, the settings for the system for configuring the remote control device to listen for data based on predicted events may be configured.  Remote control device states may be determined; the states including an active state,
a standby state, an off state, or any other intermediate state.  In the active state, the remote control device may be configured to both transmit data to terminal devices and receive (e.g., listen for) data from terminal devices.  For example, a
transceiver configured to transmit data and receive data may be active or otherwise powered/turned on in the active state.  If separate transmitter(s) and/or receiver(s) are used to communicate with terminal devices, those transmitter(s) and/or
receiver(s) may be activated so that the remote control device can both send and receive data.
<br/><br/> The remote control device may listen for (or otherwise receive) data from one or more terminal devices via one or more communication interfaces and/or communication links.  The remote control device may also request data from one or more
terminal devices prior to listening for data.  The remote control device may have a radio frequency (RF) transceiver and/or receiver interface and listen for RF signals using that interface.  The remote control device may have an infrared (IR)
transceiver and/or receiver interface and listen for data over IR communication links.  The remote control device may have a cellular network (e.g., GSM, CDMA, GPRS, UMTS, LTE, and the like) transceiver and/or receiver interface and listen for data over
the cellular network using the interface.  The remote control device may have a wireless local area network (WLAN, such as any of the IEEE 802.11 standards) transceiver and/or receiver interface and listen for data over WLAN and/or other wireless
interfaces (e.g., WiMax, Bluetooth, etc.).  Other examples of wireless communication links between the remote control device and terminal devices include, but are not limited to, visible light links (e.g., use of cameras that are configured to capture
visible light and/or pictures), audio links (e.g., communication using sound, which may be audible or inaudible, such as ultrasonic sound waves), and near field communication (NFC).  The remote control device and one or more terminal devices may also
communicate using wired communication interfaces and/or communication links.  Examples include, but are not limited to, power line communication (e.g., HomePlug), communication over coaxial or other cables (e.g., communications using the Multimedia over
Coax Alliance (MoCA) standard), communication over Ethernet, and communications using Data Over Cable Service Interface Specification (DOCSIS).
<br/><br/> Optionally, backlights on the remote control device, such as indicator lights and/or lights used to illuminate buttons or displays, may be activated in the active state.  For example, one or more display screens (which may include touchscreen
capabilities), may be turned on or otherwise illuminated.  If the remote control device has dedicated backlights for buttons, a set of backlights may be turned on, whereas a different set of backlights may be turned off in the active state.  For example,
and as will be discussed in further detail in the examples below, the backlight(s) for the fast forward button, the electronic program guide button, the number pad, volume button(s), the mute buttons, and/or the channel up/down button(s) may be
illuminated.  On the other hand, the power button, the settings button, and/or the play button might not be illuminated during the active state.  Backlight or display brightness may also be adjusted.  For example, the mute button may be set to 100% of
its maximum brightness (or some lower level of brightness, such as 80%), whereas the power button may be set to 0% of its maximum brightness (i.e., off) or some slightly higher level of brightness, such as 20%.  In general, the buttons that a user is
expected to use during the trigger event (e.g., a commercial) may be brighter than buttons the user is not expected to use during the trigger event.  The backlights may also be configured to flash a few times (e.g., 2 times, 3 times) prior to entering
the active state or at the beginning of the active state.  Optionally, a vibrator in the remote control device (e.g., a vibration motor) may vibrate just prior to or at the beginning of the active state.  Similarly, the remote control device may count
down, beep, or generate any other audible sound just prior to or at the beginning of the active state.
<br/><br/> The remote control device may also be configured for multiple active states, depending on the type of event predicted to occur in the future.  As will be described in further detail in the examples below, trigger events may include a commercial,
product placement occurring during presentation of a video program, and/or a calendar event.  A different type of active state may be assigned to each type of trigger event.  For example, if the trigger event is the presentation of a commercial, the
remote control device may activate a receiver or transceiver to receive data that supplements the commercial from terminal devices and/or illuminate one or more buttons in a first active state.  If the trigger event is a product placement, the remote
control device may activate a receiver or transceiver to receive data related to the product (e.g., a link to go to a website for the product) and/or activate a display on the remote control device to display the link in a second active state.  If the
trigger event is a calendar event (e.g., a scheduled time for the user to watch a television program with a friend), the remote control device may activate a receiver or transceiver to receive a live camera feed from a camera at the user's front door or
other external device (e.g., if the user is expecting the friend to show up) in a third active state.  The receiver or transceiver configured to receive a camera feed from a camera may, but need not be, different from the receiver or transceiver
configured to receive data that supplements a commercial from a terminal device.
<br/><br/> The type of active state that the remote control device enters into may also depend on the likelihood (e.g., based on a confidence factor) that the trigger event will occur at the predicted time.  If the likelihood that the trigger event will
occur is greater than a threshold (e.g., 50%), the remote control device may enter a first active state.  For example, backlights may be at 80% of their maximum brightness in the first active state.  If the likelihood is less than a threshold, the remote
control device may enter a second, different active state.  For example, backlights may be at 40% of their maximum brightness in the second active state.  Which active state the remote control device enters into may also depend on what commercial is
predicted to be presented during presentation of the video program and/or based on the channel that a terminal device, such as an STB, is presently tuned to.  The previously-described trigger events and/or active states are included merely as examples. 
Numerous other trigger events and/or types of active states may be used, as will be described in further detail in the examples below.
<br/><br/> In the standby state, the remote control device may deactivate (e.g., turn off) certain functionalities to save battery life.  For example, the remote control device might not be configured to listen for (or otherwise receive) data from terminal
devices.  A transceiver in the remote control device may be turned off or placed in a low power state to prevent the remote control device from listening for data.  Turning off the transceiver may also (optionally) prevent the remote control device from
transmitting information during the standby state.  However, when a physical or virtual button is actuated (e.g., pressed) by a user, the remote control device may still register the button press.  If the remote control device includes a microphone
configured to receive voice commands from the user, the microphone may be kept active and the remote control device may register voice commands during the standby state.  In some embodiments, the microphone may be deactivated, such that the remote
control device does not receive and/or process voice commands but does receive and/or process button actuations during the standby state.  A backlight indicating to users that the microphone is on and that the remote control device can receive voice
commands may be illuminated in either the active state or the standby state.  The remote control device may also be configured to sense physical movement of the remote control device using, for example, an accelerometer.
<br/><br/> After registering the button press, voice command, and/or sensing movement of the remote control device, the remote control device may transition from the standby state to the active state to transmit the corresponding command to a terminal
device or perform any other action.  Alternatively, if separate transmitter(s) and/or receiver(s) are used to communicate with terminal devices, the transmitter(s) may be activated so that the remote control device may transmit data during the standby
mode.  On the other hand, the receiver(s) may be deactivated so that the remote control device may be prevented from receiving data.  In some aspects, both the transmitter(s) and receiver(s) may be turned off in the standby state.
<br/><br/> Optionally, the backlights of the remote control device (or displays on the remote) may be selectively turned on or off in the standby state.  For example, all of the backlights and/or displays may be turned off or dimmed.  Alternatively, one
set of certain backlights, displays, or regions of displays may be turned off or dimmed, whereas a different set of backlights, displays, or regions of displays may be turned on or brightened.  For example, backlights for the number pad, the EPG button,
the channel up/down buttons, and/or the remote control device display may be turned off or dimmed, whereas the backlight for the volume up/down buttons may be turned on or brightened.  In general, the buttons that a user is expected to use during the
standby state (e.g., during presentation of a video program) may be brighter than buttons the user is not expected to use during the standby state.
<br/><br/> The remote control device may be configured for other states, such as an off state.  The remote control device may enter an off state if an off switch that shuts down power to the device is actuated.  In general, the remote control device may
consume less power when it is off than when it is in the standby state.  In some aspects, the remote control device might not register user actions (e.g., movement of the remote control device and/or user actuation of a button/display) on the remote
control device during the off state.  In other aspects, the remote control device may register some user actions (e.g., user actuation of a button/display), but not other user actions (e.g., sensing movement of the remote control device using an
accelerometer).  In other words, the remote control device may deactivate external sensors, such as an accelerometer, while leaving other sensors, such as a tactile or pressure sensor for a physical button, activated.  This may be beneficial if energy
from physical button presses is harvested.
<br/><br/> Other parameters for the remote control device may be set in the configuration step 305.  For example, the time for the remote control device to begin listening for data from terminal devices may be set relative to a predicted start time of a
trigger event (e.g., a commercial, product placement occurring during the video program, such as a particular brand of soda appearing in a television show, etc.), a predetermined time before the start of the trigger event (e.g., five seconds before the
commercial is predicted to start), a predetermined time after the start of the trigger event, the predicted end time of the trigger event, the start of the video program after presentation of a commercial ends, etc.
<br/><br/> Furthermore, the types of actions taken by the remote control device after transitioning from the standby state to the active state (or vice versa) may be defined.  For example, after transitioning from the standby to active states, the remote
control device may listen for data from terminal devices, turn on/off backlights, activate a microphone, play a sound, brighten/dim backlights, adjust backlight colors, display supplemental advertisements, and/or a combination of actions.  In order to
carry out these actions, the remote control device may transition from the active to standby states (or vice versa).
<br/><br/> By configuring in step 305, the system of listening for data based on predicted events may be enabled or disabled.  If the system is enabled, the remote control device may be configured to transition between the active, standby, and other states
as previously discussed.  If the system is disabled, the remote control device may remain in one state (e.g., active state or standby state), even if a commercial or other trigger event is predicted to occur.  The remote control device may be configured
to perform certain default actions if the system is disabled.  For example, the remote control device may listen for data at periodic intervals (e.g., every 10 seconds) or only after the user uses the remote control device.
<br/><br/> Configuration may occur at any time, and the user can trigger the configuration.  The user may use the remote control device, the terminal device (e.g., an STB), or a combination thereof to configure or reconfigure the remote control.  For
example, the remote control device may have physical or virtual configuration settings buttons that allow the user to adjust the configuration of the remote control device.  Additionally or alternatively, a menu may be displayed on the terminal device
(or a display device connected thereto) or on the remote control device itself.  The user may configure the remote control device by navigating the menu.  The configuration may be stored in a user's account or profile, which may be stored locally or on a
network (e.g., in the cloud).  The configuration data may be pushed automatically to any new remote control device that the user users or otherwise brings online.
<br/><br/> In step 310, the remote control device may initiate the standby state.  The remote control device may enter the standby state after remote control device has been configured or a predetermined time thereafter (e.g., 10 seconds).  Additionally or
alternatively, the remote control device may enter the standby state after the remote control device finishes sending data, such as a command, to the terminal device or a predetermined time thereafter.  As will be discussed in further detail in the
examples below, the remote control device may enter the standby state after the remote control device has received information indicating the next time that the remote control device should listen for data.
<br/><br/> In step 315, the remote control device may determine whether a user has used the remote control device.  The user may use the remote control device to issue commands (such as channel up, volume down, display EPG, mute, etc.), to a terminal
device (such as an STB) and/or to use any other functionalities of the remote control device.  Additionally or alternatively, the remote control device may sense movement of the remote control device using, for example, an accelerometer or other motion
sensor.  Based on detecting movement, the remote control device may determine that it has been used in step 315.  If the remote control is used (step 315: Y), the remote control device may initiate the active state in step 320.  As previously discussed,
the remote control device may illuminate a backlight and/or turn on a receiver or transceiver to listen for data from one or more terminal devices (in step 325) when it transitions from the standby state to the active state.  Instead of passively
listening for data, the remote control device may transmit, to the terminal device, a request for information, such as a poll request.  The information received from the terminal device and/or in response to the poll request may include the next time the
remote control device should listen for data.  The information may include clock drift adjustment information to synchronize the remote control device's clock with the terminal device's (or other external device's) clock.  The information may also
include information identifying the content of the next trigger event (e.g., the type of commercial, the product in the commercial, the commercial name, etc.) if the information is known.
<br/><br/> The remote control device may enter the active state at any time instead of waiting for the remote control device to be used.  As will be discussed in further detail below with respect to FIGS. 4 and 5, the remote control device may receive
information from a terminal device identifying the next time the remote control device should listen for data or otherwise enter the active state.  The identified time may correspond to the time an advertisement is expected to be presented during
presentation (e.g., playback) of a video program (e.g., a broadcast program, video on demand program, DVR program, etc.).  Accordingly, the remote control device may initiate the active state (in step 320) at the start of the video program or some
predetermined time after the start of the video program (e.g., 1 minute into the video program), such as if a commercial typically plays just after the opening scenes of the program (e.g., a recap of a previous episode).  Additionally or alternatively,
the remote control device may enter the active state (or otherwise poll for information from terminal devices) immediately (or a predetermined time) after the remote control device has been turned on, such as after the batteries of the remote control
device have been inserted or replaced.  The remote control device may similarly enter the active state at any predetermined time without waiting for user input.  For example, the remote control device could poll for information every few hours when it is
not being heavily used by the user, is out of range, is offline, etc.
<br/><br/> FIG. 4 illustrates an example method of determining the next time for the remote control device to listen for data from terminal devices based on predicted events according to one or more illustrative aspects of the disclosure.  The steps
illustrated in FIG. 4 may be performed by a terminal device that transmits data to the remote control device or any other device associated with the terminal device that may be located at the home 102, local office 103, and/or distributed among one or
more locations (e.g., in a cloud computing environment).  For the sake of brevity, the steps illustrated in FIG. 4 will be described as being performed by a terminal device, which may physically comprise one or more computing device.
<br/><br/> In step 405, the content currently being accessed (e.g., received, displayed, or otherwise presented) by the terminal device may be identified.  For example, the terminal device may comprise STB 113 at the user's home 102a.  STB 113 may be
presenting, to the user, content (e.g., a video program, such as an episode of a television program) received from the local office 103 (e.g., a video on demand movie, television program, etc.) or any other content source (e.g., Internet servers or other
network devices).  The terminal device may identify the content item based on a program or packet identifier received with the content item, based on a textual description of the content item in an electronic program guide (EPG) that lists the content
item, based on program specific information including Program Association Tables (PATs) and Program Map Tables (PMTs) associated with programs transmitted to the STB, based on content fingerprinting or watermarking, and/or based on any other method of
identifying the content item known to one of ordinary skill in the art.
<br/><br/> In step 410, the terminal device may determine the current presentation position (time) of the content item.  The current presentation position may be measured relative to the start time of the content item.  For example, if the user is 14
minutes and 20 seconds into an episode of a television program, the terminal device may determine that the current presentation time is 14 minutes and 20 seconds.  The start of the television program may be the baseline (i.e., 0 minutes).
<br/><br/> In step 415, the terminal device may determine the current presentation speed of the content item.  The content item may be presented at a normal/baseline presentation speed (e.g., 1.times.  presentation speed), which may occur, for example, if
the user presses a `play` button on the terminal device or remote control device.  The content item may also be presented at slower presentation speeds (e.g., 0.5.times., etc.) or faster presentation speeds (e.g., 2.times., 3.times., 4.5.times., etc.). 
These presentation speeds may occur if the user presses a `slow motion` button (e.g., for 0.5.times.  speed), `fast forward` or `skip` buttons (e.g., for 2.times., 3.times., 4.5.times., etc. speeds), or any other buttons on the terminal device or remote
control device.
<br/><br/> In step 420, the terminal device may identify one or more trigger events expected to occur in the future and estimate the presentation time(s) for the trigger events.  As previously discussed, trigger events may include an advertisement, such as
a television commercial, expected (or otherwise scheduled) to be presented during presentation of a video program, such as a television program.  Alternatively, trigger events may include placement of a product during presentation of the video program. 
For example, if a particular brand of soda appears at minute 16 of the video program (or a song plays back at that time), the trigger event may be the appearance of the soda (or the playing of the song).  In some aspects, marks (e.g., tags) may be
included with the video program to identify the location of product placements.  Trigger events may also include events included on the user's calendar (e.g., GOOGLE calendar, OUTLOOK calendar, or other electronic calendar) or on the calendar of a person
associated with the user, such as a friend.  The calendar events may correspond to scheduled activities for the user and/or friend.  For example, the calendar entry may indicate that the user and the user's friend plan to watch a television program
together on Tuesday at 7:00 PM.  Accordingly, Tuesday at 7:00 PM may comprise the time of the trigger event.  If the trigger event was previously defined in the configuration step 305, the terminal device may identify the trigger event by retrieving the
information stored during the configuration step.  The presentation time of the commercial may correspond to the start time of the commercial, at a predetermined time before the state of the commercial, in the middle of the commercial, at the end time of
the commercial, at the start of the video program after presentation of the commercial ends, etc.
<br/><br/> In some embodiments, the terminal device may estimate the presentation time of the next commercial by retrieving data from a database of content items associated with or otherwise similar to the content item accessed by the terminal device.  For
example, the content item may comprise an episode of a television program and the database may store data describing previous episodes of the same television program, including the start and end times of commercials presented during those previous
episodes.  Below is an example graphical representation of a previous episode having commercials:
<br/><br/> ##STR00001##
<br/><br/> Four commercials, C1-C4, may have been presented during a 30 minute episode of the television program (e.g., a previous episode).  For example, C1 may have started 48 seconds into the television program (e.g., following the opening scenes and/or
recap of previous episode(s)), C2 may have started 9 minutes and 24 seconds into the program, C3 may have started 13 minutes into the program, and C4 may have started 28 minutes and 2 seconds into the program (e.g., before the credits and/or end scenes). If the user is 30 seconds into the currently presented episode of the television program, the terminal device may estimate (in step 420) that the next trigger event (e.g., the start of the next commercial) will occur 48 seconds into the current episode,
based on the start time of commercial C1 in the previous episode.  If data for more than one previous episode is used, the average start time of C1 may be used as the estimate for the current episode.  For example, commercial C1 in a different previous
episode may have started 54 seconds into the program.  The terminal device may estimate that the start of the next commercial in the current episode will occur 51 seconds into the current episode, based on the average start time of the commercials in the
two previous episodes.  The database may similarly store the length and/or end time of each commercial C1-C4.  Similar data may be stored for many previous episodes (e.g., 5 episodes, 30 episodes, 100 episodes, etc.).
<br/><br/> Databases may similarly store data for other types of programs, such as miniseries and movies.  For example, if the video program is the final movie in a trilogy of movies, the database may store data describing the first two movies in the
trilogy including commercial times.  Other classifications may be used to identify similar content items for the database, such as genre, cast members, directors, writers, and/or a combination thereof.  For example, if the video program currently being
presented by the terminal device is an action movie starring Bruce Willis, the database may store data (e.g., commercial times) describing other action movies starring Bruce Willis.
<br/><br/> In step 425, the terminal device may determine a confidence factor for each estimated presentation time of the next trigger event.  The terminal device may rely on the database of similar content items described above to determine the confidence
factor.  For example, assume that commercial C1 has started 48 seconds or earlier into the program, in only 5% of the previous episodes.  The confidence that the first commercial in the currently presented episode will occur 48 seconds into the episode
is 5%.  Similarly, if commercial C1 has started in 20% of the previous episodes 52 seconds or earlier into the program, the confidence factor may be 20%.  If commercial C1 has started in 40% of the previous episodes 57 seconds or earlier into the
program, the confidence factor may be 40%.  If commercial C1 has started in 50% of the previous episodes 60 seconds or earlier into the program, the confidence factor may be 50%.  And, if commercial C1 has started in 100% of the previous episodes 75
seconds into the program, the confidence factor may be 100%.
<br/><br/> Other factors may be used to determine confidence factors.  These include the typical (e.g., average) number of minutes of commercials relative to the amount of time allotted the program.  For example, a 30 minute time slot may comprise, on
average, 22 minutes of content and 8 minutes of commercials.  Longer time slots (e.g., a 1 hour time slot) may scale substantially linearly or linearly (e.g., 44 minutes of content and 16 minutes of commercials).  Confidence may also be based on the
typical length of each commercial, which may depend on the content type.  For example, the average length of a TV commercial may be 2 minutes, whereas the average length of a movie commercial may be 3 minutes.  Confidence may also depend on how far into
the program the user is and how many minutes of commercials have been presented thus far.  For example, assume that the current presentation time is 21 minutes (in a 30 minute time slot), and six minutes of commercials have been presented so far.  Based
on an average of 8 minutes of commercials per 30 minute time slot, 2 minutes of commercials may remain.  The terminal device may determine that the next expected commercial break is at the 25 minute mark with a high confidence (e.g., 50% or greater
confidence) because only a few minutes of the program remain and two of those minutes should be allocated to the commercial(s).
<br/><br/> In step 430, the terminal device may determine the next time for the remote control device to listen for data from the terminal device or other terminal devices.  In some aspects, the current presentation position, presentation speed, estimate
of the presentation position of the next trigger event, and the confidence factor may be used to make this determination, according to the following algorithm:
<br/><br/> .times..times..times..times..times..times..times..times..times..times..ti- mes..times..times..times..times..times..times..times..times.  ##EQU00001##
<br/><br/> As previously discussed, if the program is being presented at normal speed (e.g., 1.times.), the presentation speed factor may be 1.  Similarly, if the program is being presented at a higher speed (e.g., 2.times.), the presentation speed factor
may be higher (e.g., 2), and if the program is being presented at a slower speed (e.g., 0.5.times.), the presentation speed factor may be lower (e.g., 0.5).  As a result, the higher the presentation speed, the sooner the Time to Listen will be.  The
lower the presentation speed, the later the Time to Listen will be.  The following table provides example calculations of the Time to Listen for a remote control device where the presentation speed is 1 and the current presentation position is 30 seconds
into the program.  Each estimate for the trigger event time may comprise a different confidence factor.
<br/><br/> TABLE-US-00001 TABLE 1 Estimate of Time to Listen from Trigger current time/ Event from program (seconds) Calculation start time (seconds) 48 .times.  ##EQU00002## 17.1/47.1 52 .times.  ##EQU00003## 17.6/47.6 57 .times.  ##EQU00004## 16.2/46.2
60 .times.  ##EQU00005## 15.0/45.0
<br/><br/> One of these results may be used as the next time for the remote control device to listen for data.  For example, the second standard deviation where 5% of the commercials C1 have started (e.g., an estimate of 48 seconds for the next trigger
event) may be used.  In other words, the remote control device may be instructed to listen for data 17.1 seconds from the current time (or 47.1 seconds into the video program/time slot).  The first standard deviation or third standard deviation may
similarly be used.  Any of the other Times to Listen may be selected.  For example, the soonest Time to Listen (e.g., 15 seconds from the current time) may be used so that there will be a greater chance that the next time to listen will occur prior to
the start of the next commercial.  A Time to Listen may also be derived from more than one of the calculated Times to Listen.  For example, the terminal device may take the average of the four calculated Times to Listen, resulting in a Time to Listen of
16.5 seconds from the current time (or 46.5 seconds into the video program/time slot).
<br/><br/> In alternative embodiments, the terminal device may select the Time to Listen to correspond to the earliest start time of commercial C1 in the database or a predetermined time prior to the start time.  For example, the Time to Listen may be 43
seconds if the earliest start time for commercial C1 in all previous episodes is 43 seconds into the program or a predetermined time prior to the start time (e.g., 38 seconds into the program if the predetermined time is 5 seconds).
<br/><br/> In yet additional embodiments, the start time of a commercial for the video program currently being accessed may be known ahead of time.  For example, the commercial presentation times may be known in a pre-recorded (e.g., non-live) video
program.  In these embodiments, the terminal device may set the Time to Listen to the start time of the scheduled advertisement, a predetermined time prior to the start time (e.g., 1 second before), or a predetermined time after the start time (e.g., 2
seconds after).  If the presentation times for more than one commercial are known, the terminal device may set multiple Times to Listen, one for each of the known commercial times.  The terminal device may transmit the multiple Times to Listen to the
remote control device (e.g., as metadata) as will be described in further detail with respect to step 445 below.  In this example, the remote control device might only need to listen for data (or poll for data) from the terminal device just once for each
pre-recorded program.  The remote control device may still keep its clock synchronized with the terminal device and/or track presentation speed changes, as will be discussed in further detail in the examples below.
<br/><br/> In step 435, the terminal device may determine whether the determined Time to Listen is below a predetermined threshold, which may be, for example, anywhere between 1 and 3 seconds from the current time.  If the Time to Listen is below the
threshold (step 435: Y), the terminal device, in step 440, may transmit a command to the remote control device to remain in the active state because the trigger event is expected to occur very soon and/or to prevent the remote control device from
excessively switching between the active and standby states.  If, on the other hand, the Time to Listen is not below the threshold (step 435: N), the terminal device, in step 445, may transmit the Time to Listen determined in step 430 to the remote
control device.  Optionally, the terminal device may transmit, with the command in step 440 or Time to Listen in step 445, action(s) that the remote control device should take the next time it listens for data or enters the active state (e.g., illuminate
a backlight, display an advertisement, etc.).
<br/><br/> FIG. 5 illustrates an example method of listening for data from the terminal device at the determined next time to listen according to one or more illustrative aspects of the disclosure.  The steps illustrated in FIG. 5 may be performed by the
remote control device or other user device.  In step 505, the remote control device may receive the data identifying the next time for the remote control device to listen for data.  In step 510, the remote control device may optionally store the Time to
Listen data in memory.  In step 515, the remote control device may return to the standby state after storing the Time to Listen data (e.g., immediately after storage or a predetermined time thereafter, such as 2 seconds).
<br/><br/> In step 520, the remote control device may determine whether the next time to listen has been reached.  For example, the remote control device may compare the Time to Listen to an internal system clock in the remote control device.  If the Time
to Listen has not been reached, in step 525, the remote control device may determine whether the remote control device has been used, such as by a user/viewer.  The remote control device may repeat steps 520 and 525 (in any order) until the Time to
Listen has been reached or the remote control device has been used.  For example, the user may issue a command from the remote control device before the Time to Listen is reached (step 525: Y), or the Time to Listen may be reached before any user
activity occurs (step 520: Y).  In some embodiments, if the user presses a button that changes the presentation speed of the program (e.g., fast forward, rewind, skip, play, etc.), the terminal device may perform one or more of the steps illustrated in
FIG. 4 using the new presentation speed to recalculate the time for the remote control device to listen for data.
<br/><br/> In step 530, the remote control device may initiate the active state in response to the Time to Listen being reached or in response to user activity on the remote control.  As previously described, when the remote control device enters the
active state, the remote control device may listen for data from terminal devices (e.g., by turning on or otherwise activating a receiver or transceiver), illuminate backlights, or perform other actions.  Additionally or alternatively, the remote control
device may poll for information from the terminal device instead of passively listening for data during the active state (e.g., send a request for information to the terminal device and receive a message back).  Instead of immediately performing these
actions in response to entering the active state, the remote control device may optionally perform steps 535 and/or 540.
<br/><br/> In step 535, the remote control device may determine whether the expected trigger event occurred.  For example, if the trigger event is the start of a commercial, and the commercial has begun when the remote control device enters the active
state, the remote control device may determine that the expected trigger event occurred (step 535: Y).  In response to determining that the trigger event occurred, the remote control device, in step 540, may perform the actions noted above, including
illuminating backlights, listening for data, displaying information based on data received from terminal devices, etc. These actions may have previously been stored during the configuration step 305.
<br/><br/> Several exemplary actions that the remote control device may perform/enable will now be described.  One or more backlights on the remote control device, such as backlights for certain buttons, may be illuminated when a commercial begins to play. For example, one or more of the backlights for the fast forward button, the electronic program guide button, the number pad, volume button(s), the mute buttons, and/or the channel up/down button(s) may be illuminated.  Illuminating the fast forward
button allows the user to easily identify the fast forward button in order to advance through the commercial.  Illuminating the electronic program guide button, the number pad, and/or the channel up/down button(s) allows the user to easily browse or
navigate between channels during the commercial.  Illuminating the volume buttons or mute button allows the user to turn down the volume during the commercial (or up if the user is interested in the commercial).  Backlights for other buttons that the
user is not expected to use during commercials, such as the power button, the settings button, and/or the play button, might not be illuminated (or may be kept at a dimmer setting or use a different color than the buttons that the user is expected to
use).  A microphone used to receive voice commands from users may also be activated in step 540.
<br/><br/> The remote control device may have an integrated display or may be connected to a separate display, including a touchscreen display device.  During the active state, the remote control device may listen for data from terminal devices, and the
data may comprise information for rendering content on the display of the remote control device.  The content may comprise advertisement data that corresponds to or otherwise supplements the advertisement displayed by the terminal device (or other
playback device).  For example, if the commercial displayed by the terminal device is car commercial, supplemental information received by and displayed on the remote control device display may comprise a map of local car dealerships selling that brand
of car or a gift for test driving the brand of car (e.g., a $50 gift card if the user tests drive the car).
<br/><br/> If the trigger event corresponds to product placement during presentation of the video program, the remote control device may receive and display information corresponding to that product (e.g., a link to purchase the product, an advertisement
of the product, a coupon for the product, etc.).  For example, if soda brand A appears during a television show, the remote control device may receive, from a terminal device, information for rendering, on the display of the remote control device, a
coupon (or other discount) for purchasing soda brand A products.  Alternatively or additionally, the remote control device may display an interface for interacting with the advertisement presented by the terminal device if the advertisement and/or
terminal device is configured for interactivity (e.g., an interactive television, program, or advertisement).  For example, the interface may give the user the option to purchase the advertised product or service (e.g., a link or QR code to a website to
purchase the product, text boxes for receiving payment information, such as credit card information, text boxes to receive an email address, a button to sign up for a particular service, and the like).  The remote control device may also display a link
to an app in an application store or cause the link or other information related to the advertised product or service to be displayed in social media (e.g., <b><i>FACEBOOK,</i></b> TWITTER, etc.) if the user has tied his or her social media account to the service
described herein.
<br/><br/> If the trigger event corresponds to a calendar entry (e.g., if the user of the remote control device and a friend have scheduled to watch a video program together), the remote control device may display the calendar entry or a message
corresponding to the calendar entry.  An example message may state: "According to your calendar, you and Tommy plan to watch Movie A together in 5 minutes (7:00 PM)." Additionally or alternatively, the remote control device may interact with another
device, such as a camera at the user's front door.  For example, a live camera feed from the front door camera may be streamed to the remote control device and displayed on the remote control device when the friend is expected to arrive to watch the
video program with the user.
<br/><br/> The information displayed on the remote control device display need not supplement or correspond to the commercial displayed by the terminal device.  For example, the remote control device could display a second commercial that is unrelated to
the one displayed by the terminal device.  As another example, the remote control device could display an EPG, allowing the user to navigate the EPG on the remote control device without disrupting presentation of the commercial by the terminal device. 
The remote control device could also display content that supplements the video program, such as extra features content or webisode content, during presentation of the commercial or the video program.
<br/><br/> In some aspects, the terminal device and/or remote control device may interact with other devices in the home in the active state.  For example, if lights in a living room are connected to the same network as the terminal device and/or remote
control device, one of these devices could issue a command to the lights to illuminate or brighten during presentation of the commercial.  The terminal device and/or remote control device may interact with a video camera at the user's home (e.g., at the
front door).  For example, if a friend is expected to arrive at the user's home at the time of the trigger event, the video camera at the user's front door may transmit a live camera feed to be displayed on the remote control device.
<br/><br/> Instead of corresponding to the beginning of the commercial, the trigger event may correspond to the end of the commercial.  The end of the commercial may be predicted in a similar manner as that described above for predicting the start of the
commercial.  Alternatively, the end of the commercial may be predicted based on the predicted start time of the commercial and adding on the expected length of the commercial (e.g., 2 minutes, 3 minutes, etc.).  If the trigger event is the end of the
commercial, the opposite of the actions previously discussed may be performed.  For example, after the commercial ends, the backlights that were illuminated during the commercial may be turned off or dimmed.  Backlights for other buttons that the user
may be expected to use while watching the program (e.g., volume buttons, display settings buttons) may be illuminated or kept illuminated if already illuminated.  The information displayed on the remote control device display may be removed when the
commercial on the terminal device ends.  Alternatively, the information may be left on the remote control device or new information may be displayed on the remote control device when the program begins.  For example, in some instances, users may have
missed the commercial displayed by the terminal device, so the commercial (or a simpler version of the commercial, such as a web link, a banner advertisement, an image, etc.) may persist on the remote control device for a predetermined amount of time
after the commercial on the terminal device ends (e.g., thirty seconds).
<br/><br/> If the trigger event did not occur (step 535: N) and/or after performing the actions in step 540, the remote control device may return to step 325 and listen for data from the terminal device.  Listening may be performed before, during, or after
the actions (in step 540) are performed.  If, for example, the trigger event did not occur, the terminal device may perform one or more of the steps illustrated in FIG. 4 to recalculate the next time the remote control device should listen for data. 
Each time the terminal device recalculates the Time to Listen, the confidence factor may increase and the interval between the current time and the time to the next commercial may decrease.  This may cause the remote control device to listen for
information more frequently (e.g., every 5-10 seconds).  However, as previously described with respect to step 435, there may be a threshold (e.g., 1-3 seconds) that prevents the remote control device from transitioning between the active state and the
standby state too frequently.  Furthermore, incremental actions may be taken by the remote control device each time it listens for data and/or enters the active state.  For example, as the terminal device gets closer to displaying the commercial and the
remote control device starts to poll more frequently, the backlight could start off dim and slowly get brighter, peaking when the commercial actually starts (e.g., step 535: Y).  A similar dimming action could be performed if the trigger event is the end
of the commercial.  The slope of the brightening and/or dimming may also correlate to the confidence factor previously described.  For example, the backlight may transition more quickly from an off state to a certain level of brightness (e.g., 80%) if
the confidence is high and more slowly if the confidence is low.  On the other hand, if the trigger event did occur (step 535: Y), the terminal device may perform one or more of the steps illustrated in FIG. 4 to estimate a time for the next commercial
to be displayed and a corresponding time for the remote control device to listen for data.
<br/><br/> The various features described above are merely non-limiting examples, and can be rearranged, combined, subdivided, omitted, and/or altered in any desired manner.  For example, features of the computing device (including the remote control
device and the terminal device) described herein can be subdivided among multiple processors and computing devices.  The true scope of this patent should only be defined by the claims that follow.
<br/><br/><center><b>* * * * *</b></center>
<hr/>
   <center>
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09313440&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D804%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D17%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>
   <table>
   <tbody><tr><td align="center"><a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D804%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209313440"><img alt="[View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9313440&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D804%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209313440">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
     <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=804&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=16&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=804&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=804&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=18&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=803&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=805&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

   <a href="#top"><img alt="[Top]" border="0" src="/netaicon/PTO/top.gif" valign="middle"/></a>
   </td></tr>
   </tbody></table>
   <a name="bottom"></a>
   <a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
   </center>

</coma></body></html>