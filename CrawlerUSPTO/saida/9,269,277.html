<html><head>
<base target="_top"/>
<title>United States Patent: 9269277</title></head>
<!---BUF1=9269277
BUF7=2016
BUF8=33513
BUF9=/1/
BUF51=9
---->
<body bgcolor="#FFFFFF">
<a name="top"></a>
<center>
<img alt="[US Patent &amp; Trademark Office, Patent Full Text and Image Database]" src="/netaicon/PTO/patfthdr.gif"/>
<br/>
<table>
<tbody><tr><td align="center">
<a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
<a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
<a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
</td></tr>
<tr><td align="center">
   <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1207&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=24&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1207&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=25&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1207&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=26&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1206&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=25&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1208&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=25&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

<a href="#bottom"><img alt="[Bottom]" border="0" src="/netaicon/PTO/bottom.gif" valign="middle"/></a>
</td></tr>
   <tr><td align="center">
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1207%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D25%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209269277"><img alt="[
View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9269277&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1207%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D25%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209269277">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09269277&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D1207%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D25%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>

   </td></tr>
</tbody></table>
</center>
<table width="100%">
<tbody><tr><td align="left" width="50%"> </td>
<td align="right" valign="bottom" width="50%"><font size="-1">( <strong>1207</strong></font> <font size="-2">of</font> <strong><font size="-1">7895</font></strong> <font size="-1">)</font></td></tr></tbody></table>
<hr/>
   <table width="100%">
   <tbody><tr>	<td align="left" width="50%"><b>United States Patent </b></td>
   <td align="right" width="50%"><b>9,269,277</b></td>
   </tr>
     <tr><td align="left" width="50%"><b>
         Leflore
 </b>
     </td>
     <td align="right" width="50%"> <b>
     February 23, 2016
</b></td>
     </tr>
     </tbody></table>
       <hr/>
       <font size="+1">Vocal / instrumental training system and method of same
</font><br/>
       <br/><center><b>Abstract</b></center>
       <p> A vocal and/or instrumental training system can include a sound storage
     database having a plurality of model sound recordings, such as recordings
     of various wild game calls, stored therein. A user can select one of the
     model sound recordings to emulate, and provide audio input, such as the
     user's vocal performance of a wild game call, in an attempt to emulate
     the selected model sound recording. The audio input can be received by an
     audio input device, and recorded by a recording device. Audio
     characteristics, such as pitch, tone, timbre, cadence, rhythm, beat
     and/or amplitude, of the recorded audio input can be compared with the
     corresponding audio characteristics of the selected model sound
     recording. Results of the comparison can be graphically displayed on a
     sound graph.
</p>
       <hr/>
<table width="100%"> <tbody><tr> <th align="left" scope="row" valign="top" width="10%">Inventors:</th> <td align="left" width="90%">
 <b>Leflore; Bradley Wilson</b> (Morgan City, MS) </td> </tr>
<tr><th align="left" scope="row" valign="top" width="10%">Applicant: </th><td align="left" width="90%"> <table> <tbody><tr> <th align="center" scope="column">Name</th> <th align="center" scope="column">City</th> <th align="center" scope="column">State</th> <th align="center" scope="column">Country</th> <th align="center" scope="column">Type</th> </tr> <tr> <td> <b><br/>Leflore; Bradley Wilson</b> </td><td> <br/>Morgan City </td><td align="center"> <br/>MS </td><td align="center"> <br/>US </td> <td align="left"> </td> </tr> </tbody></table>
<!-- AANM>
~AANM Leflore; Bradley Wilson
~AACI Morgan City
~AAST MS
~AACO US
</AANM -->
</td></tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Family ID:
       </th><td align="left" width="90%">
       <b>50545717
</b></td></tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Appl. No.:
       </th><td align="left" width="90%">
       <b>13/950,922</b></td></tr>
       <tr><th align="left" scope="row" valign="top" width="10%">Filed:
       </th><td align="left" width="90%">
       <b>July 25, 2013</b></td></tr>
     </tbody></table>
<hr/> <center><b>Prior Publication Data</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Document Identifier</u></b></th><th align="center" scope="col"><b><u>Publication Date</u></b></th></tr><tr><td align="center"> </td><td align="center"> US 20140116231 A1</td><td align="center">May 1, 2014</td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table>
<hr/> <center><b>Related U.S. Patent Documents</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col" width="7%"></th><th scope="col"></th><th scope="col"></th> <th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Application Number</u></b></th><th align="center" scope="col"><b><u>Filing Date</u></b></th><th align="center" scope="col"><b><u>Patent Number</u></b></th><th align="center" scope="col"><b><u>Issue Date</u></b></th></tr><tr><td align="center"> </td><td align="center">61675586</td><td align="center">Jul 25, 2012</td><td align="center"></td><td align="center"></td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table><td< td=""></td<><td< td=""></td<>     <hr/>
<p> <table width="100%"> <tbody><tr><td align="left" valign="top" width="30%"><b>Current U.S. Class:</b></td> <td align="right" valign="top" width="70%"><b>1/1</b> </td></tr> 
       <tr><td align="left" valign="top" width="30%"><b>Current CPC Class: </b></td>
       <td align="right" valign="top" width="70%">G09B 15/023 (20130101)</td></tr>
         <tr><td align="left" valign="top" width="30%"><b>Current International Class: </b></td>
         <td align="right" valign="top" width="70%">G10G 3/04 (20060101); G10L 17/00 (20130101); G10H 7/00 (20060101); G09B 15/02 (20060101)</td></tr>
       <tr><td align="left" valign="top" width="30%"><b>Field of Search: </b></td>
       <td align="right" valign="top" width="70%">
       
 ;84/466
       </td></tr>
     </tbody></table>
</p><hr/><center><b>References Cited  <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2Fsearch-adv.htm&amp;r=0&amp;f=S&amp;l=50&amp;d=PALL&amp;Query=ref/9269277">[Referenced By]</a></b></center>       <hr/>
       <center><b>U.S. Patent Documents</b></center>
<table width="100%"> <tbody><tr><th scope="col" width="33%"></th> <th scope="col" width="33%"></th> <th scope="col" width="34%"></th></tr> <tr> <td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5287789">5287789</a></td><td align="left">
February 1994</td><td align="left">
Zimmerman</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5906494">5906494</a></td><td align="left">
May 1999</td><td align="left">
Ogawa et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5951302">5951302</a></td><td align="left">
September 1999</td><td align="left">
Decker, Jr.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6417435">6417435</a></td><td align="left">
July 2002</td><td align="left">
Chantzis et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7062220">7062220</a></td><td align="left">
June 2006</td><td align="left">
Haynes et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7164076">7164076</a></td><td align="left">
January 2007</td><td align="left">
McHale et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7271329">7271329</a></td><td align="left">
September 2007</td><td align="left">
Franzblau</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7705229">7705229</a></td><td align="left">
April 2010</td><td align="left">
Bancroft et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8138409">8138409</a></td><td align="left">
March 2012</td><td align="left">
Brennan</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20040107104&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2004/0107104</a></td><td align="left">
June 2004</td><td align="left">
Schaphorst</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20040194610&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2004/0194610</a></td><td align="left">
October 2004</td><td align="left">
Davis</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060009979&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0009979</a></td><td align="left">
January 2006</td><td align="left">
McHale et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060150803&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0150803</a></td><td align="left">
July 2006</td><td align="left">
Taub</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080156171&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0156171</a></td><td align="left">
July 2008</td><td align="left">
Guldi</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090056525&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0056525</a></td><td align="left">
March 2009</td><td align="left">
Oppenheimber</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
       <center><b>Foreign Patent Documents</b></center>
<table width="100%"> <tbody><tr><td></td><th scope="col"></th> <td></td><th scope="col"></th> <td></td><th scope="col"></th></tr> <tr> <td align="left">
</td><td align="left">WO2010083563</td><td></td><td align="left">
Jul 2010</td><td></td><td align="left">
WO</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
       <i>Primary Examiner:</i> Uhlir; Christopher
<br/>
       <i>Attorney, Agent or Firm:</i> <coma><coma>Ashley Law Firm P.C.
Ashley, Jr.; Stephen S.
<br/>
       <hr/>
       <center><b><i>Parent Case Text</i></b></center>
       <hr/>
       <br/><br/>CROSS-REFERENCE TO RELATED APPLICATIONS
<br/><br/> This application claims priority to U.S. Provisional Patent Application
     No. 61/675,586, filed Jul. 25, 2012, which is incorporated herein by
     reference.
         <hr/>
<center><b><i>Claims</i></b></center> <hr/> <br/><br/>What is claimed is: <br/><br/> 1.  A wild game call training system comprising: (a) a processor device comprising a central processing unit;  (b) a software program operatively connected to the central
processing unit, whereby the central processing unit carries out instructions of the program;  (c) a sound storage database for storing a plurality of model sound files processable by the processor device, the model sound files comprising recordings of
wild game calls;  (d) input means operatively connected to the processor device, wherein the input means receives and stores an audio input from a user that is intended to emulate at least one of the plurality of model sound files;  and (e) wherein the
program instructs the central processing unit to allow a user to select one of the plurality of model sounds files, and instructs the central processing unit to perform an analysis comparing audio characteristics of the audio input from the user with
audio characteristics of the selected model sound file.
<br/><br/> 2.  The system according to claim 1, wherein the processor device comprises a computer.
<br/><br/> 3.  The system according to claim 1, wherein the processor device comprises a device selected from the group consisting of a personal computer and a smartphone.
<br/><br/> 4.  The system according to claim 1, further comprising means for connecting the processor device to the Internet, and further wherein the program allows for sound files to be uploaded via the Internet into the sound storage database.
<br/><br/> 5.  The system according to claim 1, wherein the audio characteristics of the audio input from the user and the audio characteristics of the selected model sound file are selected from the group consisting of pitch, tone, timbre, cadence,
rhythm, beat, and amplitude.
<br/><br/> 6.  The system according to claim 1, wherein the program instructs the processor device to graphically display the analysis comparing the audio characteristics of the audio input from the user with the audio characteristics of the selected model
sound file on a sound graph.
<br/><br/> 7.  The system according to claim 1, further comprising: (a) an audio unit operatively connected to the central processing unit, whereby the audio unit can transmit sound audible to the user;  (b) recording means operatively connected to the
processor device for recording the audio input from the user, the recording means comprising a selectable recording option, wherein selection of the recording option by the user initiates recording of the audio input received by the input means, and the
recorded audio is stored in a recording storage database comprising a plurality of recorded performance files;  and (c) playback means operatively connected to the processor device for playing a selected one of the plurality of recorded performance files
and a selected one of the plurality of model sound files through the audio unit.
<br/><br/> 8.  The system according to claim 7, wherein the playback means comprises a playback option, wherein selection of the playback option initiates simultaneous playing of the selected one of the plurality of recorded performance files and a
selected one of the plurality of model sound files through the audio unit.
<br/><br/> 9.  The system according to claim 7, wherein the audio unit comprises at least one audio speaker.
<br/><br/> 10.  The system according to claim 7, wherein the input means comprises a microphone.
<br/><br/> 11.  A method of wild game call training comprising: (a) providing a sound storage database comprising a plurality of model sound recordings, wherein the plurality of model sound recordings comprise recordings of wild game calls;  (b) providing
an input device for receiving audio input from a person;  (c) providing a recording device for recording audio input received by the input device;  (d) selecting one of the plurality of model sound recordings to emulate;  (e) providing audio input into
the input device that is intended to emulate the selected model sound recording;  (f) recording the audio input;  and (g) comparing audio characteristics of the recorded audio input with corresponding audio characteristics of the selected model sound
recording.
<br/><br/> 12.  The method according to claim 11, further comprising the step of assigning an alphanumeric score to the recorded audio input based on the comparing of the audio characteristics of the recorded audio input with the audio characteristics of
the selected model sound recording.
<br/><br/> 13.  The method according to claim 11, further comprising the step of graphically displaying the audio characteristics of the recorded audio input in comparison with the corresponding audio characteristics of the selected model sound recording.
<br/><br/> 14.  The method according to claim 11, wherein the step of comparing audio characteristics of the recorded audio input with corresponding audio characteristics of the selected model sound recording comprises comparing audio characteristics
selected from the group consisting of pitch, tone, timbre, cadence, rhythm, beat, and amplitude.
<br/><br/> 15.  The method according to claim 11, further comprising providing an Internet website on which users can upload audio files into the sound storage database.
<br/><br/> 16.  The method according to claim 15, wherein users can download model sound recordings from the sound storage database, and further comprising the step of charging users a fee for downloading model sound recordings from the sound storage
database.
<br/><br/> 17.  The method according to claim 15, further comprising the step of storing recorded audio inputs and allowing website users to listen to a selected audio input and enter ratings data on the website regarding the selected audio input, and
assigning a score to the selected audio input based on the ratings of the website users.
<br/><br/> 18.  The method according to claim 11, wherein the step of providing audio input into the input device comprises a person vocally performing a wild game call in an attempt to emulate the selected model sound recording. <hr/>
<center><b><i>Description</i></b></center> <hr/> <br/><br/>TECHNICAL FIELD AND BACKGROUND OF THE INVENTION
<br/><br/> The present invention relates to a system for developing and/or improving a person's vocal or musical abilities, such as in singing, game calling and/or playing musical instruments.  One embodiment of the invention is a vocal training system
comprised of a software program that can be used in smartphone based applications and/or downloadable software for a PC and/or Mac computer that helps users replicate a desired vocal sound, such as a wild game call.
<br/><br/> Wild game hunting has been a popular recreational activity in the United States for generations.  Many hunters utilize the tactic of game calling, in which the hunter uses his voice to try to mimic the mating, gathering and/or feeding calls of
the desired game in an attempt to attract the game to within firing range of the hunter.  However, game calling is not easy, and typically requires a great deal of practice and training to become proficient in accurately reproducing a particular game
call.
<br/><br/>SUMMARY OF THE INVENTION
<br/><br/> Therefore, one object of the present invention is to provide a system for developing a person's ability to accurately replicate a desired sound, such as wild game calls, or other vocal performances.  These and other objects of the invention can
be achieved in the preferred embodiments of the invention described below.
<br/><br/> One embodiment of the invention comprises a system that helps users accurately replicate a desired sound comprising a software program that can be used in smartphone based applications and/or downloadable software for a PC and/or Mac computer. 
The system gives the user the ability to see their sound on a sound graph in comparison to the desired original sound from the software or application or a recorded sound stored on the PC or Mac.  The smartphone or computer shows both sounds on the sound
graph to help the user improve his performance showing where the user's performance was accurate and the user's mistakes in the performance.  The software and application also gives the user a number grade from 0-100% on how well they replicated the
original desired sound.  The user also has the ability to listen to both sounds at the same time to determine where mistakes were made.  The user can share his grades through social media, and challenge others to beat his score.  The user can record
sounds he desires to emulate, and save them to a PC, Mac or smartphone application for future tutorial sessions.
<br/><br/> According to another embodiment of the invention, a vocal and instrumental training system can include a processor device comprising a central processing unit, and a software program operatively connected to the central processing unit, whereby
the central processing unit carries out instructions of the program.  A sound storage database stores a plurality of model sound files processable by the processor device, and a recording storage database stores a plurality of recorded performance files
processable by the processor device.  The program instructs the central processing unit to allow a user to select one of the plurality of model sounds files and one of the plurality of recorded performance files, and instructs the central processing unit
to perform an analysis comparing audio characteristics of the selected recorded performance file with the audio characteristics of the selected model sound file.
<br/><br/> According to another embodiment of the invention, the processor device comprises a computer.
<br/><br/> According to another embodiment of the invention, the processor device can be a personal computer or a smartphone.
<br/><br/> According to another embodiment of the invention, the plurality of model sound files can include recordings of wild game calls, recordings of vocal performances and/or recordings of musical performances.
<br/><br/> According to another embodiment of the invention, the training system includes means for connecting the processor device to the Internet, and the program allows for sound files to be uploaded via the Internet into the model sounds database.
<br/><br/> According to another embodiment of the invention, the program instructs the central processing unit to perform an analysis comparing audio characteristics such as pitch, tone, timbre, cadence, rhythm, beat, and/or amplitude of the selected
recorded performance file with the corresponding audio characteristics of the selected model sound file.
<br/><br/> According to another embodiment of the invention, the program instructs the processor device to graphically display the analysis comparing the audio characteristics of the selected recorded performance file with the audio characteristics of the
selected model sound file on a sound graph.
<br/><br/> According to another embodiment of the invention, the training system includes an audio unit operatively connected to the central processing unit, so that the audio unit can transmit sound audible to a user, and input means operatively connected
to the processor drive and adapted to receive audio input from the user.  Recording means can be operatively connected to the processor drive for recording audio input from the user.  The recording means includes a selectable recording option, in which
selection of the recording option by the user initiates recording of the audio received by the input means.  The recorded audio is stored in the recording storage database as one of the plurality of recorded performance files.  Playback means can be
operatively connected to the processor device to play a selected recorded performance file and a selected model sound file through the audio unit.
<br/><br/> According to another embodiment of the invention, the playback means includes a playback option, in which selection of the playback option initiates simultaneous playing of the selected recorded performance file and a selected model sound file
through the audio unit.
<br/><br/> According to another embodiment of the invention, the audio unit comprises at least one audio speaker.
<br/><br/> According to another embodiment of the invention, the input means comprises a microphone.
<br/><br/> According to another embodiment of the invention, a method of vocal or instrumental training comprises providing a sound storage database comprising a plurality of model sound recordings, and providing an input device for receiving audio input
from a person.  A recording device is provided for recording audio input received by the input device, and one of the model sound recordings is selected to emulate.  Audio input is provided into the input device that is intended to emulate the selected
model sound recording.  The audio input is recorded, and the audio characteristics of the recorded audio input is compared with corresponding audio characteristics of the selected model sound recording.
<br/><br/> According to another embodiment of the invention, an alphanumeric score is assigned to the recorded audio input based on the comparison of the audio characteristics of the recorded audio input with the audio characteristics of the selected model
sound recording.
<br/><br/> According to another embodiment of the invention, the audio characteristics of the recorded audio input in comparison with the corresponding audio characteristics of the selected model sound recording are graphically displayed.
<br/><br/> According to another embodiment of the invention, the pitch, tone, timbre, cadence, rhythm, beat, and/or amplitude of the recorded audio input are compared with the corresponding audio characteristics of the selected model sound recording.
<br/><br/> According to another embodiment of the invention, an Internet website can be provided on which users can upload audio files into the sound storage database.
<br/><br/> According to another embodiment of the invention, users of the Internet website can download model sound recordings from the sound storage database.  The users can be charged a monetary fee for downloading the model sound recordings from the
sound storage database.
<br/><br/> According to another embodiment of the invention, recorded audio inputs are stored in a database that can be accessed by website users.  The users can listen to a selected audio input, and enter ratings data on the website regarding the selected
audio input.  A score can be assigned to the selected audio input based on the ratings of the website users.
<br/><br/> According to another embodiment of the invention, the model sound recordings are recordings of wild game calls, recordings of vocal performances and/or recordings of musical performances.
<br/><br/> According to another embodiment of the invention, the model sound recordings are recordings of wild game calls, and the audio input comprises a person vocally performing a wild game call in an attempt to emulate a selected model sound recording
of a wild game call. <br/><br/>BRIEF DESCRIPTION OF THE DRAWINGS
<br/><br/> FIG. 1 is a schematic view of a vocal/instrumental training system according to a preferred embodiment of the invention;
<br/><br/> FIG. 2 is a schematic view of a sound graph of the system of FIG. 1; and
<br/><br/> FIG. 3 is a schematic view of a website page according to another embodiment of the invention.
<br/><br/>DESCRIPTION OF THE PREFERRED EMBODIMENTS OF THE INVENTION AND BEST MODE
<br/><br/> A vocal/instrumental training system according to a preferred embodiment of the invention comprises a software program 10 that can be used in smartphone based applications and/or is downloadable software for a PC and/or Mac computer.  As shown
in FIG. 1, the program 10 includes a sound database 12 on which is stored a plurality of recorded "model" sounds 14 for users to attempt to replicate.  The model sounds 14 can be wild game calls, vocal performances, instrumental performances, and/or any
other recorded sounds that users wish to emulate.
<br/><br/> A user 100 can select a particular model sound 14, such as a particular wild game call, which the user aspires to replicate.  The system 10 includes play back and recording means.  The playback means can be comprised of a play back option 24,
which when selected plays the selected model sound 14.
<br/><br/> The system includes input means, such as a microphone 30, for receiving audio input from the user 100, as shown in FIG. 1.  After listening to the particular model sound 14 a desired number of times, the user 100 can perform his own version of
the model sound 14, which is received into the system 10 via the microphone 30, as shown in FIG. 1, and recorded by the recording means.  The recording means can be comprised of a recording option 22, which when selected records the sounds received by
the microphone 30 from the user, and stores the recording in a recording database 16.  Multiple recordings can be stored in the recording database 16, and retrieved to be played again when desired by the user 100.
<br/><br/> The system 10 can provide feedback to the user regarding the characteristics of the user's performance, such as the pitch, tone, timbre, cadence, rhythm, beat, and/or amplitude of the performance, and can compare these audio characteristics of
the user's performance to those of the selected model sound 14, and visually displays the comparison of the two sounds on a sound graph 40, as shown in FIG. 2.  The sound graph can be displayed on the user's smartphone or computer.  The sound graph 40
helps the user 100 improve his performance by showing where and how the user's performance accurately replicated the selected model sound, and where and how the user's performance deviated from the model sound.  The program can gives the user 100 a
number grade from 0-100% relating to how well the user replicated the selected model sound.  Also, both the recording of the user's performance and the selected model sound can be played back simultaneously to aid the user 100 in determining where
mistakes were made.  The user 100 can share his grades through social media, and challenge others to beat his score.
<br/><br/> In an embodiment of the invention, the recording means can be voice-activated, and records the user's sound with a pad of 0.5 seconds before and after the end of the sound.  A sample frequency of 8000 Hertz is used.  Multiple attempts by the
user 100 to perform a particular sound or musical piece can be recorded, and the program 10 can use the multiple samples to compute a model, or a weighted average for analysis.  The waveform of a sound recording can be converted to a sequence of feature
vectors using a frame-based analysis.  Features can be computed every forty samples (40/8000=5.0 msec) using 120 samples (15 msec) of audio data to compute the features.  The audio data in each analysis window can be converted to a frequency domain
representation using a 256 point zero-stuffed fast Fourier transform (FFT) with a rectangular window.  Each sound example (ideal set) can be stored as a matrix where each row represents a frame number, and each column represents a feature vector.  Ideal
examples are first aligned together using an algorithm known as dynamic time warping (a variant of dynamic programming).  The initial example is taken as a reference, and the remaining examples are stretched or compressed in time to match the duration of
the initial example.  The spectrum is then computed frame by frame and the result for each example is saved in a matrix.  A user's audio input is compared to the selected model sound recording by correlating the time and frequency representation of the
test signal with the ideal examples.  The test sound can be aligned with the average of the ideal examples using dynamic programming.  The absolute value of the statistical correlation between each feature vector of the test signal and each feature
vector of the ideal signal is computed.  The mean and median of the rawscore can be computed over all input frames of data.  The rawscore calculated above does not extend over the range [0,1].  Rather, it is between [p,q] where p&gt;0 and q&lt;1.  So the
rawscore is remapped into [0,1] using a mapping function.  The procedure used to compute the final rawscore computes two numbers for two extreme cases: (1) using a noise signal instead of test signal; and (2) using several ideal signals instead of test
signals.  A linear mapping can be defined based on the estimates that maps scores onto the range [0,1].  score(1)=min(max((mean(rawscore1)-p1)/(q1-p1),0),1) score(2)=min(max((mean(rawscore2)-p2)/(q2-p2),0),1) The reason for using min(max()) is to make
sure the final score is between 0 and 1.  Sometimes the raw score computed for the test signal can be worse than the raw score for noise or better than the raw score for ideal case.  Postprocess the Score: final_score=mean(score(1), score(2)) where
score(1) and score(2) are the respective frame-based scores.  The final score is displayed as user feedback.
<br/><br/> In a preferred embodiment of the invention, the system 10 can be used by hunters to improve their wild game calling skills.  For example, a hunter may wish to improve his duck calling ability.  The program 10 includes model samples of various
duck call sounds 14 recorded from professional callers.  The user 100 selects a particular model sample 14, and listens to the model duck call sound as many times as desired.  Then the user 100 can press the record button 22, and record his own
performance of the duck call in an attempt to replicate the model sample to which he has been listening.  The program 10 gives the user 100 a grade based on how his performance matched the model sample sound 14, and displays to the user on the sound
graph 40 where mistakes were made in tone, pitch, beat, cadence, etc. Also, the user can repeatedly listen to the model sample sound 14 and his recorded performance at the same time for comparison.
<br/><br/> The system 10 can include a plurality of model sounds 14 that are pre-installed on the software.  In addition, the user himself can download model sounds into the system 10, via the user's smartphone or computer.  The user can record sounds he
desires to emulate, and save them to his computer or smartphone application for future tutorial sessions.
<br/><br/> The system 10 can include an Internet website accessible to the general public, on which model sounds can be downloaded using audio files, such as way or MP3, as shown in FIG. 3.  In addition, website users can upload their own recordings, which
can be downloaded by other users.  As such, the system 10 can facilitate a community of multiple users, who can upload model sounds for others to download and use.
<br/><br/> The community of users can communicate with each other, and make requests for particular model sound samples.  For example, a particular user may be unfamiliar with the call of a particular species of wild game that he intends to hunt.  The user
can communicate a request on the website for other users who have experience calling the particular species to record and upload model samples of the call for use in training.  Users can rate the model sample sounds that have been uploaded to provide
guidance to users when determining which uploaded model samples to use for training.  In addition, the program 10 can maintain a count of the number of times a particular model sample sound has been downloaded by users, and includes features for sharing
to social networking Internet sites, such as <b><i>FACEBOOK</i></b> and TWITTER.  Also, there can be an "AMERICAN IDOL" style talent contest, in which users vote for various accolades, such as the best model sample sound for a particular species of game call, and the
user who has contributed the best overall collection of model sound samples.  Top users can win prizes for the sounds they have uploaded.
<br/><br/> In another preferred embodiment of the invention, the system 10 comprises a smartphone application or computer program having minimal or no pre-existing sound samples installed thereon.  Users are allowed to download this version on their
smartphone or computer for free, and are charged a particular fee for downloading the sample sounds of their choice per each sample downloaded.  Users can purchase sound samples from a web store having a library of stored samples.  Users can upgrade to a
fully functional version by paying an upgrade fee.
<br/><br/> While a preferred embodiment of the invention is described above as being used to develop wild game calling skills, the invention is not so limited.  For example, in another embodiment of the invention, the training system 10 can comprise a
software application that aids music teachers in instructing their students to play musical instruments.  In this embodiment, a music teacher can download a model sample of instrumental music to be learned by the teacher's student, and the corresponding
sheet music for the particular piece of music being taught can be displayed on a pdf file on the student's computer or smartphone.  The student can listen to the sample of instrumental music while reading the sheet music.  The student can then attempt to
replicate the music they have seen and heard, and the system 10 provides a sound graph comparison of the teacher's model sample and the student's recorded performance.
<br/><br/> In another embodiment of the invention, a community of musical instrument players sharing the same interest in the same instrument can challenge each other by uploading their own sound samples, and challenge others to try to replicate the
quality of the particular sound sample.  For example, a guitarist can record himself playing a particular piece of music, upload the recording, and challenge others to replicate his recording.  Vocalists can do the same with regard to samples of their
singing.
<br/><br/> In another embodiment of the invention, users can try to replicate lines from famous movies, television shows and plays.  In yet another embodiment of the invention, users can upload various random sound recordings, and other users are allowed
to try to replicate them.  A user can record a sound, and challenge other users of his choosing to try to replicate the recorded sound and guess what the sound is.
<br/><br/> Another embodiment of the invention comprises a smartphone application for use while driving a vehicle.  The application compares the vocals emanating from the smartphone generated radio to the vocal performance of the user who is singing along. The user sings the song they are hearing, and the application scores them based on the voice comparisons of the user and the vocals in the original song.  Records of best scores for each song that is used in the application are recorded and maintained.
<br/><br/> A vocal/instrumental training system and method of same are described above.  Various changes can be made to the invention without departing from its scope.  The above description of preferred embodiments and best mode of the invention are
provided for the purpose of illustration only and not limitation--the invention being defined by the claims and equivalents thereof.
<br/><br/><center><b>* * * * *</b></center>
<hr/>
   <center>
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09269277&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D1207%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D25%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>
   <table>
   <tbody><tr><td align="center"><a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1207%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D25%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209269277"><img alt="[View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9269277&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1207%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D25%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209269277">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
     <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1207&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=24&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1207&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=25&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1207&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=26&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1206&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=25&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1208&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=25&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

   <a href="#top"><img alt="[Top]" border="0" src="/netaicon/PTO/top.gif" valign="middle"/></a>
   </td></tr>
   </tbody></table>
   <a name="bottom"></a>
   <a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
   </center>

</coma></coma></body></html>