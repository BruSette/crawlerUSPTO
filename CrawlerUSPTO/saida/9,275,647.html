<html><head>
<base target="_top"/>
<title>United States Patent: 9275647</title></head>
<!---BUF1=9275647
BUF7=2016
BUF8=89944
BUF9=/1/
BUF51=9
---->
<body bgcolor="#FFFFFF">
<a name="top"></a>
<center>
<img alt="[US Patent &amp; Trademark Office, Patent Full Text and Image Database]" src="/netaicon/PTO/patfthdr.gif"/>
<br/>
<table>
<tbody><tr><td align="center">
<a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
<a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
<a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
</td></tr>
<tr><td align="center">
   <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1142&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=22&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1142&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=23&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1142&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=24&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1141&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=23&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1143&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=23&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

<a href="#bottom"><img alt="[Bottom]" border="0" src="/netaicon/PTO/bottom.gif" valign="middle"/></a>
</td></tr>
   <tr><td align="center">
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1142%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D23%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209275647"><img alt="[
View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9275647&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1142%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D23%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209275647">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09275647&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D1142%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D23%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>

   </td></tr>
</tbody></table>
</center>
<table width="100%">
<tbody><tr><td align="left" width="50%"> </td>
<td align="right" valign="bottom" width="50%"><font size="-1">( <strong>1142</strong></font> <font size="-2">of</font> <strong><font size="-1">7895</font></strong> <font size="-1">)</font></td></tr></tbody></table>
<hr/>
   <table width="100%">
   <tbody><tr>	<td align="left" width="50%"><b>United States Patent </b></td>
   <td align="right" width="50%"><b>9,275,647</b></td>
   </tr>
     <tr><td align="left" width="50%"><b>
         Papakipos
,   et al.</b>
     </td>
     <td align="right" width="50%"> <b>
     March 1, 2016
</b></td>
     </tr>
     </tbody></table>
       <hr/>
       <font size="+1">Periodic ambient waveform analysis for enhanced social functions
</font><br/>
       <br/><center><b>Abstract</b></center>
       <p> In particular embodiments, one or more computer-readable non-transitory
     storage media embody software that is operable when executed to receive
     an audio waveform fingerprint and a client-determined location from a
     client device. The received audio waveform fingerprint may be compared to
     a database of stored audio waveform fingerprints, each stored audio
     waveform fingerprint associated with an object in an object database. One
     or more matching audio waveform fingerprints may be found from a
     comparison set of audio waveform fingerprints obtained from the audio
     waveform fingerprint database. Location information associated with a
     location of the client device may be determined, and the location
     information may be sent to the client device. The client device may be
     operable to update the client-determined location based at least in part
     on the location information.
</p>
       <hr/>
<table width="100%"> <tbody><tr> <th align="left" scope="row" valign="top" width="10%">Inventors:</th> <td align="left" width="90%">
 <b>Papakipos; Matthew Nicholas</b> (Palo Alto, CA)<b>, Garcia; David Harry</b> (Sunnyvale, CA) </td> </tr>
<tr><th align="left" scope="row" valign="top" width="10%">Applicant: </th><td align="left" width="90%"> <table> <tbody><tr> <th align="center" scope="column">Name</th> <th align="center" scope="column">City</th> <th align="center" scope="column">State</th> <th align="center" scope="column">Country</th> <th align="center" scope="column">Type</th> </tr> <tr> <td> <b><br/><b><i>Facebook,</i></b> Inc.</b> </td><td> <br/>Menlo Park </td><td align="center"> <br/>CA </td><td align="center"> <br/>US </td> <td align="left"> </td>
</tr> </tbody></table>
<!-- AANM>
~AANM <B><I>Facebook,</I></B> Inc.
~AACI Menlo Park
~AAST CA
~AACO US
</AANM -->
</td></tr>
<tr> <th align="left" scope="row" valign="top" width="10%">Assignee:</th>
<td align="left" width="90%">

<b><a href="#h2" name="h3"></a><a href="#h4"></a><b><i>Facebook,</i></b> Inc.</b>
 (Menlo Park, 
CA)
<br/>

</td>
</tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Family ID:
       </th><td align="left" width="90%">
       <b>47713258
</b></td></tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Appl. No.:
       </th><td align="left" width="90%">
       <b>14/256,787</b></td></tr>
       <tr><th align="left" scope="row" valign="top" width="10%">Filed:
       </th><td align="left" width="90%">
       <b>April 18, 2014</b></td></tr>
     </tbody></table>
<hr/> <center><b>Prior Publication Data</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Document Identifier</u></b></th><th align="center" scope="col"><b><u>Publication Date</u></b></th></tr><tr><td align="center"> </td><td align="center"> US 20140358555 A1</td><td align="center">Dec 4, 2014</td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table>
<hr/> <center><b>Related U.S. Patent Documents</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col" width="7%"></th><th scope="col"></th><th scope="col"></th> <th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Application Number</u></b></th><th align="center" scope="col"><b><u>Filing Date</u></b></th><th align="center" scope="col"><b><u>Patent Number</u></b></th><th align="center" scope="col"><b><u>Issue Date</u></b></th></tr><tr><td align="center"> </td><td align="center">13211182</td><td align="center">Aug 16, 2011</td><td align="center">8706499</td><td align="center"></td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table><td< td=""></td<><td< td=""></td<>     <hr/>
<p> <table width="100%"> <tbody><tr><td align="left" valign="top" width="30%"><b>Current U.S. Class:</b></td> <td align="right" valign="top" width="70%"><b>1/1</b> </td></tr> 
       <tr><td align="left" valign="top" width="30%"><b>Current CPC Class: </b></td>
       <td align="right" valign="top" width="70%">G10L 25/54 (20130101); H04L 67/42 (20130101); G10L 19/018 (20130101)</td></tr>
         <tr><td align="left" valign="top" width="30%"><b>Current International Class: </b></td>
         <td align="right" valign="top" width="70%">G10L 15/00 (20130101); G06F 7/00 (20060101); G06F 17/30 (20060101); G06F 3/00 (20060101); G10L 19/018 (20130101); G10L 25/54 (20130101); G06F 11/30 (20060101); G10L 25/00 (20130101); H04L 29/06 (20060101); G10L 15/26 (20060101); G10L 17/00 (20130101); G10L 21/00 (20130101)</td></tr>
       <tr><td align="left" valign="top" width="30%"><b>Field of Search: </b></td>
       <td align="right" valign="top" width="70%">
       
















 ;704/243,249,273,235-236,275,246 ;707/751,724,748,769-770,722,739 ;701/410,469,31.5,455 ;715/745
       </td></tr>
     </tbody></table>
</p><hr/><center><b>References Cited  <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2Fsearch-adv.htm&amp;r=0&amp;f=S&amp;l=50&amp;d=PALL&amp;Query=ref/9275647">[Referenced By]</a></b></center>       <hr/>
       <center><b>U.S. Patent Documents</b></center>
<table width="100%"> <tbody><tr><th scope="col" width="33%"></th> <th scope="col" width="33%"></th> <th scope="col" width="34%"></th></tr> <tr> <td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6012027">6012027</a></td><td align="left">
January 2000</td><td align="left">
Bossemeyer, Jr.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6201176">6201176</a></td><td align="left">
March 2001</td><td align="left">
Yourlo</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7886024">7886024</a></td><td align="left">
February 2011</td><td align="left">
Kelly et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7930197">7930197</a></td><td align="left">
April 2011</td><td align="left">
Ozzie et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8117193">8117193</a></td><td align="left">
February 2012</td><td align="left">
Svendsen et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8150844">8150844</a></td><td align="left">
April 2012</td><td align="left">
Redstone et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8204952">8204952</a></td><td align="left">
June 2012</td><td align="left">
Stremel et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8244848">8244848</a></td><td align="left">
August 2012</td><td align="left">
Narayanan et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8260315">8260315</a></td><td align="left">
September 2012</td><td align="left">
Fortescu et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8284931">8284931</a></td><td align="left">
October 2012</td><td align="left">
Pare et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030061490&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0061490</a></td><td align="left">
March 2003</td><td align="left">
Abajian</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030182119&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0182119</a></td><td align="left">
September 2003</td><td align="left">
Junqua et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070124292&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0124292</a></td><td align="left">
May 2007</td><td align="left">
Kirshenbaum et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070185718&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0185718</a></td><td align="left">
August 2007</td><td align="left">
Di Mambro et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070280436&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0280436</a></td><td align="left">
December 2007</td><td align="left">
Rajakumar</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070282605&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0282605</a></td><td align="left">
December 2007</td><td align="left">
Rajakumar</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080312924&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0312924</a></td><td align="left">
December 2008</td><td align="left">
De Los Reyes et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090105950&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0105950</a></td><td align="left">
April 2009</td><td align="left">
Arteaga et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090144392&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0144392</a></td><td align="left">
June 2009</td><td align="left">
Wang et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20100049852&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2010/0049852</a></td><td align="left">
February 2010</td><td align="left">
Whitnah et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20100205174&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2010/0205174</a></td><td align="left">
August 2010</td><td align="left">
Jiang et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110072020&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0072020</a></td><td align="left">
March 2011</td><td align="left">
Ngo et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110137920&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0137920</a></td><td align="left">
June 2011</td><td align="left">
Cohen et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110211813&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0211813</a></td><td align="left">
September 2011</td><td align="left">
Marks</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110221671&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0221671</a></td><td align="left">
September 2011</td><td align="left">
King et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120047147&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0047147</a></td><td align="left">
February 2012</td><td align="left">
Redstone et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120158751&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0158751</a></td><td align="left">
June 2012</td><td align="left">
Tseng</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120166435&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0166435</a></td><td align="left">
June 2012</td><td align="left">
Graham et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120166964&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0166964</a></td><td align="left">
June 2012</td><td align="left">
Tseng</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120197709&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0197709</a></td><td align="left">
August 2012</td><td align="left">
Kendall et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120233158&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0233158</a></td><td align="left">
September 2012</td><td align="left">
Braginsky et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120233238&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0233238</a></td><td align="left">
September 2012</td><td align="left">
Braginsky et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120323763&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0323763</a></td><td align="left">
December 2012</td><td align="left">
Michael</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20120323859&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2012/0323859</a></td><td align="left">
December 2012</td><td align="left">
Yasa et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20130018657&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2013/0018657</a></td><td align="left">
January 2013</td><td align="left">
Di Mambro et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20130023284&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2013/0023284</a></td><td align="left">
January 2013</td><td align="left">
Stanger</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20130159106&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2013/0159106</a></td><td align="left">
June 2013</td><td align="left">
Gross</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20130159116&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2013/0159116</a></td><td align="left">
June 2013</td><td align="left">
Gross</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20130179066&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2013/0179066</a></td><td align="left">
July 2013</td><td align="left">
de los Reyes et al.</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
       <i>Primary Examiner:</i> Desir; Pierre-Louis
<br/>
       <i>Assistant Examiner:</i> Thomas-Homescu; Anne
<br/>
       <i>Attorney, Agent or Firm:</i> <coma>Baker Botts L.L.P.
<br/>
       <hr/>
       <center><b><i>Parent Case Text</i></b></center>
       <hr/>
       <br/><br/>PRIORITY
<br/><br/> This application is a continuation under 35 U.S.C. .sctn.120 of U.S.
     patent application Ser. No. 13/211,182 filed on 16 Aug. 2011, which is
     incorporated herein by reference.
         <hr/>
<center><b><i>Claims</i></b></center> <hr/> <br/><br/>What is claimed is: <br/><br/> 1.  One or more computer-readable non-transitory storage media embodying software that is operable when executed to: receive an audio waveform fingerprint and a
client-determined location from a client device;  compare the received audio waveform fingerprint to a database of stored audio waveform fingerprints, each stored audio waveform fingerprint associated with an object in an object database;  find one or
more matching audio waveform fingerprints from a comparison set of audio waveform fingerprints obtained from the audio waveform fingerprint database;  determine, based at least in part on the matching audio waveform fingerprints, location information
associated with a location of the client device;  and send the location information to the client device, wherein the client device is operable to update the client-determined location based at least in part on the location information;  wherein: the
database of stored audio waveform fingerprints comprises uploaded audio waveform fingerprints from one or more other client devices;  and the comparison set of audio waveform fingerprints is determined based at least in part on the received
client-determined location.
<br/><br/> 2.  The media of claim 1, the software further operable when executed to: send content from an object associated with one or more of the matching audio waveform fingerprints to the client device.
<br/><br/> 3.  The media of claim 2, wherein the object is a song and the content from the song comprises information about the song.
<br/><br/> 4.  The media of claim 1, wherein the one or more other client devices are associated with one or more users of a social-networking system.
<br/><br/> 5.  The media of claim 4, wherein the matching audio waveform fingerprints comprise uploaded audio waveform fingerprints from one or more of the users.
<br/><br/> 6.  The media of claim 5, wherein the location information is determined based at least in part on information associated with one or more of the users in the social-networking system.
<br/><br/> 7.  The media of claim 4, wherein the objects comprise voices of one or more of the users.
<br/><br/> 8.  The media of claim 4, wherein the comparison set of audio waveform fingerprints from the audio waveform fingerprint database is based at least in part on social factors between a user of the client device and one or more of the users of the
social-networking system.
<br/><br/> 9.  A system comprising: one or more processors;  and a memory coupled to the processors comprising instructions executable by the processors, the processors being operable when executing the instructions to: receive an audio waveform
fingerprint and a client-determined location from a client device;  compare the received audio waveform fingerprint to a database of stored audio waveform fingerprints, each stored audio waveform fingerprint associated with an object in an object
database;  find one or more matching audio waveform fingerprints from a comparison set of audio waveform fingerprints obtained from the audio waveform fingerprint database;  determine, based at least in part on the matching audio waveform fingerprints,
location information associated with a location of the client device;  and send the location information to the client device, wherein the client device is operable to update the client-determined location based at least in part on the location
information;  wherein: the database of stored audio waveform fingerprints comprises uploaded audio waveform fingerprints from one or more other client devices;  and the comparison set of audio waveform fingerprints is determined based at least in part on
the received client-determined location.
<br/><br/> 10.  The system of claim 9, the processors further operable when executing the instructions to: send content from an object associated with one or more of the matching audio waveform fingerprints to the client device.
<br/><br/> 11.  The system of claim 10, wherein the object is a song and the content from the song comprises information about the song.
<br/><br/> 12.  The system of claim 9, wherein the one or more other client devices are associated with one or more users of a social-networking system.
<br/><br/> 13.  The system of claim 12, wherein the matching audio waveform fingerprints comprise uploaded audio waveform fingerprints from one or more of the users.
<br/><br/> 14.  The system of claim 13, wherein the location information is determined based at least in part on information associated with one or more of the users in the social-networking system.
<br/><br/> 15.  The system of claim 12, wherein the objects comprise voices of one or more of the users.
<br/><br/> 16.  The system of claim 12, wherein the comparison set of audio waveform fingerprints from the audio waveform fingerprint database is based at least in part on social factors between a user of the client device and one or more of the users of
the social-networking system.
<br/><br/> 17.  One or more computer-readable non-transitory storage media embodying software that is operable when executed to: receive a first audio waveform fingerprint and a client-determined location from a first client device;  compare the received
first audio waveform fingerprint to a database of stored audio waveform fingerprints, each stored audio waveform fingerprint being uploaded from one of a plurality of second client devices;  find one or more matching audio waveform fingerprints from a
comparison set of audio waveform fingerprints obtained from the audio waveform fingerprint database, the comparison set being determined based at least in part on the received client-determined location;  classify each matching audio waveform fingerprint
as a high-confidence or low-confidence match;  and for each high-confidence match: determine, based at least in part on the matching audio waveform fingerprints, location information associated with a location of the first client device;  and send the
location information to the first client device, wherein the first client device is operable to update the client-determined location based at least in part on the location information;  for each low confidence match, send an instruction to the first
client device and the one or more second client devices whose uploaded audio waveform fingerprints match the received first audio waveform fingerprint to capture audio data at a particular time and for a particular duration.
<br/><br/> 18.  The media of claim 17, the software further operable when executed to: receive in response to the instruction a plurality of second audio waveform fingerprints from the first client device and the one or more second client devices; 
determine whether the received second audio waveform fingerprint from the first client device matches any of the one or more received second audio waveform fingerprints from the one or more second client devices;  and in response to a positive
determination, determine that the first client device is in the same location as the second client devices whose received second audio waveform fingerprints match the received second audio waveform fingerprint from the first client device.
<br/><br/> 19.  The media of claim 18, the software further operable when executed to: in response to a positive determination, determine that the first client device and the second client devices whose received second audio waveform fingerprints match the
received second audio waveform fingerprint from the first client device are in the same location as a particular user whose voice is associated with the matching received second audio waveform fingerprints;  and store the location of the particular user.
<br/><br/> 20.  The media of claim 17, wherein the comparison set of audio waveform fingerprints from the audio waveform fingerprint database is based at least in part on social factors between a user of the first client device and one or more users of the
second client devices.
<br/><br/> 21.  A system comprising: one or more processors;  and a memory coupled to the processors comprising instructions executable by the processors, the processors being operable when executing the instructions to: receive a first audio waveform
fingerprint and a client-determined location from a first client device;  compare the received first audio waveform fingerprint to a database of stored audio waveform fingerprints, each stored audio waveform fingerprint being uploaded from one of a
plurality of second client devices;  find one or more matching audio waveform fingerprints from a comparison set of audio waveform fingerprints obtained from the audio waveform fingerprint database, the comparison set being determined based at least in
part on the received client-determined location;  classify each matching audio waveform fingerprint as a high-confidence or low-confidence match;  and for each high-confidence match: determine, based at least in part on the matching audio waveform
fingerprints, location information associated with a location of the first client device;  and send the location information to the first client device, wherein the first client device is operable to update the client-determined location based at least
in part on the location information;  for each low confidence match, send an instruction to the first client device and the one or more second client devices whose uploaded audio waveform fingerprints match the received first audio waveform fingerprint
to capture audio data at a particular time and for a particular duration.
<br/><br/> 22.  The system of claim 21, the software further operable when executed to: receive in response to the instruction a plurality of second audio waveform fingerprints from the first client device and the one or more second client devices; 
determine whether the received second audio waveform fingerprint from the first client device matches any of the one or more received second audio waveform fingerprints from the one or more second client devices;  and in response to a positive
determination, determine that the first client device is in the same location as the second client devices whose received second audio waveform fingerprints match the received second audio waveform fingerprint from the first client device.
<br/><br/> 23.  The system of claim 21, the software further operable when executed to: in response to a positive determination, determine that the first client device and the second client devices whose received second audio waveform fingerprints match
the received second audio waveform fingerprint from the first client device are in the same location as a particular user whose voice is associated with the matching received second audio waveform fingerprints;  and store the location of the particular
user.
<br/><br/> 24.  The system of claim 21, wherein the comparison set of audio waveform fingerprints from the audio waveform fingerprint database is based at least in part on social factors between a user of the first client device and one or more users of
the second client devices. <hr/> <center><b><i>Description</i></b></center> <hr/> <br/><br/>TECHNICAL FIELD
<br/><br/> This disclosure generally relates to periodically capturing waveform data using the sensor subsystem of a mobile device and generating a fingerprint of the waveform for analysis on a server for enhanced social functions.
<br/><br/>BACKGROUND
<br/><br/> A social networking system, such as a social networking website, enables its users to interact with it and with each other through the system.  The social networking system may create and store a record, often referred to as a user profile, in
connection with the user.  The user profile may include a user's demographic information, communication channel information, and personal interest.  The social networking system may also create and store a record of a user's relationship with other users
in the social networking system (e.g., social graph), as well as provide services (e.g., wall-posts, photo-sharing, or instant messaging) to facilitate social interaction between users in the social networking system.  A geo-social networking system is a
social networking system in which geographic services and capabilities are used to enable additional social interactions.  User-submitted location data or geo-location techniques (e.g., mobile phone position tracking) can allow a geo-social network to
connect and coordinate users with local people or events that match their interests.  For example, users can check-in to a place using a mobile client application by providing a name of a place (or selecting a place from a pre-established list of
places).  The geo-social networking system, among other things, can record information about the user's presence at the place and possibly provide this information to other users of the geo-social networking system.
<br/><br/>SUMMARY
<br/><br/> Particular embodiments relate to a geo-social networking system that includes features directed to automatically and periodically capturing waveform data from the sensor subsystem of a mobile device, uploading a representation of the waveform
data to a server for analysis, and receiving content based on the analysis.  These and other features, aspects, and advantages of the disclosure are described in more detail below in the detailed description and in conjunction with the following figures.
<br/><br/>BRIEF DESCRIPTION OF THE DRAWINGS
<br/><br/> FIG. 1 illustrates an example social networking system.
<br/><br/> FIG. 2 illustrates an example user device.
<br/><br/> FIG. 3 illustrates an example geographic area and the self-reported location of users in the geographic area.
<br/><br/> FIG. 3A illustrates an example of three users in the same geographic location.
<br/><br/> FIG. 3B illustrates the social graph for the three users of FIG. 3A.
<br/><br/> FIG. 4 illustrates an example method for delivering enhanced social functions based on captured waveform data.
<br/><br/> FIG. 5 illustrates an example method of enhancing location accuracy.
<br/><br/> FIG. 6 illustrates an example method of providing an enhanced social function.
<br/><br/> FIG. 7 illustrates an example computer system.
<br/><br/>DESCRIPTION OF EXAMPLE EMBODIMENTS
<br/><br/> The invention is now described in detail with reference to a few embodiments thereof as illustrated in the accompanying drawings.  In the following description, numerous specific details are set forth in order to provide a thorough understanding
of the present disclosure.  It is apparent, however, to one skilled in the art, that the present disclosure may be practiced without some or all of these specific details.  In other instances, well known process steps and/or structures have not been
described in detail in order not to unnecessarily obscure the present disclosure.  In addition, while the disclosure is described in conjunction with the particular embodiments, it should be understood that this description is not intended to limit the
disclosure to the described embodiments.  To the contrary, the description is intended to cover alternatives, modifications, and equivalents as may be included within the spirit and scope of the disclosure as defined by the appended claims.
<br/><br/> A social networking system, such as a social networking website, enables its users to interact with it, and with each other through, the system.  Typically, to become a registered user of a social networking system, an entity, either human or
non-human, registers for an account with the social networking system.  Thereafter, the registered user may log into the social networking system via an account by providing, for example, a correct login ID or username and password.  As used herein, a
"user" may be an individual (human user), an entity (e.g., an enterprise, business, or third party application), or a group (e.g., of individuals or entities) that interacts or communicates with or over such a social network environment.
<br/><br/> When a user registers for an account with a social networking system, the social networking system may create and store a record, often referred to as a "user profile", in connection with the user.  The user profile may include information
provided by the user and information gathered by various systems, including the social networking system, relating to activities or actions of the user.  For example, the user may provide his name, profile picture, contact information, birth date,
gender, marital status, family status, employment, education background, preferences, interests, and other demographical information to be included in his user profile.  The user may identify other users of the social networking system that the user
considers to be his friends.  A list of the user's friends or first degree contacts may be included in the user's profile.  Connections in social networking systems may be in both directions or may be in just one direction.  For example, if Bob and Joe
are both users and connect with each another, Bob and Joe are each connections of the other.  If on the other hand, Bob wishes to connect to Sam to view Sam's posted content items, but Sam does not choose to connect to Bob, a one-way connection may be
formed where Sam is Bob's connection, but Bob is not Sam's connection.  Some embodiments of a social networking system allow the connection to be indirect via one or more levels of connections (e.g., friends of friends).  Connections may be added
explicitly by a user, for example, the user selecting a particular other user to be a friend, or automatically created by the social networking system based on common characteristics of the users (e.g., users who are alumni of the same educational
institution).  The user may identify or bookmark websites or web pages he visits frequently and these websites or web pages may be included in the user's profile.
<br/><br/> The user may provide information relating to various aspects of the user (such as contact information and interests) at the time the user registers for an account or at a later time.  The user may also update his or her profile information at
any time.  For example, when the user moves, or changes a phone number, he may update his contact information.  Additionally, the user's interests may change as time passes, and the user may update his interests in his profile from time to time.  A
user's activities on the social networking system, such as frequency of accessing particular information on the system, may also provide information that may be included in the user's profile.  Again, such information may be updated from time to time to
reflect the user's most-recent activities.  Still further, other users or so-called friends or contacts of the user may also perform activities that affect or cause updates to a user's profile.  For example, a contact may add the user as a friend (or
remove the user as a friend).  A contact may also write messages to the user's profile pages--typically known as wall-posts.  A user may also input status messages that get posted to the user's profile page.
<br/><br/> A social network system may maintain social graph information, which can generally model the relationships among groups of individuals, and may include relationships ranging from casual acquaintances to close familial bonds.  A social network
may be represented using a graph structure.  Each node of the graph corresponds to a member of the social network.  Edges connecting two nodes represent a relationship between two users.  In addition, the degree of separation between any two nodes is
defined as the minimum number of hops required to traverse the graph from one node to the other.  A degree of separation between two users can be considered a measure of relatedness between the two users represented by the nodes in the graph.
<br/><br/> A social networking system may support a variety of applications, such as photo sharing, on-line calendars and events.  For example, the social networking system may also include media sharing capabilities.  For example, the social networking
system may allow users to post photographs and other multimedia files to a user's profile, such as in a wall post or in a photo album, both of which may be accessible to other users of the social networking system.  Social networking system may also
allow users to configure events.  For example, a first user may configure an event with attributes including time and date of the event, location of the event and other users invited to the event.  The invited users may receive invitations to the event
and respond (such as by accepting the invitation or declining it).  Furthermore, social networking system may allow users to maintain a personal calendar.  Similarly to events, the calendar entries may include times, dates, locations and identities of
other users.
<br/><br/> The social networking system may also support a privacy model.  A user may or may not wish to share his information with other users or third-party applications, or a user may wish to share his information only with specific users or third-party
applications.  A user may control whether his information is shared with other users or third-party applications through privacy settings associated with his user profile.  For example, a user may select a privacy setting for each user datum associated
with the user and/or select settings that apply globally or to categories or types of user profile information.  A privacy setting defines, or identifies, the set of entities (e.g., other users, connections of the user, friends of friends, or third party
application) that may have access to the user datum.  The privacy setting may be specified on various levels of granularity, such as by specifying particular entities in the social network (e.g., other users), predefined groups of the user's connections,
a particular type of connections, all of the user's connections, all first-degree connections of the user's connections, the entire social network, or even the entire Internet (e.g., to make the posted content item index-able and searchable on the
Internet).  A user may choose a default privacy setting for all user data that is to be posted.  Additionally, a user may specifically exclude certain entities from viewing a user datum or a particular type of user data.
<br/><br/> Social networking system may maintain a database of information relating to geographic locations or places.  Places may correspond to various physical locations, such as restaurants, bars, train stations, airports and the like.  Some places may
correspond to larger regions that themselves contain places such as a restaurant or a gate location in an airport.  In one implementation, each place can be maintained as a hub node in a social graph or other data structure maintained by the social
networking system, as described in U.S.  patent application Ser.  No. 12/863,181, which is incorporated by reference herein for all purposes.  Social networking system may allow users to access information regarding each place using a client application
(e.g., a browser) hosted by a wired or wireless station, such as a laptop, desktop or mobile device.  For example, social networking system may serve web pages (or other structured documents) to users that request information about a place.  In addition
to user profile and place information, the social networking system may track or maintain other information about the user.  For example, the social networking system may support geo-social networking system functionality including one or more
location-based services that record the user's location.  For example, users may access the geo-social networking system using a special-purpose client application hosted by a mobile device of the user (or a web- or network-based application using a
browser client).  The client application may automatically access Global Positioning System (GPS) or other geo-location functions supported by the mobile device and report the user's current location to the geo-social networking system.  In addition, the
client application may support geo-social networking functionality that allows users to check-in at various locations and communicate this location to other users.  A check-in to a given place may occur when a user is physically located at a place and,
using a mobile device, access the geo-social networking system to register the user's presence at the place.  A user may select a place from a list of existing places near to the user's current location or create a new place.  The user may also provide
comments in a text string when checking in to a given place.  The user may also identify one or more other users in connection with a check-in (such as friends of a user) and associate them with the check-in as well.  U.S.  patent application Ser.  No.
12/584,614, which is incorporated by reference herein for all purposes, describes a system that allows a first user to check-in other users at a given place.  An entry including a comment and a time stamp corresponding to the time the user checked in may
be displayed to other users.  For example, a record of the user's check-in activity may be stored in a database.  Social networking system may select one or more records associated with check-in activities of users at a given place and include such
check-in activity in web pages (or other structured documents) that correspond to a given place.  For example, social networking system may select the check-in activity associated with the friends or other social contacts of a user that requests a page
corresponding to a place.  U.S.  application Ser.  No. 12/858,817, incorporated by reference in its entirety for all purposes, describes an example geo-social networking system that can be used in connection with various embodiments of the present
invention.  The check-in activity may also be displayed on a user profile page and in news feeds provided to users of the social networking system.
<br/><br/> Still further, a special purpose client application hosted on a mobile device of a user may be configured to continuously capture location data of the mobile device and send the location data to social networking system.  In this manner, the
social networking system may track the user's location and provide various recommendations to the user related to places that are proximal to the user's path or that are frequented by the user.  In one implementation, a user may opt in to this
recommendation service, which causes the client application to periodically post location data of the user to the social networking system.
<br/><br/> Still further, particular embodiments allow the social networking system to receive waveform fingerprints from a client or mobile device, and perform analysis on the waveform fingerprints to provide enhanced social functions to the user of the
device.  In particular embodiments, the determined location of the client device may be enhanced through waveform analysis.  For example, if a user is in a particular venue, the waveform fingerprints captured by his mobile device will match the waveform
fingerprints uploaded by other users.  If any of the other users' locations converge, or if one of the users makes an explicit on-network statement that he or she is at the venue, either through a check-in operation or a comment, the social networking
system may update and enhance the user's inaccurately determined position.
<br/><br/> In particular embodiments, received waveform fingerprints may be matched to a database of waveforms for pushing suggestions, advertisements, and other content to users.  For example, if a user is in a particular location and the waveform
fingerprint uploaded by his or her mobile device matches the fingerprint of a particular song stored in an audio database, the social networking system may ask the user if he or she would like to purchase the song for download, may suggest similar
songs/artists to the user, or target the user for marketing based on his musical taste.  In particular embodiments, the detected song may be posted to the wall of the user as a "currently listening to" story or widget.
<br/><br/> In particular embodiments, received waveform fingerprints matching the fingerprint of an object in the audio store may be substituted for explicit graph connections.  For example, if three of a user's friends capture and upload waveforms
matching a particular television program or movie, the social networking system may infer a connection from those three users to the matched program, and suggest the matched program to the user.  In particular embodiments, the social networking system
may prompt the user to submit a review for the identified content.  In particular embodiments, the server may classify matches as high or low confidence, and in the case of a low confidence match, transmit a command to the client devices generating the
partially patching waveform fingerprints to capture ambient audio data at a specific time and duration for retransmission and analysis to the server.  Thus, the server may determine whether particular waveforms match to a high degree of confidence.  This
disclosure provides a method of capturing the ambient sounds around a user for enhanced social functions.
<br/><br/> FIG. 1 illustrates an example social networking system.  In particular embodiments, the social networking system may store user profile data and social graph information in user profile database 101.  In particular embodiments, the social
networking system may store user event data in event database 102.  For example, a user may register a new event by accessing a client application to define an event name, a time and a location, and cause the newly created event to be stored in event
database 102.  In particular embodiments, the social networking system may store user privacy policy data in privacy policy database 103.  In particular embodiments, the social networking system may store geographic and location data in location database
104.  In particular embodiments, social networking system may store audio waveforms or audio waveform fingerprints for various songs, TV shows, soundtracks, movies, performances, and the like in audio database 105.  In particular embodiments, databases
101, 102, 103, 104, and 105 may be operably connected to the social networking system's front end.  In particular embodiments, social networking system also includes waveform matching application 118, that matches uploaded waveform fingerprints with
waveforms or waveform fingerprints stored in audio database 105.
<br/><br/> In particular embodiments, the front end 120 may interact with client device 122 through network cloud 121.  Client device 122 is generally a computer or computing device including functionality for communicating (e.g., remotely) over a computer
network.  Client device 122 may be a desktop computer, laptop computer, personal digital assistant (PDA), in- or out-of-car navigation system, smart phone or other cellular or mobile phone, or mobile gaming device, among other suitable computing devices. Client device 122 may execute one or more client applications, such as a web browser (e.g., Microsoft Windows Internet Explorer, Mozilla Firefox, Apple Safari, Google Chrome, and Opera, etc.) or special-purpose client application (e.g., <b><i>Facebook</i></b> for
iPhone, etc.), to access and view content over a computer network.  Front end 120 may include web or HTTP server functionality, as well as other functionality, to allow users to access the social networking system.  Network cloud 121 generally represents
a network or collection of networks (such as the Internet or a corporate intranet, or a combination of both) over which client devices 122 may access the social network system.
<br/><br/> In particular embodiments, location database 104 may store an information base of places, where each place includes a name, a geographic location and meta information (such as the user that initially created the place, reviews, comments,
check-in activity data, and the like).  Places may be created by administrators of the system and/or created by users of the system.  For example, a user may register a new place by accessing a client application to define a place name and provide a
geographic location and cause the newly created place to be registered in location database 104.  As discussed above, a created place may correspond to a hub node, which an administrator can claim for purposes of augmenting the information about the
place and for creating ads or other offers to be delivered to users.  In particular embodiments, system front end 120 may construct and serve a web page of a place, as requested by a user.  In some embodiments, a web page of a place may include
selectable components for a user to "like" the place or check in to the place.  In particular embodiments, location database 104 may store geo-location data identifying a real-world geographic location of a user associated with a check-in. For example, a
geographic location of an Internet connected computer can be identified by the computer's IP address.  For example, a geographic location of a cell phone equipped with cellular, Wi-Fi and/or GPS capabilities can be identified by cell tower triangulation,
Wi-Fi positioning, and/or GPS positioning.  In particular embodiments, location database 104 may store a geographic location and additional information of a plurality of places.  For example, a place can be a local business, a point of interest (e.g.,
Union Square in San Francisco, Calif.), a college, a city, or a national park.  For example, a geographic location of a place (e.g., a local coffee shop) can be an address, a set of geographic coordinates (latitude and longitude), or a reference to
another place (e.g., "the coffee shop next to the train station").  For example, a geographic location of a place with a large area (e.g., Yosemite National Park) can be a shape (e.g., a circle, or a polygon) approximating the boundary of the place
and/or a centroid of the shape.  For example, additional information of a place can be business hours, photos, or user reviews of the place.  In particular embodiments, location database 104 may store a user's location data.  For example, a user can
create a place (e.g., a new restaurant or coffee shop) and the social networking system can store the created place in location database 104.  For example, location database 104 may store a user's check-in activities.  For example, location database 104
may store a user's geographic location provided by the user's GPS-equipped mobile device.  In particular embodiments, the social networking system may calculate one or more routes of a user based on the user's user profile information, check-in
activities, and/or geographic location data reported by a client application (see above) and store the one or more routes in location database 104.  For example, the social networking system can calculate a "commute route" of a user between the user's
home and work (as described in the user's user profile information stored in user profile database 101) by using a mapping service application such as Google Map, or by using geographic location data points from the user's GPS-equipped mobile phone while
the user is driving to work.
<br/><br/> Waveform matching application 118 matches waveforms or waveform fingerprints uploaded by client devices 122 to waveforms or waveform fingerprints in audio database 105.  In particular embodiments, waveform matching application utilizes feature
detection using Fast Fourier Transforms (FFTs) or Direct Cosine Transforms (DCTs).  In particular embodiments, cross correlation in either the frequency or time domain is utilized for waveform matching.  In particular embodiments, dynamic waveform
matching (DWM) may be utilized to shift the waveforms on the time axis.  In particular embodiments, waveform matching application 118 utilizes audio fingerprinting of the waveform files in audio database 105.  This disclosure contemplates any suitable
method or algorithm for waveform or waveform fingerprint matching.
<br/><br/> FIG. 2 illustrates an example client device 122.  In particular embodiments, client device 122 may be a smart phone (e.g., iPhone or Blackberry), which is a mobile telephone that offers more advanced computing ability and connectivity than a
traditional mobile phone.  It may be considered as a handheld computer integrated with a mobile phone.  In particular embodiments, client device 122 may be a netbook or tablet computer (e.g., iPad).  In particular embodiments, client device 122 may be
connected to a network through a wireless connection.
<br/><br/> In particular embodiments, client device 122 may include hardware 210 and software 220.  In particular embodiments, hardware 210 may include any number of hardware components such as, for example and without limitation, processor 211, memory
212, storage 213, transceiver 214, input/output device 215 (e.g., display, touch screen, keypad, microphone, speaker, etc.), camera 216, global positioning system (GPS) sensor 217, sensors hub 218, notification control switch 219, RFID reader 241, RF
sensor 242, accelerometer 243, light sensor 244, microphone 245 (which may be part of input/output block 215) and so on.  This disclosure contemplates any suitable hardware components.  In particular embodiments, some or all of a user's user data may be
stored in storage 213.
<br/><br/> In particular embodiments, software 220 may include an operating system 221, which may include a kernel 231 and/or any number of device drivers 232 corresponding to some of the hardware components available on client device 122.  Operating
system 221 may be selected for client device 122 based on the actual type of device client device 122 is.  For example, if client device 122 is a mobile device (e.g., a smart phone), then operating system 221 may be a mobile operating system such as, for
example and without limitation, Microsoft's Windows Mobile, Google's Android, Nokia's Symbian, Apple's iOS, and Samsung's Bada.
<br/><br/> In particular embodiments, one or more software applications 223 may be executed on client device 122.  In particular embodiments, they may be native applications installed and residing on client device 122.  For example, one application (e.g.,
Google Maps) may enable a device user to view a map, search for addresses and businesses, and get directions; a second application may enable the device user to read, send, and receive mails; a third application (e.g., a web browser) may enable the
device user to browse and search the Internet; a fourth application may enable the device user to take photos or record videos using camera 216; a fifth application may allow the device user to receive and initiate VoIP and/or cellular network calls, and
so on.  In particular embodiments, there may be a software application (e.g., notification control 241) that enables the device user to manage the notifications pushed to client device 122.  Each software application 220 may have a user interface and may
implement one or more specific functionalities.  Each software application 220 may include one or more software modules implementing the individual functionalities.  The executable code of software applications 220 may be stored in a computer-readable
and non-transitory medium (e.g., storage 213 or memory 212) on client device 122.  In particular embodiments, non-native, web-based applications interact with the hardware of client device 122 through various application program interfaces (APIs) to
allow use of the microphone and other subsystems of client device 122.  For example, a web application or plug-in at www.google.com/voice may permit the user to utilize the microphone subsystem of client device 122 to make VoIP calls directly from the
web browser residing on client device 122.
<br/><br/> Audio capture application 246 is operably connected to microphone 245 and sensor hub 218, in particular embodiments, audio capture application 246 continuously captures audio data and converts it into a waveform fingerprint, using audio feature
detection algorithms (FFT/DCT/etc.).  In particular embodiments, audio capture application 246 only periodically captures waveform data and converts the data into waveform fingerprints.  In particular embodiments, sensor hub 218 captures and stores
waveform data via microphone 245 and stores the waveforms in storage 213 for later fingerprint generation by audio capture application 245.  In particular embodiments, audio capture application 246 runs only when the user changes location.  In particular
embodiments, audio capture application 246 runs only when the detected sound level exceeds a predetermined number of decibels.  This disclosure contemplates any suitable manner of capturing ambient audio data.
<br/><br/> FIG. 3 illustrates an example geographic area 300 and the self-reported location of various users 301 of the social networking system on the map.  In particular embodiments, the self-reported location is calculated by a GPS receiver chip in
client devices 122.  In particular embodiments, the location is calculated by TDOA or other position determination algorithms.  In particular embodiments, geographic area may be segmented into various quadrants, and user waveform fingerprints may be
searched against waveform fingerprints uploaded by other users in the same quadrant.  In particular embodiments, the search area is based on the amplitude or absolute volume of the uploaded fingerprint.  For example, if an uploaded fingerprint indicates
that the ambient sound in the environment of the user is extremely loud, the search area may be decreased, as there would be a larger number of users reporting the same sound from disparate locations.  In particular embodiments, the social networking
system first searches the fingerprints uploaded by friends of the user at the same time, based on the assumption that they are more likely to be together.  In particular embodiments, spatial partitioning algorithms may be used to determine the search
space.  In particular embodiments, an oct-tree spatial partitioning algorithm is utilized to address the search space.  In particular embodiments, a kd-tree is used.  in particular embodiments, a quad-tree, or any other grid-based method, is used.  This
disclosure contemplates any suitable method of generating a search area for fingerprints uploaded by other users.
<br/><br/> FIG. 3A illustrates a zoomed-in view of the upper left tile of FIG. 3.  In FIG. 3, three users' self-determined locations are plotted on the map.  Two users, 310 and 320 report their location to be within a few meters of each other, in the Fox
Plaza.  Another user, 330, reports his or her location to be across the street, near the "Ma'velous" restaurant.  Users 310, 320, and 300 may or may not have explicit edge connections between each other on the social graph.  For the purposes of this
example, the social networking system has matched the waveform fingerprints generated by all three users.
<br/><br/> FIG. 3B illustrates an example portion of a social graph including user 310, represented by user node 1, user 320, represented by user node 2, and user 330, represented by user node 3.  Because the waveform fingerprints from all three users
match, the social networking system may assume that they are in the same general vicinity.  In particular embodiments, the social networking system takes into account the amplitude of all three waveform fingerprints.  For example, if all three waveform
fingerprints are at the same volume, and the volume is low, the social network may infer that the user location of user 330 is incorrect, and may transmit a corrected location to client device 122 of user 330.  On the other hand, if all three waveform
fingerprints are at the same volume, and the volume is very high, then the social network may not transmit a corrected location.
<br/><br/> In FIG. 3B, user node 1 has performed an explicit, on-network action, such as RSVPing to an event, checking-in to a location, or being tagged in a location or event, for an event page, in this case "John and Jane's Wedding." Thus, the social
network immediately knows, upon finding matching waveform fingerprints to the fingerprints transmitted by user node 1, that the users transmitting the matching fingerprints are also in the same location and attending the same event.  Thus, user nodes 2
and 3 may be placed at the same location, and a corrected location may be transmitted to user node 3 (user 330 of FIG. 3A).  In particular embodiments, the type of event can be used to determine whether to alter the device settings of the users.  For
example, given that the social network knows that user nodes 1, 2, and 3 are attending a wedding, it may transmit a command to automatically change the client device settings to "silent" or "vibrate."
<br/><br/> In particular embodiments, the social networking system compares uploaded waveform fingerprints to fingerprints uploaded by other users in the search area, as well as audio database 105.  For example, in FIG. 3B, the social network determines
that user nodes 1, 2, and 3 are in the same location.  It may also compare the uploaded waveform fingerprints to an audio database of the voice of every single user of the social networking system.  For example, the social networking system may detect
the voice of the pastor of the wedding, represented on the social networking system by user node 4.  Thus, the social networking system may maintain a database of user locations for every member that is updated any time the member's voice is detected. 
In particular embodiments, the social networking system may even maintain a location database of users who are not members of the social network, by assigning an arbitrary placeholder user node for each detected voice.  In particular embodiments, to
reduce search time, the social network may search waveform fingerprints uploaded by a particular user to the audio fingerprints in audio database 105 of the voices of the particular user's friends.  In particular embodiments, the social network may first
search the user's friends who are currently in the same geographic quadrant as the uploading user.  Thus, in particular embodiments, search time may be greatly reduced relative to searching every single stored voice fingerprint in audio database 105.
<br/><br/> FIG. 4 illustrates an example method for providing enhanced social functions based on ambient waveform capture.  At step 401, microphone 245 of client device 122 records an audio waveform.  As previously discussed, waveform recording may be
carried out by processor 211 running audio capture application 246, or low-power processor in sensor hub 218.  In particular embodiments, client device 122 constantly records the ambient audio and stores it in storage 213.  In particular embodiments,
client device 122 periodically records ambient audio for analysis.  In particular embodiments, client device 122 records the ambient audio whenever a change in position is detected via GPS sensor 217 or other location determination algorithms.  In
particular embodiments, client device 122 captures the ambient audio whenever the audio exceeds a certain volume.  In particular embodiments, audio capture step 301 is triggered by user interaction with the social network, such as using a social
networking application, viewing the social networking website, or checking-in to a location.  This disclosure contemplates any suitable manner of initiating or timing audio capture.
<br/><br/> At Step 402, audio capture application 246 performs feature detection on the waveform and analyzes waveform characteristics, also referred to as the "waveform DNA.` Feature detection step 402 may include, in particular embodiments, identifying
spikes in the audio waveform, predominance or lack of a particular frequency band, or other trends in waveform amplitude.  In particular embodiments, the feature detection is implemented via an FFT or DCT.  In particular embodiments, other
frequency-domain transforms may be utilized to identify key characteristics of the waveform, such as how much treble or bass is present in the waveform.  In particular embodiments, audio capture application 246 utilizes a discrete wavelet transform.  In
particular embodiments, audio capture application 246 utilizes a short-time Fourier transform.  In particular embodiments, audio capture application 246 detects a fundamental frequency of the waveform.  In particular embodiments, audio capture
application 246 filters noise components from the captured waveform.  In particular embodiments, audio capture application 246 utilizes a form of event onset detection to create a beat model for the captured waveform.  In particular embodiments, audio
capture application 246 generates a beat histogram for the waveform.  This disclosure contemplates any suitable method or algorithm for audio waveform feature detection.
<br/><br/> At Step 403, an audio "fingerprint" is generated for one or more waveforms.  The fingerprint is a small robust representation that summarizes the waveform or collection of waveforms.  For example, in particular embodiments, waveforms may be
captured and analyzed periodically, at one sample per second.  Each waveform captured may be analyzed for feature detection, and audio capture application 246 may aggregate a number of waveforms having similar features (perhaps 100-200 waveforms) and
generate a fingerprint for the aggregate waveform representing a song, video, or soundtrack to a movie.  In particular embodiments, audio capture application 246 uses vector quantization to generate representative vectors as the waveform fingerprint.  In
particular embodiments, audio capture application 246 utilizes spectrogram peaks, such as those used in the Shazam song recognition software, as the captured waveform fingerprint.  Techniques for generating waveform fingerprints are known in the art. 
This disclosure contemplates any suitable manner of generating fingerprints for the captured waveform or waveforms.
<br/><br/> At Step 404, client device 122 transmits the fingerprint generated in Step 403 to a server.  In particular embodiments, the server is the system front end 120 of the social networking system.  In particular embodiments, client device 122
transmits the fingerprint directly to one or more servers running audio matching application 118.  This disclosure contemplates any suitable mechanism of transmitting the waveform fingerprints to audio matching application 118.  The one or more servers
running audio matching application 118 receive the transmitted fingerprint at Step 405.
<br/><br/> At Step 406, the received fingerprint is searched against a database of fingerprints stored in audio database 105.  In particular embodiments, audio database 105 stores fingerprints of various different formats, so that fingerprints generated by
a different method may still be compared to the stored fingerprints, in particular embodiments, audio database 105 stores waveforms, and the fingerprints for the stored waveforms are dynamically generated.  If no matches are found, the process ends at
Step 412.
<br/><br/> If a match is found, at Step 407, information relating to the object associated with the matching fingerprint is pulled from the social networking system.  In particular embodiments, this information is stored in audio database 105.  In
particular embodiments, the information may be stored in a separate object or node database in the social networking system.  In particular embodiments, the information may be metadata attached to the waveform stored in audio database 105.  The
information may comprise general characteristics, such as the artist, song title, album title, date of recording, etc., and social characteristics, such as how many of the user's friends have "liked", commented on, or otherwise interacted with the
object.  In particular embodiments, the information may be other songs performed by the artist, or other types of music in the genre.  This disclosure contemplates any type of information related to the object associated with the matching waveform
fingerprint.
<br/><br/> At Step 409, the social networking system may optionally perform on-network actions, such as automatically tagging the object in a photo, automatically "liking" the object for a user, or posting a story to the user's news feed.  For example, the
social networking application may have a "now playing" or "now listening/watching" area of the user profile or news feed, and update the feed with the object associated with the matching waveform.  In particular embodiments, the social networking system
may tag a photo of the event with a tag of the songs that were played at the event.  In particular embodiments, the photo need not be uploaded by the same user who uploaded the waveform fingerprint, so long as the social network may determine that the
user attended the event.  This disclosure contemplates any manner of on-network actions for the user.
<br/><br/> At Step 408, the server transmits the information to client device 122, and at Step 410, the information is received at client device 122.  The client device at Step 411 may then display the information in various graphical representations to
the user.  For example, client device 122 may display the album art and song information to the user.  In particular embodiments, client device 122 may prompt the user as to whether the user would like to purchase, download, "like", or post a review
about the detected object.  In particular embodiments, client device 122 may also display social information to the user, such as the number of friends who "liked" or became a fan of the artist associated with the object.  In particular embodiments,
client device may display suggestions pushed from the social network to the user.  In particular embodiments, the user may select the suggested song or artist to listen to their work.  This disclosure contemplates any manner of displaying received
information at client device 122 to the user.
<br/><br/> Audio object database 105 is not limited to songs.  For example, the social networking system may determine whether a particular user is watching a movie or TV program.  In particular embodiments, audio object database 105 stores a fingerprint
for each user of the social network's voice.  Thus, it is possible to determine the location of a user speaking to the uploading user, even if the speaker does not have his or her mobile device.  In such an embodiment, the social networking system may
automatically tag the detected speaker into the physical location associated with the uploading user.  Therefore, it is possible for the social networking system to track the physical location of its users, even those without mobile devices connected to
the social network, based on voice matching.
<br/><br/> FIG. 5 illustrates an example method for enhancing the location determination of a user based on detected waveforms.  The process is substantially identical to the process of FIG. 4 until Step 506.  In particular embodiments, Steps 506-510 may
be performed substantially simultaneously or in parallel with Steps 405-409.
<br/><br/> At Step 506, audio matching algorithm 246 pulls uploaded waveforms from the same general time and area as the uploading user.  The location may be ascertained through GPS coordinates, TDOA, or a self-reported location, such as a check-in. In
particular embodiments, the geographic search area decreases for areas in which a large number of fingerprints are being uploaded, as previously described with reference to FIG. 3.
<br/><br/> At Step 508, upon obtaining a matching fingerprint or fingerprints, the social networking system pulls location data associated with the one or more matching fingerprints.  For example, if a particular user's uploaded fingerprints match three
other users' uploaded fingerprints, and one of the three other users has checked-in to a particular location, then the location data for the check-in is pulled and transmitted to the client devices of the three users that did not check-in. In particular
embodiments, the social networking system may average the geographic locations, or find the point equidistant to all the locations, of users uploading matching waveforms.  For example, if three other users' uploaded audio fingerprints match the user's
uploaded fingerprint, the social networking system may calculate a point equidistant to the three other users' locations.  In particular embodiments, the social networking system searches for position outliers, for example if three of the four users with
matching uploaded fingerprints are extremely close, and one is several hundred feet away, the social networking system may infer that the location of the outlier user is inaccurate.
<br/><br/> At Step 510, the network may perform actions as previously described.  In particular embodiments, the social networking system may check the uploading user in to the location obtained in Step 508.
<br/><br/> At Step 512, after receiving the location information from the server in Step 511 client device 122 updates its self-determined location with the location obtained in Step 508.  In some cases, it may be to the location of a physical check-in. In
particular embodiments, it is updated to comport with the location of other uses with matching waveforms.  In particular embodiments, client device 122 prompts the user as to whether he wishes to check-in to the venue.  In particular embodiments, client
device 122 prompts the user whether he wishes to update his location.  This disclosure contemplates any suitable manner of updating the self-determined position of client device 122.
<br/><br/> FIG. 6 illustrates an example method of obtaining a higher confidence match between one or more client devices.  Steps 601 to 603 are identical to Steps 505-506 of FIG. 5.  Similarly, Steps 608-610 are identical to Steps 508 to 509.  In
particular embodiments, waveform matching application 118 may only obtain a partial, or "low confidence" match.  In particular embodiments, the confidence level is merely a percentage of the fingerprints that are matching.  In particular embodiments, the
confidence score is based off the degree the fingerprints match as well as location data of the uploading users.  For example, if the users fingerprints are matching, but their locations are several miles apart, the process of Step 604 is not initiated. 
In particular embodiments, social factors are utilized in determining the confidence of a match.  For example, where two waveform fingerprints partially match, but the two uploading users are friends in roughly the same location, then Step 604 is
initiated.  This disclosure contemplates any suitable method of determining whether a match is high or low confidence.
<br/><br/> At Step 605, the server transmits instructions to all clients whose uploaded fingerprints produced the low confidence match to begin capturing ambient audio data at a specific time and duration.  In particular embodiments, this instruction may
also instruct the client devices to perform fingerprint analysis via an alternative method.  In particular embodiments, the alternative method is determined by the degree of confidence of the match.  In particular embodiments, the alternative method is
determined by the percent of the uploaded fingerprints that match.  In particular embodiments, this instruction may inform the clients to capture audio at a higher quality.  The client devices 122 receiving this instruction comply, and transmit the
subsequently generated waveforms to the server.
<br/><br/> In Step 606, the server and waveform matching application 118 receive the fingerprints, and compares them in Step 607.  Because the fingerprints capture the exact same moment in time, the fingerprints generated from these waveforms should
produce an extremely high confidence match.  Thus, waveform matching application 118 can ascertain, with a high degree of confidence, that the uploading users are in the same location.  In particular embodiments, this high-confidence match can be matched
with the fingerprints of user voices in audio database 105 to determine which of the users is speaking.  In particular embodiments, the users may be all auto-tagged in the location.  In particular embodiments, the users may not be explicitly tagged, but
stored in a user location database for the delivery of advertisements or suggestions.
<br/><br/> The process of FIG. 6 thus allows the social network to increase the confidence of any two partially matching fingerprints, by coordinating waveform capture to the same temporal window.  This disclosure contemplates multiple variations of this
technique, such as, for example, multiple stages of fingerprint matching, wherein each stage instructs the client devices to capture a longer waveform.
<br/><br/> Particular embodiments may be implemented on one or more computer systems.  FIG. 7 illustrates an example computer system 700.  In particular embodiments, one or more computer systems 700 perform one or more steps of one or more methods
described or illustrated herein.  In particular embodiments, one or more computer systems 700 provide functionality described or illustrated herein.  In particular embodiments, software running on one or more computer systems 700 performs one or more
steps of one or more methods described or illustrated herein or provides functionality described or illustrated herein.  Particular embodiments include one or more portions of one or more computer systems 700.
<br/><br/> This disclosure contemplates any suitable number of computer systems 700.  This disclosure contemplates computer system 700 taking any suitable physical form.  As example and not by way of limitation, computer system 700 may be an embedded
computer system, a system-on-chip (SOC), a single-board computer system (SBC) (such as, for example, a computer-on-module (COM) or system-on-module (SOM)), a desktop computer system, a laptop or notebook computer system, an interactive kiosk, a
mainframe, a mesh of computer systems, a mobile telephone, a personal digital assistant (PDA), a server, or a combination of two or more of these.  Where appropriate, computer system 700 may include one or more computer systems 700; be unitary or
distributed; span multiple locations; span multiple machines; or reside in a cloud, which may include one or more cloud components in one or more networks.  Where appropriate, one or more computer systems 700 may perform without substantial spatial or
temporal limitation one or more steps of one or more methods described or illustrated herein.  As an example and not by way of limitation, one or more computer systems 700 may perform in real time or in batch mode one or more steps of one or more methods
described or illustrated herein.  One or more computer systems 700 may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein, where appropriate.
<br/><br/> In particular embodiments, computer system 700 includes a processor 702, memory 704, storage 706, an input/output (I/O) interface 708, a communication interface 710, and a bus 712.  Although this disclosure describes and illustrates a particular
computer system having a particular number of particular components in a particular arrangement, this disclosure contemplates any suitable computer system having any suitable number of any suitable components in any suitable arrangement.
<br/><br/> In particular embodiments, processor 702 includes hardware for executing instructions, such as those making up a computer program.  Where appropriate, processor 702 may include one or more arithmetic logic units (ALUs); be a multi-core
processor; or include one or more processors 702.  Although this disclosure describes and illustrates a particular processor, this disclosure contemplates any suitable processor.
<br/><br/> In particular embodiments, memory 704 includes main memory for storing instructions for processor 702 to execute or data for processor 702 to operate on one or more memory buses (which may each include an address bus and a data bus) may couple
processor 702 to memory 704.  Bus 712 may include one or more memory buses, as described below.  In particular embodiments, one or more memory management units (MMUs) reside between processor 702 and memory 704 and facilitate accesses to memory 704
requested by processor 702.  In particular embodiments, memory 704 includes random access memory (RAM).  This RAM may be volatile memory, where appropriate.  Where appropriate, this RAM may be dynamic RAM (DRAM) or static RAM (SRAM).  Moreover, where
appropriate, this RAM may be single-ported or multi-ported RAM.  This disclosure contemplates any suitable RAM.  Memory 704 may include one or more memories 704, where appropriate.  Although this disclosure describes and illustrates particular memory,
this disclosure contemplates any suitable memory.
<br/><br/> In particular embodiments, storage 706 includes mass storage for data or instructions.  As an example and not by way of limitation, storage 706 may include an HDD, a floppy disk drive, flash memory, an optical disc, a magneto-optical disc,
magnetic tape, or a Universal Serial Bus (USB) drive or a combination of two or more of these.  Storage 706 may include removable or non-removable (or fixed) media, where appropriate.  Storage 706 may be internal or external to computer system 700, where
appropriate.  In particular embodiments, storage 706 is non-volatile, solid-state memory.  In particular embodiments, storage 706 includes read-only memory (ROM).  This disclosure contemplates mass storage 706 taking any suitable physical form.  Storage
706 may include one or more storage control units facilitating communication between processor 702 and storage 706, where appropriate.  Where appropriate, storage 706 may include one or more storages 706.  Although this disclosure describes and
illustrates particular storage, this disclosure contemplates any suitable storage.
<br/><br/> In particular embodiments, I/O interface 708 includes hardware, software, or both providing one or more interfaces for communication between computer system 700 and one or more I/O devices.  Computer system 700 may include one or more of these
I/O devices, where appropriate.  One or more of these I/O devices may enable communication between a person and computer system 700.  As an example and not by way of limitation, an I/O device may include a keyboard, keypad, microphone, monitor, mouse,
printer, scanner, speaker, still camera, stylus, tablet, touch screen, trackball, video camera, another suitable I/O device or a combination of two or more of these.  An I/O device may include one or more sensors.  This disclosure contemplates any
suitable I/O devices and any suitable I/O interfaces 708 for them.  Where appropriate, I/O interface 708 may include one or more device or software drivers enabling processor 702 to drive one or more of these I/O devices.  I/O interface 708 may include
one or more I/O interfaces 708, where appropriate.  Although this disclosure describes and illustrates a particular I/O interface, this disclosure contemplates any suitable I/O interface.
<br/><br/> In particular embodiments, communication interface 710 includes hardware, software, or both providing one or more interfaces for communication (such as, for example, packet-based communication) between computer system 700 and one or more other
computer systems 700 or one or more networks.  As an example and not by way of limitation, communication interface 710 may include a network interface controller (NIC) or network adapter for communicating with an Ethernet or other wire-based network or a
wireless NIC (WNIC) or wireless adapter for communicating with a wireless network, such as a WI-FI network.  This disclosure contemplates any suitable network and any suitable communication interface 710 for it.  As an example and not by way of
limitation, computer system 700 may communicate with an ad hoc network, a personal area network (PAN), a local area network (LAN), a wide area network (WAN), a metropolitan area network (MAN), or one or more portions of the Internet or a combination of
two or more of these.  One or more portions of one or more of these networks may be wired or wireless.  As an example, computer system 700 may communicate with a wireless PAN (WPAN) (such as, for example, a BLUETOOTH WPAN), a WI-FI network, a WI-MAX
network, a cellular telephone network (such as, for example, a Global System for Mobile Communications (GSM) network), or other suitable wireless network or a combination of two or more of these.  Computer system 700 may include any suitable
communication interface 710 for any of these networks, where appropriate.  Communication interface 710 may include one or more communication interfaces 710, where appropriate.  Although this disclosure describes and illustrates a particular communication
interface, this disclosure contemplates any suitable communication interface.
<br/><br/> In particular embodiments, bus 712 includes hardware, software, or both coupling components of computer system 700 to each other.  Bus 712 may include one or more buses 712, where appropriate.  Although this disclosure describes and illustrates
a particular bus, this disclosure contemplates any suitable bus or interconnect.
<br/><br/> Herein, reference to a computer-readable storage medium encompasses one or more non-transitory, tangible computer-readable storage media possessing structure.  As an example and not by way of limitation, a computer-readable storage medium may
include a semiconductor-based or other integrated circuit (IC) (such, as for example, a field-programmable gate array (FPGA) or an application-specific IC (ASIC)), a hard disk, an HDD, a hybrid hard drive (HHD), an optical disc, an optical disc drive
(ODD), a magneto-optical disc, a magneto-optical drive, a floppy disk, a floppy disk drive (FDD), magnetic tape, a holographic storage medium, a solid-state drive (SSD), a RAM-drive, a SECURE DIGITAL card, a SECURE DIGITAL drive, or another suitable
computer-readable storage medium or a combination of two or more of these, where appropriate.  Herein, reference to a computer-readable storage medium excludes any medium that is not eligible for patent protection under 35 U.S.C.  .sctn.101.  Herein,
reference to a computer-readable storage medium excludes transitory forms of signal transmission (such as a propagating electrical or electromagnetic signal per se) to the extent that they are not eligible for patent protection under 35 U.S.C. 
.sctn.101.  A computer-readable non-transitory storage medium may be volatile, non-volatile, or a combination of volatile and non-volatile, where appropriate.
<br/><br/> This disclosure contemplates one or more computer-readable storage media implementing any suitable storage.  In particular embodiments, a computer-readable storage medium implements one or more portions of processor 702 (such as, for example,
one or more internal registers or caches), one or more portions of memory 704, one or more portions of storage 706, or a combination of these, where appropriate.  In particular embodiments, a computer-readable storage medium implements RAM or ROM.  In
particular embodiments, a computer-readable storage medium implements volatile or persistent memory.  In particular embodiments, one or more computer-readable storage media embody software.  Herein, reference to software may encompass one or more
applications, bytecode, one or more computer programs, one or more executables, one or more instructions, logic, machine code, one or more scripts, or source code, and vice versa, where appropriate.  In particular embodiments, software includes one or
more application programming interfaces (APIs).  This disclosure contemplates any suitable software written or otherwise expressed in any suitable programming language or combination of programming languages.  In particular embodiments, software is
expressed as source code or object code.  In particular embodiments, software is expressed in a higher-level programming language, such as, for example, C, Perl, or a suitable extension thereof.  In particular embodiments, software is expressed in a
lower-level programming language, such as assembly language (or machine code).  In particular embodiments, software is expressed in JAVA, C, or C++.  In particular embodiments, software is expressed in Hyper Text Markup Language (HTML), Extensible Markup
Language (XML), or other suitable markup language.
<br/><br/> Herein, "or" is inclusive and not exclusive, unless expressly indicated otherwise or indicated otherwise by context.  Therefore, herein, "A or B" means "A, B, or both," unless expressly indicated otherwise or indicated otherwise by context. 
Moreover, "and" is both joint and several, unless expressly indicated otherwise or indicated otherwise by context.  Therefore, herein, "A and B" means "A and B, jointly or severally," unless expressly indicated otherwise or indicated otherwise by
context.
<br/><br/> This disclosure encompasses all changes, substitutions, variations, alterations, and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend.  Similarly, where appropriate, the appended
claims encompass all changes, substitutions, variations, alterations, and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend.  Moreover, reference in the appended claims to an apparatus or
system or a component of an apparatus or system being adapted to, arranged to, capable of, configured to, enabled to, operable to, or operative to perform a particular function encompasses that apparatus, system, component, whether or not it or that
particular function is activated, turned on, or unlocked, as long as that apparatus, system, or component is so adapted, arranged, capable, configured, enabled, operable, or operative.
<br/><br/><center><b>* * * * *</b></center>
<hr/>
   <center>
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09275647&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D1142%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D23%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>
   <table>
   <tbody><tr><td align="center"><a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1142%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D23%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209275647"><img alt="[View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9275647&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D1142%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D23%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209275647">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
     <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1142&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=22&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1142&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=23&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1142&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=24&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1141&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=23&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=1143&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=23&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

   <a href="#top"><img alt="[Top]" border="0" src="/netaicon/PTO/top.gif" valign="middle"/></a>
   </td></tr>
   </tbody></table>
   <a name="bottom"></a>
   <a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
   </center>

</coma></body></html>