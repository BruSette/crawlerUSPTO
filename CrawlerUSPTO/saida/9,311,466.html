<html><head>
<base target="_top"/>
<title>United States Patent: 9311466</title></head>
<!---BUF1=9311466
BUF7=2016
BUF8=107801
BUF9=/1/
BUF51=9
---->
<body bgcolor="#FFFFFF">
<a name="top"></a>
<center>
<img alt="[US Patent &amp; Trademark Office, Patent Full Text and Image Database]" src="/netaicon/PTO/patfthdr.gif"/>
<br/>
<table>
<tbody><tr><td align="center">
<a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
<a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
<a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
<a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
</td></tr>
<tr><td align="center">
   <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=833&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=16&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=833&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=833&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=18&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=832&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=834&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

<a href="#bottom"><img alt="[Bottom]" border="0" src="/netaicon/PTO/bottom.gif" valign="middle"/></a>
</td></tr>
   <tr><td align="center">
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D833%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209311466"><img alt="[
View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9311466&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D833%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209311466">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09311466&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D833%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D17%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>

   </td></tr>
</tbody></table>
</center>
<table width="100%">
<tbody><tr><td align="left" width="50%"> </td>
<td align="right" valign="bottom" width="50%"><font size="-1">( <strong>833</strong></font> <font size="-2">of</font> <strong><font size="-1">7895</font></strong> <font size="-1">)</font></td></tr></tbody></table>
<hr/>
   <table width="100%">
   <tbody><tr>	<td align="left" width="50%"><b>United States Patent </b></td>
   <td align="right" width="50%"><b>9,311,466</b></td>
   </tr>
     <tr><td align="left" width="50%"><b>
         Headley
 </b>
     </td>
     <td align="right" width="50%"> <b>
     April 12, 2016
</b></td>
     </tr>
     </tbody></table>
       <hr/>
       <font size="+1">User authentication for social networks
</font><br/>
       <br/><center><b>Abstract</b></center>
       <p> Systems and methods are provided for social networks that can verify that
     enrolled users are not misrepresenting facts about themselves such as age
     and gender. Verification can be performed, for example, by reference to
     biometric templates stored during the user enrollment process. The
     biometric templates can also be used to authenticate users logging into
     the social network to prevent user impersonation. The ability of some
     users to communicate to other users of the social network can be limited
     to only certified users, and even to those certified users that match a
     criterion, such as gender or age.
</p>
       <hr/>
<table width="100%"> <tbody><tr> <th align="left" scope="row" valign="top" width="10%">Inventors:</th> <td align="left" width="90%">
 <b>Headley; Paul</b> (Hollister, CA) </td> </tr>
<tr><th align="left" scope="row" valign="top" width="10%">Applicant: </th><td align="left" width="90%"> <table> <tbody><tr> <th align="center" scope="column">Name</th> <th align="center" scope="column">City</th> <th align="center" scope="column">State</th> <th align="center" scope="column">Country</th> <th align="center" scope="column">Type</th> </tr> <tr> <td> <b><br/>Headley; Paul</b> </td><td> <br/>Hollister </td><td align="center"> <br/>CA </td><td align="center"> <br/>US </td> <td align="left"> </td>
</tr> </tbody></table>
<!-- AANM>
~AANM Headley; Paul
~AACI Hollister
~AAST CA
~AACO US
</AANM -->
</td></tr>
<tr> <th align="left" scope="row" valign="top" width="10%">Assignee:</th>
<td align="left" width="90%">

<b>K. Y. TRIX LTD.</b>
 (Kfar Mordechai, 
<b>IL</b>)
<br/>

</td>
</tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Family ID:
       </th><td align="left" width="90%">
       <b>42129256
</b></td></tr>
       <tr><th align="left" nowrap="" scope="row" valign="top" width="10%">Appl. No.:
       </th><td align="left" width="90%">
       <b>13/442,232</b></td></tr>
       <tr><th align="left" scope="row" valign="top" width="10%">Filed:
       </th><td align="left" width="90%">
       <b>April 9, 2012</b></td></tr>
     </tbody></table>
<hr/> <center><b>Prior Publication Data</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Document Identifier</u></b></th><th align="center" scope="col"><b><u>Publication Date</u></b></th></tr><tr><td align="center"> </td><td align="center"> US 20120198532 A1</td><td align="center">Aug 2, 2012</td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table>
<hr/> <center><b>Related U.S. Patent Documents</b></center> <hr/> <table width="100%"> <tbody><tr><th scope="col" width="7%"></th><th scope="col"></th><th scope="col"></th> <th scope="col"></th><th scope="col"></th><td></td></tr> <tr><td align="left">
</td><th align="center" scope="col"><b><u>Application Number</u></b></th><th align="center" scope="col"><b><u>Filing Date</u></b></th><th align="center" scope="col"><b><u>Patent Number</u></b></th><th align="center" scope="col"><b><u>Issue Date</u></b></th></tr><tr><td align="center"> </td><td align="center">12608190</td><td align="center">Oct 29, 2009</td><td align="center">8185646</td><td align="center"></td></tr><tr><td align="center"> </td><td align="center">61110878</td><td align="center">Nov 3, 2008</td><td align="center"></td><td align="center"></td></tr><tr><td align="center"> 
</td>
</tr> </tbody></table><td< td=""></td<><td< td=""></td<><td< td=""></td<>     <hr/>
<p> <table width="100%"> <tbody><tr><td align="left" valign="top" width="30%"><b>Current U.S. Class:</b></td> <td align="right" valign="top" width="70%"><b>1/1</b> </td></tr> 
       <tr><td align="left" valign="top" width="30%"><b>Current CPC Class: </b></td>
       <td align="right" valign="top" width="70%">G06F 21/32 (20130101); G10L 17/22 (20130101); H04L 67/306 (20130101)</td></tr>
         <tr><td align="left" valign="top" width="30%"><b>Current International Class: </b></td>
         <td align="right" valign="top" width="70%">G06F 15/16 (20060101); G10L 17/22 (20130101); G06F 21/32 (20130101); H04L 29/08 (20060101)</td></tr>
       <tr><td align="left" valign="top" width="30%"><b>Field of Search: </b></td>
       <td align="right" valign="top" width="70%">
       
 ;709/229
       </td></tr>
     </tbody></table>
</p><hr/><center><b>References Cited  <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2Fsearch-adv.htm&amp;r=0&amp;f=S&amp;l=50&amp;d=PALL&amp;Query=ref/9311466">[Referenced By]</a></b></center>       <hr/>
       <center><b>U.S. Patent Documents</b></center>
<table width="100%"> <tbody><tr><th scope="col" width="33%"></th> <th scope="col" width="33%"></th> <th scope="col" width="34%"></th></tr> <tr> <td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5033088">5033088</a></td><td align="left">
July 1991</td><td align="left">
Shipman</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5805674">5805674</a></td><td align="left">
September 1998</td><td align="left">
Anderson, Jr.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5841870">5841870</a></td><td align="left">
November 1998</td><td align="left">
Fieres et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F5958016">5958016</a></td><td align="left">
September 1999</td><td align="left">
Chang et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6009442">6009442</a></td><td align="left">
December 1999</td><td align="left">
Chen et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6021491">6021491</a></td><td align="left">
February 2000</td><td align="left">
Renaud</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6256630">6256630</a></td><td align="left">
July 2001</td><td align="left">
Gilai et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6262732">6262732</a></td><td align="left">
July 2001</td><td align="left">
Coleman et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6446210">6446210</a></td><td align="left">
September 2002</td><td align="left">
Borza</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6480304">6480304</a></td><td align="left">
November 2002</td><td align="left">
Os et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6480825">6480825</a></td><td align="left">
November 2002</td><td align="left">
Sharma et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6496206">6496206</a></td><td align="left">
December 2002</td><td align="left">
Mernyk et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6496595">6496595</a></td><td align="left">
December 2002</td><td align="left">
Puchek et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6501966">6501966</a></td><td align="left">
December 2002</td><td align="left">
Bareis et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6519561">6519561</a></td><td align="left">
February 2003</td><td align="left">
Farrell et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6529885">6529885</a></td><td align="left">
March 2003</td><td align="left">
Johnson</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6581042">6581042</a></td><td align="left">
June 2003</td><td align="left">
Pare, Jr. et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6671672">6671672</a></td><td align="left">
December 2003</td><td align="left">
Heck</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6697947">6697947</a></td><td align="left">
February 2004</td><td align="left">
Matyas, Jr. et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6766295">6766295</a></td><td align="left">
July 2004</td><td align="left">
Murveit et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6778644">6778644</a></td><td align="left">
August 2004</td><td align="left">
Jenkins et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6819219">6819219</a></td><td align="left">
November 2004</td><td align="left">
Bolle et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6886095">6886095</a></td><td align="left">
April 2005</td><td align="left">
Hind et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6907408">6907408</a></td><td align="left">
June 2005</td><td align="left">
Angel</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6934858">6934858</a></td><td align="left">
August 2005</td><td align="left">
Woodhill et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6944772">6944772</a></td><td align="left">
September 2005</td><td align="left">
Dozortsev</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F6993166">6993166</a></td><td align="left">
January 2006</td><td align="left">
Lo et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7171694">7171694</a></td><td align="left">
January 2007</td><td align="left">
Jespersen et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7240363">7240363</a></td><td align="left">
July 2007</td><td align="left">
Ellingson</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7277891">7277891</a></td><td align="left">
October 2007</td><td align="left">
Howard et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7305700">7305700</a></td><td align="left">
December 2007</td><td align="left">
Boynton et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7319987">7319987</a></td><td align="left">
January 2008</td><td align="left">
Hoffman et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7333635">7333635</a></td><td align="left">
February 2008</td><td align="left">
Tsantes et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7334259">7334259</a></td><td align="left">
February 2008</td><td align="left">
Haala</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7349557">7349557</a></td><td align="left">
March 2008</td><td align="left">
Tibor</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7352868">7352868</a></td><td align="left">
April 2008</td><td align="left">
Hawkes et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7383572">7383572</a></td><td align="left">
June 2008</td><td align="left">
Rolfe</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7461258">7461258</a></td><td align="left">
December 2008</td><td align="left">
Rolfe</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7522751">7522751</a></td><td align="left">
April 2009</td><td align="left">
White et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7545961">7545961</a></td><td align="left">
June 2009</td><td align="left">
Ahern et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7545962">7545962</a></td><td align="left">
June 2009</td><td align="left">
Peirce et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7617522">7617522</a></td><td align="left">
November 2009</td><td align="left">
Schmidt et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7634662">7634662</a></td><td align="left">
December 2009</td><td align="left">
Monroe</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7647498">7647498</a></td><td align="left">
January 2010</td><td align="left">
Brown et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7676439">7676439</a></td><td align="left">
March 2010</td><td align="left">
Tattan et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7685629">7685629</a></td><td align="left">
March 2010</td><td align="left">
White et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7689833">7689833</a></td><td align="left">
March 2010</td><td align="left">
Lange</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7690032">7690032</a></td><td align="left">
March 2010</td><td align="left">
Peirce</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7698322">7698322</a></td><td align="left">
April 2010</td><td align="left">
Langley</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7702918">7702918</a></td><td align="left">
April 2010</td><td align="left">
Tattan et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7788730">7788730</a></td><td align="left">
August 2010</td><td align="left">
Dean et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7797545">7797545</a></td><td align="left">
September 2010</td><td align="left">
Adams et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7835548">7835548</a></td><td align="left">
November 2010</td><td align="left">
Langley</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7865449">7865449</a></td><td align="left">
January 2011</td><td align="left">
Tattan et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7865937">7865937</a></td><td align="left">
January 2011</td><td align="left">
White et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7941380">7941380</a></td><td align="left">
May 2011</td><td align="left">
Tattan et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7987495">7987495</a></td><td align="left">
July 2011</td><td align="left">
Maler et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F7997972">7997972</a></td><td align="left">
August 2011</td><td align="left">
Nguyen et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8006291">8006291</a></td><td align="left">
August 2011</td><td align="left">
Headley et al.</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8166297">8166297</a></td><td align="left">
April 2012</td><td align="left">
Headley</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8185646">8185646</a></td><td align="left">
May 2012</td><td align="left">
Headley</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8347370">8347370</a></td><td align="left">
January 2013</td><td align="left">
Headley</td></tr><tr><td align="left">
<a href="/netacgi/nph-Parser?Sect2=PTO1&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;d=PALL&amp;RefSrch=yes&amp;Query=PN%2F8984282">8984282</a></td><td align="left">
March 2015</td><td align="left">
Kragh</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20020129251&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2002/0129251</a></td><td align="left">
September 2002</td><td align="left">
Itakura et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20020152179&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2002/0152179</a></td><td align="left">
October 2002</td><td align="left">
Racov</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20020174347&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2002/0174347</a></td><td align="left">
November 2002</td><td align="left">
Ting</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030005326&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0005326</a></td><td align="left">
January 2003</td><td align="left">
Flemming</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030140235&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0140235</a></td><td align="left">
July 2003</td><td align="left">
Immega et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030163710&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0163710</a></td><td align="left">
August 2003</td><td align="left">
Ortiz et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030163739&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0163739</a></td><td align="left">
August 2003</td><td align="left">
Armington et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20030236978&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2003/0236978</a></td><td align="left">
December 2003</td><td align="left">
Evans et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20040100362&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2004/0100362</a></td><td align="left">
May 2004</td><td align="left">
Mohamed et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20040158723&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2004/0158723</a></td><td align="left">
August 2004</td><td align="left">
Root</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20050091338&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2005/0091338</a></td><td align="left">
April 2005</td><td align="left">
de la Huerga</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20050114705&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2005/0114705</a></td><td align="left">
May 2005</td><td align="left">
Reshef et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060000896&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0000896</a></td><td align="left">
January 2006</td><td align="left">
Bonalle et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060021009&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0021009</a></td><td align="left">
January 2006</td><td align="left">
Lunt</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060041755&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0041755</a></td><td align="left">
February 2006</td><td align="left">
Pemmaraju</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060106734&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0106734</a></td><td align="left">
May 2006</td><td align="left">
Hoffman et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060129821&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0129821</a></td><td align="left">
June 2006</td><td align="left">
Zugenmaier et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060136219&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0136219</a></td><td align="left">
June 2006</td><td align="left">
Wang</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060136744&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0136744</a></td><td align="left">
June 2006</td><td align="left">
Lange</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060184800&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0184800</a></td><td align="left">
August 2006</td><td align="left">
Rosenberg</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060212717&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0212717</a></td><td align="left">
September 2006</td><td align="left">
Ito et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20060245619&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2006/0245619</a></td><td align="left">
November 2006</td><td align="left">
Sathath</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070022196&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0022196</a></td><td align="left">
January 2007</td><td align="left">
Agrawal</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070055517&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0055517</a></td><td align="left">
March 2007</td><td align="left">
Spector</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070061590&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0061590</a></td><td align="left">
March 2007</td><td align="left">
Boye et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070107016&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0107016</a></td><td align="left">
May 2007</td><td align="left">
Angel et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070107017&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0107017</a></td><td align="left">
May 2007</td><td align="left">
Angel et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070107021&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0107021</a></td><td align="left">
May 2007</td><td align="left">
Angel et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070136573&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0136573</a></td><td align="left">
June 2007</td><td align="left">
Steinberg</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070169182&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0169182</a></td><td align="left">
July 2007</td><td align="left">
Wolfond et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070175986&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0175986</a></td><td align="left">
August 2007</td><td align="left">
Petrone et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070186106&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0186106</a></td><td align="left">
August 2007</td><td align="left">
Ting et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070198435&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0198435</a></td><td align="left">
August 2007</td><td align="left">
Siegal et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070226516&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0226516</a></td><td align="left">
September 2007</td><td align="left">
Kubota et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070226787&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0226787</a></td><td align="left">
September 2007</td><td align="left">
Maletsky et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070241861&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0241861</a></td><td align="left">
October 2007</td><td align="left">
Venkatanna et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20070255963&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2007/0255963</a></td><td align="left">
November 2007</td><td align="left">
Pizano et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080052527&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0052527</a></td><td align="left">
February 2008</td><td align="left">
Siedlarz</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080077524&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0077524</a></td><td align="left">
March 2008</td><td align="left">
Greene</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080077525&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0077525</a></td><td align="left">
March 2008</td><td align="left">
Willey et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080077526&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0077526</a></td><td align="left">
March 2008</td><td align="left">
Arumugam</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080082451&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0082451</a></td><td align="left">
April 2008</td><td align="left">
Schneider et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080086319&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0086319</a></td><td align="left">
April 2008</td><td align="left">
Berger</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080086764&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0086764</a></td><td align="left">
April 2008</td><td align="left">
Kulkarni et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080091618&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0091618</a></td><td align="left">
April 2008</td><td align="left">
Obrea et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080113786&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0113786</a></td><td align="left">
May 2008</td><td align="left">
Alderucci et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20080141353&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2008/0141353</a></td><td align="left">
June 2008</td><td align="left">
Brown</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090052745&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0052745</a></td><td align="left">
February 2009</td><td align="left">
Sathath</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090116703&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0116703</a></td><td align="left">
May 2009</td><td align="left">
Schultz</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090119299&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0119299</a></td><td align="left">
May 2009</td><td align="left">
Rhodes</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090164796&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0164796</a></td><td align="left">
June 2009</td><td align="left">
Peirce</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090259588&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0259588</a></td><td align="left">
October 2009</td><td align="left">
Lindsay</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090313165&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0313165</a></td><td align="left">
December 2009</td><td align="left">
Walter</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20090327131&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2009/0327131</a></td><td align="left">
December 2009</td><td align="left">
Beenau et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20100029196&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2010/0029196</a></td><td align="left">
February 2010</td><td align="left">
Tan</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20100039218&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2010/0039218</a></td><td align="left">
February 2010</td><td align="left">
Cohen et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20100107230&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2010/0107230</a></td><td align="left">
April 2010</td><td align="left">
Tyagi et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20100146604&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2010/0146604</a></td><td align="left">
June 2010</td><td align="left">
Piccionelli</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20100312763&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2010/0312763</a></td><td align="left">
December 2010</td><td align="left">
Peirce</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110035788&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0035788</a></td><td align="left">
February 2011</td><td align="left">
White et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110185405&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0185405</a></td><td align="left">
July 2011</td><td align="left">
Ganesan</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110209200&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0209200</a></td><td align="left">
August 2011</td><td align="left">
White et al.</td></tr><tr><td align="left">
<a href="http://appft.uspto.gov/netacgi/nph-Parser?TERM1=20110231911&amp;Sect1=PTO1&amp;Sect2=HITOFF&amp;d=PG01&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsrchnum.html&amp;r=0&amp;f=S&amp;l=50" target="_blank">2011/0231911</a></td><td align="left">
September 2011</td><td align="left">
White et al.</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
       <center><b>Foreign Patent Documents</b></center>
<table width="100%"> <tbody><tr><td></td><th scope="col"></th> <td></td><th scope="col"></th> <td></td><th scope="col"></th></tr> <tr> <td align="left">
</td><td align="left">2278549</td><td></td><td align="left">
Jul 1998</td><td></td><td align="left">
CA</td></tr><tr><td align="left">
</td><td align="left">2399961</td><td></td><td align="left">
Apr 1999</td><td></td><td align="left">
CA</td></tr><tr><td align="left">
</td><td align="left">1868131</td><td></td><td align="left">
Dec 2007</td><td></td><td align="left">
EP</td></tr><tr><td align="left">
</td><td align="left">2379040</td><td></td><td align="left">
Feb 2003</td><td></td><td align="left">
GB</td></tr><tr><td align="left">
</td><td align="left">0156352</td><td></td><td align="left">
Aug 2001</td><td></td><td align="left">
WO</td></tr><tr><td align="left">
</td><td align="left">2009032036</td><td></td><td align="left">
Mar 2009</td><td></td><td align="left">
WO</td></tr><tr><td align="left">
</td><td align="left">2009127984</td><td></td><td align="left">
Oct 2009</td><td></td><td align="left">
WO</td></tr><tr><td align="left">
</td><td align="left">2010096628</td><td></td><td align="left">
Aug 2010</td><td></td><td align="left">
WO</td></tr><tr><td align="left">

</td>
</tr> </tbody></table>
<table width="90%">   <tbody><tr><td><align="left"><br/>Dictionary.com, definition of `associate`, Apr. 12, 2013, http://dictionary.reference.com/browse/associate?s=t&amp;path=/. cited by examiner
.<br/>EP 09824114.4 Response to Rules 70(2) and 70a(2) Communication, Nov. 25, 2013. cited by applicant
.<br/>International Search Report and Written Opinion, PCT/US09/43363 (May 8, 2009), dated Jul. 16, 2009. cited by applicant
.<br/>International Search Report and Written Opinion, PCT/US09/47049 (Jun. 11, 2009), dated Sep. 1, 2009. cited by applicant
.<br/>International Search Report and Written Opinion, PCT/US09/48842 (Jun. 26, 2009), dated Aug. 3, 2009. cited by applicant
.<br/>International Search Report and Written Opinion, PCT/US09/62490 (Oct. 29, 2009), dated Dec. 14, 2009. cited by applicant
.<br/>International Search Report and Written Opinion, PCT/US11/58974 (Nov. 2, 2011), dated Mar. 16, 2012. cited by applicant
.<br/>Vince Thomas et al., "Learning to Predict Gender from Iris Images," First IEEE International Conference on Biometrics: Theory, Applications, and Systems, Sep. 2007. cited by applicant
.<br/>Jain et al., Soft Biometric Traits for Personal Recognition Systems, http://www.springerlink.com/content/5gg1c23821cevbnk/. cited by applicant
.<br/>Ambalakat, Security of Biometric Authentication Systems, 2005, http://www.ewp.rpl.edu/hartford/.about.rhb/cs.sub.--seminar.sub.--2005/Se- ssionA1/ambalakat.pdf. cited by applicant
.<br/>EP 09747255.9 European Supplementary Search Report, dated Jun. 28, 2012. cited by applicant
.<br/>EP 12180301.9 Extended European Search Report, dated Dec. 6, 2012. cited by applicant
.<br/>Chenafa, M. et al., "Biometric System Based on Voice Recognition Using Multiclassifiers," Biometrics and Identity Management, Springer Berlin, pp. 206-215, May 5, 2008. cited by applicant
.<br/>Tan, T. G., "Phising Redefined--Preventing Man-in-the-Middle Attacks for Web-based Transactions," http://www.dssasia.com, Mar. 2005. cited by applicant
.<br/>EP 09824114.4 Extended European Search Report, Apr. 29, 2013. cited by applicant. </align="left"></td></tr> </tbody></table><br/><center><b>Other References</b></center> <br/>
       <i>Primary Examiner:</i> Avellino; Joseph E
<br/>
       <i>Assistant Examiner:</i> Conaway; James
<br/>
       <i>Attorney, Agent or Firm:</i> <coma>Peters Verny, LLP
<br/>
       <hr/>
       <center><b><i>Parent Case Text</i></b></center>
       <hr/>
       <br/><br/>CROSS-REFERENCE TO RELATED APPLICATIONS
<br/><br/> This application is a continuation of U.S. patent application Ser. No.
     12/608,190 filed Oct. 29, 2009, now U.S. Pat. No. 8,185,646 also entitled
     "User Authentication for Social Networks," and which claims the benefit
     of U.S. Provisional Patent Application 61/110,878 filed Nov. 3, 2008 and
     is also entitled "Identity Authentication for Social Networks," both of
     which are incorporated herein by reference. This application also
     incorporates by reference U.S. patent application Ser. No. 12/119,617
     filed May 13, 2008 and entitled "Multi-Channel Multi-Factor
     Authentication" and U.S. patent application Ser. No. 12/137,129 filed
     Jun. 11, 2008 and entitled "Single-Channel Multi-Factor Authentication."
         <hr/>
<center><b><i>Claims</i></b></center> <hr/> <br/><br/>What is claimed is: <br/><br/> 1.  A social network system comprising: enrollment logic comprising a first microprocessor and configured to associate users with user IDs, store a plurality of prompts in
association with each such user ID, store a plurality of biometric templates each in association with one of the plurality of prompts, compare a biometric template of the plurality of biometric templates of a first user against a plurality of biometric
templates of barred users, and deny enrollment to the first user based on a match between the biometric template of the first user and one of the plurality of biometric templates of barred users;  and authentication logic comprising a second
microprocessor and configured to authenticate a claimant as a second user by receiving a claimant target, sending a prompt from the plurality of prompts, receiving a biometric response to the prompt, and determining a match between the biometric response
and a biometric template associated with the prompt;  and further configured to receive a request from a third user of the social network to authenticate the second user of the social network;  and to send to the third user at least a portion of the
biometric response of the second user, or at least a portion of the biometric template of the second user.
<br/><br/> 2.  A method comprising: associating users of a social network with user IDs;  storing a plurality of prompts in association with each such user ID;  storing each such user ID in association with a biometric template of the respective user; 
comparing a biometric template of a first user against a plurality of biometric templates of barred users, and denying enrollment to the first user based on a match between the biometric template of the first user and one of the plurality of biometric
templates of barred users;  providing a prompt from the plurality of prompts to a second user and storing a biometric response of the second user thereto in association with the user ID of the second user;  receiving a request from a third user of the
social network to authenticate the second user of the social network;  and sending to the third user at least a portion of the biometric response of the second user, or at least a portion of the biometric template of the second user.
<br/><br/> 3.  The method of claim 2 wherein the steps of providing the prompt and storing the biometric response of the second user are steps that are performed to log into the second user's social network account.
<br/><br/> 4.  The method of claim 2 wherein the step of receiving the request from the third user is performed after the step of storing the biometric response of the second user. <hr/> <center><b><i>Description</i></b></center> <hr/> <br/><br/>BACKGROUND OF
THE INVENTION
<br/><br/> 1.  Field of the Invention
<br/><br/> The present invention relates generally to the field of authentication and more particularly to authenticating users of social networks.
<br/><br/> 2.  Description of the Prior Art
<br/><br/> Social networking Internet sites (hereinafter "social networks") such as MySpace and <b><i>Facebook</i></b> allow individuals to connect over the Internet for various purposes from business networking, to sharing common interests, to dating.  Individuals
generally have the ability to represent themselves however they choose, through these social networks, simply by creating an account and providing whatever details they would like to share with the other users of the social network.
<br/><br/> While many individuals are honest in their self-representations, other individuals attempt to pass themselves off as being older or younger than they really are, or of a different gender, for example.  Often, such misrepresentations are done for
the purpose of taking advantage of other users of the social network, especially children, sometimes for criminal ends.
<br/><br/> An additional problem that has arisen in social networks is the problem of impersonation, where someone gains unauthorized access to an existing account of a legitimate user.  With the unauthorized access, the impersonator can post content
and/or communicate with other users, typically in a manner that the legitimate user would find objectionable.  Such impersonations can both damage the reputation of the legitimate user and harm other users.
<br/><br/>SUMMARY
<br/><br/> The present invention provides various social network system.  In an exemplary social network system, the system comprises both enrollment logic and authentication logic.  The enrollment logic is configured to enroll users in the social network
by associating each user with a unique user ID, by further associating a plurality of prompts with each user ID, and by further associating a plurality of biometric templates each with one of the plurality of prompts.  The enrollment logic is further
configured to receive an indication of each user's gender and/or age and verify each user's gender by analyzing a biometric template from the plurality of biometric templates associated with each user.  In this way the enrollment logic can certify users. Users that do not wish to be enrolled in this manner may still be enrolled in the social network, but would not be treated as a certified user of the social network.
<br/><br/> In various embodiments the enrollment logic is further configured to enroll users by receiving an indication of the user's age and verifying the user's age by analyzing the same biometric template that was used to verify the user's gender.  In
other embodiments, the enrollment logic is further configured to compare a biometric template of each user against a plurality of biometric templates of barred users, and to deny enrollment to any user based on a match between their biometric template
and one of the plurality of biometric templates of a barred user.
<br/><br/> The authentication logic of the exemplary system is configured to authenticate a claimant as a particular user by receiving a claimant target, sending a prompt from a plurality of prompts associated with the claimant target, receiving a
biometric response to the prompt, and determining a match between the biometric response and a biometric template associated with the prompt.  Various embodiments of the exemplary system further comprise logic configured to authenticate a first user to a
second user by sending at least a portion of the biometric response of the first user, or at least a portion of a biometric template of first user, to the second user.
<br/><br/> The present invention also provides methods for maintaining a social network.  An exemplary such method comprises enrolling users in the social network, wherein enrolling users includes storing in association with a user ID for each enrolled
user a voice template, a facial recognition template, and either the user's gender or the user's age.  The exemplary method further comprises certifying enrolled users by using their voice template or their facial recognition template to verify their
gender and/or age, and indicating to users of the social network which other users are certified.  The exemplary method can further comprise restricting some users to communicate only with certified users, such as those that meet a criterion like gender
or age.
<br/><br/> The present invention also provides methods for enrolling a user in a social network.  An exemplary enrollment method comprises associating the user with a user ID, associating a plurality of prompts with the user ID, and associating a plurality
of biometric templates each with one of the plurality of prompts.  In various embodiments the method further comprises receiving an indication of the user's gender, age, or both, and then verifying the user's gender, age, or both by comparing the
indication of the gender and/or age with a result of an analysis of a biometric template from the plurality of biometric templates.  The comparison can be manual or automated in various embodiments.
<br/><br/> In still other embodiments of the enrollment method, in addition to, or in the alternative to receiving and verifying age and/or gender, the enrollment method comprises comparing a biometric template of the plurality of biometric templates of
the user against a plurality of biometric templates of barred users and denying enrollment to the user based on a match between the biometric template of the plurality of biometric templates and one of the plurality of biometric templates of the barred
users.
<br/><br/> The present invention also provides methods for preventing a first user from making certain misrepresentations in a social network.  An exemplary method comprises enrolling the first user by associating the first user with a user ID, associating
the user ID with a biometric template of the first user.  The exemplary method also comprises providing a prompt to the first user, and storing a biometric response of the first user thereto in association with the user ID.  The method further comprises
receiving a request from a second user of the social network to authenticate the first user of the social network, and sending to the second user at least a portion of the biometric response of the first user, or at least a portion of the biometric
template of the first user.  In various embodiments the at least the portion of the biometric response or biometric template of the first user comprises at least a portion of a biometric login response. <br/><br/>BRIEF DESCRIPTION OF DRAWINGS
<br/><br/> FIG. 1 is a schematic representation of an exemplary environment for carrying out various methods described herein.
<br/><br/> FIG. 2 is a flow-chart representation of an enrollment method according to an exemplary embodiment.
<br/><br/> FIG. 3 is a flow-chart representation of an exemplary authentication method according to an exemplary embodiment.
<br/><br/> FIG. 4 is a schematic representation of an authentication system according to an exemplary embodiment.
<br/><br/> FIG. 5 is a flow-chart representation of an exemplary method for a claimant to be authenticated according to an exemplary embodiment.
<br/><br/> FIG. 6 is a flow-chart representation of a method for preventing a user from making certain misrepresentations in a social network according to an exemplary embodiment.
<br/><br/> FIG. 7 is a flow-chart representation of a method for maintaining a social network according to an exemplary embodiment.
<br/><br/>DETAILED DESCRIPTION
<br/><br/> The present disclosure is directed to systems and methods for authenticating users of social networks to prevent or at least deter impersonation and misrepresentation.  Authentication for social networks can achieve these ends, according to the
present invention, by the use of an authentication system that employs a number of security features in combination, including some biometric security features.  These security features can be based, for example, on unique knowledge of the legitimate
user, a unique thing that the user has, unique personal features and attributes of the user, the ability of the user to respond, and to do so in a fashion that a machine cannot, that only a fraction of the authentication information is made available in
any one authentication attempt, and so forth.
<br/><br/> The methods described herein comprise an initial enrollment and subsequent authentications.  In the initial enrollment process, an enrollee user is associated with a user ID and that user ID is further associated with the address of a
communication device for the user.  The user is also asked to provide biometric samples in response to a plurality of different prompts.  The prompts and responses are also associated with the user ID.  After enrollment, a person seeking to be
authenticated, termed a claimant herein, first submits a claimant target which can be the user ID or some other unique identifier from which the authentication system can infer the particular identity sought to be authenticated.  One of the prompts
associated with the user ID is then provided to the claimant, the claimant provides a biometric response to the prompt, and that response is compared to the biometric sample previously associated with that prompt.  Within this simple framework a variety
of security features can be effectively employed.
<br/><br/> One such security feature is achieved through the use of biometrics which provides security based on the uniqueness of various personal features, attributes, and behaviors such as one's fingerprint, voice, eyes, face, genetic material, scent,
signature, and so forth.  Another security feature can be achieved through the use of responses to prompts which require the user's unique knowledge to respond correctly.  In some instances, multiple pairs of prompts and responses are stored, though only
one pair need be used for any authentication attempt.  In these embodiments, another security feature is realized because only a fraction of the authentication information is made available in any one authentication attempt.  Still another security
feature can be achieved by implementing a rule that the same prompt from the plurality of prompts cannot be used in successive authentications.  This rule makes it more difficult to record the biometric response from a legitimate authentication and
replay that response in a fraudulent authentication attempt.
<br/><br/> Yet another security feature can be achieved through the use of two channels of communication between the authentication system and the claimant.  To complete the authentication, a second communication channel is established using the device
address recorded during the enrollment process.  The second channel is different from the communication channel over which the authentication system received the claimant target.  Here, the prompt is provided to the claimant over the second channel,
and/or the biometric response to the prompt is returned to the authentication system over the second channel.  The use of the second channel to the device associated with the previously recorded device address makes fraudulent activity more difficult
because a party seeking to perpetrate a fraud would need to have access to some unique thing that the enrolled user has, such as a cell phone.  Still further security features, described in more detail below, can also be employed.
<br/><br/> Within the context of a social network, the invention can be used to prevent both impersonations and misrepresentations.  Turning first to the problem of impersonation, the invention can prevent a claimant from accessing the account of another
user without the authorization of that user in order to impersonate that user.  In a social network that implements the present invention, a user can choose to disclose their true identity or remain anonymous and only be identified by a screen name, for
example.  In either instance, however, the present invention assures that only the legitimate user can access their account and post content and communicate with others from that account.  An impersonator that approaches the social network as a claimant
will be prevented from logging into any account that the claimant is not authorized to access.
<br/><br/> According to the present invention, impersonation in social networks is prevented by requiring that users go through a brief enrollment process in which biometric templates such as facial recognition and voice templates are stored.  In the
enrollment process, some of these biometric templates are associated with prompts, as described above.  Subsequently, when a claimant seeks to access an existing account, the claimant is authenticated either using a multi-channel multi-factor
authentication process, or using a single-channel multi-factor authentication process as described in U.S.  patent application Ser.  Nos.  12/119,617 and 12/137,129, respectively.
<br/><br/> Turning next to the problem of misrepresentations in a social network, during the enrollment process users can make certain representations about themselves, whether they disclose their true identity or remain anonymous behind a fabricated
screen name.  Such representations include gender, age, race, hair color and so forth.  Embodiments of the present invention allow certain representations to be authenticated.  Users that are willing to have their representations verified by the social
network, in some embodiments, are classified as certified users.  Certified and uncertified users represent two classes of users in the social network, and the two classes can be afforded different rights and subjected to different rules by the social
network.
<br/><br/> For instance, the enrollment process can comprise an enrollee speaking to a video camera in response to a prompt.  Here, the authentication system 110 is able to capture both a facial recognition template and a voice template of the enrollee. 
The social network can then attempt to verify representations made during the enrollment process against these biometric templates.  In this way, a middle aged sexual predator cannot easily misrepresent himself as a teenage girl, for example.
<br/><br/> Verifications of representations made during the enrollment process, or subsequently, can be performed manually or automatically.  For example, a person acting on behalf of the social network can manually compare age and gender representations
made by an enrollee against the enrollee's facial recognition template and make a determination as to whether the enrollee is making false representations.  Some automated systems, such as VoiceVault, are able to estimate a person's age and determine the
person's gender based on voice samples.  Accordingly, the authentication system 110 can be configured to automatically screen enrollees to verify age and gender representations.  Representations that fail the screen, in some cases, can be reviewed by a
person acting on behalf of the social network.
<br/><br/> As already noted, in some embodiments, a social network that screens enrollees for misrepresentations can classify those users that pass the screening as certified users.  In some social networks, submission to the screening process is optional
so that an enrollee can opt to become a certified user or not, either at the time of enrollment or subsequently.  In those embodiments in which certification is optional, users can be enticed to become certified, for example, through rate reductions,
special offers, or the availability of additional features and/or services that are made available only to certified users.
<br/><br/> Certified users can be identified as such to other users of the social network, in some embodiments, for example with a frame around a profile picture.  Additionally, where a social network has a sub-population of certified users, the social
network can offer parental controls that limit contact to only certified users, and further, to only those certified users that fit one or more criteria.  In this way, a parent can limit a child's access through a social network to only those certified
users that are girls under the age of 20, for example.
<br/><br/> Within the context of a social network, the invention can also allow one user to authenticate a certified user to help the first user assess the certified user's trustworthiness before accepting messages, communications, content, or the like. 
For example, stored biometric templates or subsequent biometric responses to prompts made by the certified user can be viewed, in whole or in part, by other users before accepting contact or content form the certified user.  For instance, when a user
(certified or not) receives an invitation to join a group or share photographs, the social network can make available selected portions of a login video, for instance, of the certified user that is extending the invitation.
<br/><br/> It should be appreciated that empowering social network users to assess the trustworthiness of other users through stored biometric templates or biometric responses affords users an opportunity to see and hear another user and make a more
informed judgment as to whether to engage the other user.  The social network, in some embodiments, provides a mechanism by which a user can report suspected frauds or misrepresentations, either to the social network itself, and/or to other users, and/or
to police.
<br/><br/> Beyond the actual preventative actions noted above, the present invention can also have a deterrent effect on those seeking to either misrepresent themselves or impersonate others within a social network.  Enrollment and authentication logic
(see FIG. 4, below) can each be configured to require that the enrollee, or claimant, provide a video image and can be further configured to notify the enrollee or claimant that the biometric information being submitted is being recorded and stored. 
Thus, the enrollee or claimant is on notice that his image, and other biometric data such as voice samples, are being recorded and can be used like fingerprints from a crime scene to help identify the enrollee or claimant should the social network be
used for illegal purposes.  While such notice alone may not bar a claimant from making misrepresentations or attempting to impersonate another user, as noted elsewhere herein, such notice can provide a powerful deterrent against trying.
<br/><br/> FIG. 1 shows an exemplary environment 100 for carrying out various methods described herein.  The environment 100 comprises an authentication system 110 in communication with a first device 120 over a first communication channel 130, and in
communication with a second device 140 over a second communication channel 150.  The authentication system 110 can comprise one or more servers, data storage devices, workstations, and the like, networked together and configured to perform the functions
described herein.  The authentication system 110 is preferably implemented in a secure environment to prevent both external and internal tampering.  In some embodiments, the authentication system 110 is part of a social network computing system, such as
the computing systems that provide the functionality of a social network, like <b><i>FaceBook</i></b> and MySpace) to its users.  The authentication system 110 is configured to implement authentications, described in more detail with respect to FIG. 3, and in some
embodiments the authentication system 110 is also configured to implement user enrollment.  Alternatively, enrollment can be implemented by a separate system in communication with the authentication system 110.  The enrollment process is described in
detail with respect to FIG. 2.
<br/><br/> To implement an authentication, in various embodiments, the authentication system 110 receives a claimant target from the first device 120, sends a prompt to the second device 140, receives a biometric response from either the first device 120
or the second device 140, and compares the biometric response with the biometric sample that was previously associated with the prompt.  Biometric responses, as well as biometric samples which are also referred to herein as a biometric signatures or
biometric templates, are discussed in greater detail below.  Upon completion of a successful authentication, the authentication system 110 may communicate the successful result to either or both of the authenticated user and other parties to a
transaction.  The authentication system 110 is discussed further with respect to FIG. 4.
<br/><br/> The first device 120 is a communication device that can communicate a claimant target to the authentication system 110.  Exemplary first devices 120 include servers, personal computers (PCs), laptops, personal digital assistants (PDAs), cell
phones, smart phones (such as Treos, BlackBerries, etc.), kiosks, and so forth.  The claimant target can simply be, for example, the user ID associated with the user during the enrollment process.  The claimant target can also be a biometric input that
has been associated with the user ID, such as a scan of a fingerprint.  A biometric input can be indistinguishable from a biometric response (e.g., both can be an iris scan), but are referred to herein by separate terms to distinguish between their uses
in the various methods.  In other words, a biometric input is used as a claimant target to indicate the identity sought to be authenticated, while a biometric response is provided in response to a prompt sent from the authentication system to
authenticate the claimant.
<br/><br/> In those instances where the claimant target is a string of alphanumeric characters, an e-mail address, or the like, the first device 120 can comprise a keypad, keyboard, touch-sensitive screen, or the like on which the claimant target can be
entered.  Where the claimant target is a biometric input, the first device 120 can comprise a camera capable of taking still images and/or providing video images.  The first device 120 can also include other biometric entry devices such as a touch pad
for recording signatures, an iris scanner, a fingerprint reader, and so forth.  Biometric inputs and responses are discussed in greater detail below.
<br/><br/> It should be noted that in some instances the claimant sends the claimant target from the first device 120, while in other instances another party to the transaction, such as a merchant, a financial institution, or another individual sends the
claimant target to/from the first device 120.  Thus, in the former situation the first device 120 may be a device in the claimant's home, such as a PC, interactive TV system, gaming console, or the like, or a hand-held device that the claimant carries,
such as a smart phone or PDA.  The claimant can also send the claimant target from a first device 120 such as a kiosk or a terminal in a retail store, for example.  In the latter situation, where the other party sends the claimant target, the first
device 120 may be physically remote from the claimant, such as a web server (this is sometimes referred to as a Cardholder-Not-Present (CNP) transaction environment).  In some of these embodiments, the first device 120 stores the claimant target (e.g.,
an on-line retailer can store the claimant targets of registered shoppers for their convenience) or receives the claimant target from the claimant at the beginning of the authentication process.  In still other embodiments, the first device 120 can be a
surveillance station, such as a closed-circuit TV (CCTV) camera, that sends a video feed to the authentication system.  The video feed includes images of faces of people, and those images constitute claimant targets.  As one example, a store can monitor
people entering through a door and begin the authentication process for quicker and easier checkout.
<br/><br/> The second device 140 is something the enrolled user possesses, or at least has ready access to.  Exemplary second devices 140 include cell phones, PDAs, smart phones, pagers, PCs, home phones, etc. The second device 140 is something that is
unique to the user in as much as the second device 140 is characterized by a unique device address such as a phone number, IP address, URL, e-mail address, etc. In various embodiments, the second device 140 is able to receive and render a prompt from the
authentication system 110 and/or transmit a response thereto.  The prompt can be provided by the second device 140 visually, aurally, or in combination, for example.  For instance, the prompt can be displayed as a text message, a verbal command or cue,
an audio clip, a video clip, etc. In some instances, the second device 140 can be used by the claimant to provide the biometric response to the authentication system 110.  Towards this end, the second device 140 can include a camera capable of taking
still images and/or providing video images.  The second device 140 may also include other biometric entry devices such as the ones noted above.
<br/><br/> It should be appreciated that the use of still images or video images as the biometric response for authentication purposes provides a powerful security feature, in some embodiments.  In particular, part of the prevalence of identity theft and
electronic fraud lies in the anonymity associated with electronic transactions.  It is a very strong deterrent to such malfeasance, however, to have to expose one's face to surveillance in order to perpetrate the fraudulent activity.  With the advent of
readily available and inexpensive webcams and cameras on cell phones, for example, the widespread implementation of a system that employs video for biometric responses becomes practical.
<br/><br/> This is especially useful for social networks, where a need has existed since the inception of on-line communities for the ability for users to positively authenticate one another.  Presently, the typical login system that requires a combination
of a username and a password does not provide positive authentication of users to the extent that one user cannot tell whether the other user is misrepresenting them self or impersonating another.  Thus, even if a user of a social network chooses to
employ a screen name and otherwise remain anonymous (i.e., not positively identified), the user still records biometric responses that allows the person to log back into the social network, and that can optionally be shown to other users and/or used to
prevent the login and the re-enrollment of users that should become barred from the social network.  Thus, the present invention provides social networks the ability to positively authenticate users at login, allows users the ability to positively
authenticate each other, and allows the social network the ability to exclude users that violate rules, for example.
<br/><br/> The first and second communication channels 130, 150, extend between the authentication system 110 and the first and second devices, 120, 140, respectively.  The first and second communication channels 130, 150 can be fully duplexed and can each
comprise connections made through networks, represented generally by clouds in FIG. 1, such as the public switched telephone network (PSTN), wireless telephone networks, the Internet, wide area networks (WANs) and local area networks (LANs).  It should
be noted that although each of the first and second communication channels 130, 150 are represented in FIG. 1 as connecting through only one such cloud, either communication channel 130 or 150 can comprise a connection through more than one network and
both communication channels 130 and 150 can cross the same network.
<br/><br/> It will also be understood that the authentication system 110 can comprise further channels to facilitate communications with other parties to a transaction with a claimant.  As described more fully below, a merchant may request an
authentication over a third channel (not shown), the authentication then proceeds over the first and second channels 130 and 150 between the claimant and the authentication system 110, and then confirmation of the authentication is sent to the merchant
over the third channel.
<br/><br/> FIG. 2 illustrates an exemplary method 200 for enrolling a user, for example, into an on-line community such as a social network.  The method 200 comprises a step 210 of associating a user with a user ID, a step 220 of associating the user ID
with a device address, a step 230 of associating the user ID with a plurality of prompts, and a step 240 of associating each of the plurality of prompts with a biometric template or signature of the user.  The method 200 can also comprise, in some
embodiments, a step of obtaining a biometric template of the user that is not associated with any of the prompts.  The method 200 can be implemented, in some embodiments, by communicating with an enrollee user through a kiosk or over the Internet.  It
should be appreciated that method 200 can be fully performed by a computing system interacting with the enrollee user and does not require, in some embodiments, the intervention of a trusted individual acting on behalf of the on-line community.
<br/><br/> In the step 210, the enrollee user is associated with a user ID.  This can comprise, for example, assigning a unique numeric or alphanumeric code to the user, or having the user select a unique numeric or alphanumeric code.  In some embodiments
a password is optionally assigned to, or selected by, the user as an additional security feature.  The user ID can also be, in some instances, a biometric template.  For example, a file containing a list of features extracted from the user's fingerprint
(i.e., a fingerprint template) is one such possible user ID.  In some embodiments more than one user ID is associated with the user so that the user can seek authentication multiple ways, such as by entering a code or presenting a finger to a scanner,
for example.  Step 210 can further comprise providing the user with a token including the user ID, such as a magnetic swipe card, a fob, an RFID tag, etc.
<br/><br/> As described in the subsequent steps of the method 200, the user ID is further associated with additional information pertaining to the enrollee user.  The user ID and such further information can be stored as records in relational databases, or
in other data storage configurations, for later retrieval during an authentication.  In addition to the information described below in steps 210-250, other information that can be associated with the user ID through the enrollment method 200 includes
addresses, spending limits, access levels, and other third party management information system attributes.  Such additional information can be stored locally, or can constitute a link or pointer to a record in an external database.
<br/><br/> In step 220 a device address is associated with the user ID.  The device address is unique to a communication device that the user has, or has ready access to, such as the second device 140 (FIG. 1).  Step 220 can include receiving the device
address from the user, for example, where the user enters the device address into a text box in an on-line enrollment form.  In some embodiments, receiving the device address from the user comprises reading the device address directly from the
communication device.  In some instances, where the user has more than one communication device, a device address for each can be associated with the user ID.
<br/><br/> The user ID is further associated with a plurality of prompts in step 230.  The prompts can include common prompts such as "Say your mother's maiden name," and "Sign your name on the signature pad." In some embodiments, the user selects some or
all of the plurality of prompts from a list of predefined prompts such as the common prompts noted above.  The prompts selected by the user are then associated with the user ID.  In other embodiments, a plurality of predefined prompts is automatically
assigned to the user.  In some embodiments, still other prompts that can be associated with the user ID are personalized prompts.  As used herein, a personalized prompt is a prompt created by the user, for example, "Say the rhyme your daughter loves."
The personalized prompts can be recorded in the user's own voice, or entered as text, for example.  The number of prompts in the plurality of prompts can be two or more, but preferably is a number that strikes a balance between the security offered by
greater numbers of prompts and the burden on the user to enroll large numbers of prompts and associated responses.  In some embodiments, the number of prompts is 5, 6, 7, 8, 9, or 10 at the time of enrollment, and may be increased subsequently.
<br/><br/> It should be appreciated that the use of a personalized prompt for authentication purposes provides a powerful security feature, in some embodiments.  In particular, part of the prevalence of identity theft and electronic fraud lies in the
availability of information through contracts and electronic databases.  Prompts including questions such as "what is your mother's maiden name?" and "what is the name of your youngest sibling?" are easily discovered through contracts or Internet
searches.  A personalized prompt such as "color of my teenage dream car" is not readily known and whose response cannot be easily identified even by a spouse.  With the increase in identity theft and a significant part of identity theft being perpetrated
by family members, personalized prompts present a significant hurdle for even a person's closest associates.
<br/><br/> In step 240 each of the plurality of prompts is associated with a biometric template of the enrollee user.  For example, where the prompt is an instruction to say some word or phrase, the biometric template can be a voice template derived from
the user saying the word or phrase.  Here, associating the prompt with the biometric template can include providing the prompt to the user and receiving audio data (e.g., a .wav file) of the user's response.  Associating the prompt with the biometric
template can further include, in some instances, processing the received audio data to extract the biometric template.  The biometric template can be, in some embodiments, a filtered or enhanced version of the originally received audio data, such as with
background noise removed, or averaged over multiple repetitions by the user.  The biometric template can also include a set of markers or values derived from the audio data.
<br/><br/> Other examples of biometric templates include fingerprint templates derived from users' fingerprints; signature templates derived from users' signatures, and in some instances also derived from aspects of the act of creating the signature such
as rate and pressure of the writing implement as a function of time; facial recognition templates derived from still or video images of users' faces; iris scan templates derived from users' iris scans; and so forth.  A biometric template can also
comprise an unprocessed biometric response, such as a .wav file of the user's voice, a .jpg file of an image of the user's face, etc. Both biometric templates and prompts can be stored in association with the user ID in a database, for example.
<br/><br/> It will be appreciated that the biometric template associated with any particular prompt need not make sense to anyone other than the user, adding still another security feature in some cases.  For example, the user can create the prompt "Monday
morning" and associate with that prompt a biometric template derived from saying "marvelous marigolds." Even if someone were to sample enough of the user's voice to reasonably model the user's voice, it would be virtually impossible to know the correct
response to the particular prompt.
<br/><br/> In some embodiments step 240 includes the use of voice recognition.  Voice recognition is distinguished here from voice identification in that voice recognition can distinguish spoken words independent of the speaker, whereas voice
identification associates the individual with the acoustics of the phrase without regard for the meaning of the words spoken.  Thus, for instance, a user can create a personalized prompt by saying a phrase and then voice recognition can be employed by
the authentication system to extract the phrase from a recording of the user saying the phrase.  The extracted phase can then be stored as the biometric template, as a component of the biometric template, or as a completely separate record.  Likewise,
the system can prompt the user to say a few randomly selected words and use voice recognition to verify those words were spoken.  In addition, voice identification (biometric comparison) can be applied to the same sample to insure that the user spoke the
randomly selected words thus verifying authenticity of the response.
<br/><br/> Step 250 is an optional step that comprises obtaining a biometric template of the user that is not associated with any of the prompts.  For example, enrolling the user can comprise capturing a digital image of the user's face.  The image can be
associated with the user ID but not with any particular prompt.  Should the user have problems with a subsequent authentication and end up speaking with a live operator, provided that the communication with the live operator is over a video conference or
something similar, then the operator can compare the stored digital image of the user's face with the image of the claimant.  Additionally, method 200 can optionally comprise associating additional user information with the user ID.  Examples of
additional user information include home address, home phone number, credit card numbers, system preferences and user settings, and so forth.
<br/><br/> In some embodiments, the enrollment method 200 optionally includes a step 260 of verifying the gender of the enrollee user.  Step 260 can comprise, in some embodiments, receiving an indication of the enrollee user's gender, and comparing the
indication with the result of an analysis of a biometric template from the plurality of biometric templates.  An example of an indication of the enrollee user's gender can be, for example, a representation of gender made through an on-line enrollment
form.  Some automated systems, such as VoiceVault, are able to determine a person's gender based on voice samples.  An analysis by such an automated system of a voice sample, such as a biometric voice template made by the enrollee user, yields a result,
either male or female, that can be compared against the indication of gender to verify the gender.  In the alternative to the automated analysis, a manual comparison can be performed in step 260 in which a human evaluates the biometric template for
gender and compares the result to the indication of gender from the enrollee user.
<br/><br/> In some embodiments, the enrollment method 200 optionally includes a step 270 of verifying the age of the enrollee user.  Step 270 can comprise, in some embodiments, receiving an indication of the enrollee user's age, and comparing the
indication with the result of an analysis of a biometric template from the plurality of biometric templates.  An example of an indication of the enrollee user's age can be, for example, a representation of age made through an on-line enrollment form. 
Some automated systems, such as VoiceVault, are able to estimate a person's age based on voice samples.  An analysis by such an automated system of a voice sample, such as a biometric voice template made by the enrollee user, yields a result, such as an
age range, that can be compared against the indication of age to verify the age.  In the alternative to the automated analysis, a manual comparison can be performed in step 260 in which a human evaluates the biometric template for age and compares the
result to the indication of age from the enrollee user.
<br/><br/> Yet another optional step 280 comprises verifying that the enrollee user has not been barred from the social network.  For example, step 280 can comprise comparing a biometric template of the plurality of biometric templates of the first user
against a plurality of biometric templates of barred users.  If the result of the comparison is a match, indicating that the enrollee user is the same individual as one who has previously been barred from the social network, than enrollment can be denied
to the enrollee user based on the match.
<br/><br/> FIG. 3 illustrates an exemplary method 300 for authenticating a claimant, such as a user of a social network seeking to log back in to their account.  The method 300 comprises a step 310 of receiving a claimant target over a first channel, a
step 320 of retrieving a device address associated with the user ID, an optional step 330 of selecting a prompt from a plurality of prompts where each of the plurality of prompts is associated with a biometric template of a user, and a step 340 of
sending a prompt, such as the prompt selected in step 330, over a second channel to a device associated with the device address.  The method 300 further comprises a step 350 of receiving a biometric response to the prompt, and a step 360 of determining a
match between the biometric response and a biometric template associated with the prompt sent over the second channel.
<br/><br/> In step 310 a claimant target is received over a first channel.  In some embodiments the claimant target comprises a user ID, while in other embodiments the method 300 further comprises determining the user ID from the claimant target.  In some
embodiments where the claimant target comprises the user ID, the user ID can be a numeric or alphanumeric character string, for example, such as an e-mail address or a user name selected by an enrollee user during the enrollment method 200 (FIG. 2).  In
other embodiments where the claimant target comprises the user ID, the user ID is a template such as a fingerprint template or an iris scan template.  As one example, a fingerprint scanner on a kiosk scans the claimant's fingerprint, reduces the scan to
a fingerprint template, and then sends the template to the authentication system which receives the template as the claimant target.
<br/><br/> As note previously, in some instances the claimant target is not the user ID itself, and in these embodiments the method 300 further comprises determining the user ID from the claimant target.  Returning to the prior example of the claimant at
the kiosk, the kiosk could instead transmit to the authentication system the scan of the fingerprint without further processing.  Here, the authentication system would further determine the user ID from the claimant target by reducing the scan to the
fingerprint template.
<br/><br/> In some embodiments, step 310 also comprises receiving an authentication request, which in some embodiments precedes receiving the user ID and in some embodiments includes the user ID.  For example, a claimant seeking to complete a transaction
with another party can send an authentication request including her user ID to the authentication system.  Similarly, the authentication request, including the user ID, may come from another party, such as a merchant.  In still other embodiments, either
the claimant or the other party to the transaction can make the request for authentication and subsequently the claimant is prompted by the authentication system to submit the user ID.  It should be noted that in some embodiments that claimant also
supplies a password with the user ID, while in other embodiments a password is not required.  Thus, in these latter embodiments, step 310 specifically does not comprise receiving a password.
<br/><br/> After step 310, a device address associated with the user ID is retrieved in step 320.  The device address can be retrieved, for example, from a database that associates device addresses with user IDs.  Step 320 can also comprise retrieving a
record associated with the user ID, where the record includes one or more device addresses as well as other information such as prompts and biometric templates.
<br/><br/> In optional step 330 a prompt is selected from a plurality of prompts, where each of the plurality of prompts has a biometric template of the claimant associated therewith.  In some embodiments, the plurality of prompts is ordered, say from
first to last, and the act of selecting the prompt simply comprises identifying the next prompt in the order based on the last prompt used.  Other embodiments employ randomization algorithms.  A rule can be implemented, in some embodiments, that the same
prompt from the plurality of prompts cannot be used in successive authentications.  Similar rules can be implemented to prevent the same prompt from being employed twice within any three authentications, and so forth.  Yet another rule that can be
implemented applies where several of the biometric templates each include voice data comprising at least two syllables.  Here, the rule requires that the same two syllables used in one authentication cannot be used in the next subsequent authentication.
<br/><br/> In step 340, a prompt is sent over a second channel to a device associated with the device address.  The device may be a cell phone, PDA, smart phone, PC, and so forth.  In the limiting case where there is only a single prompt associated with
the user ID, for example, the step 330 of selecting a prompt from a plurality of prompts is unnecessary and step 340 simply comprises sending the one prompt.  Where the prompt is selected in step 330 from a plurality of prompts, step 340 comprises
sending the selected prompt.  In some instances, the prompt is sent in a text message according to the Short Message Service (SMS) communications protocol.  In other embodiments, the prompt is delivered as a voice transmission such as an audio recording
or as synthesized speech.  The prompt can similarly comprise a video transmission.  The prompt can also be sent as an e-mail or an Instant Message.
<br/><br/> It should be noted that instructions can also be sent to the claimant, over either channel, in addition to the prompt.  As one example, the claimant submits a claimant target over a first channel from a PC, and receives a prompt on her cell
phone over a second channel.  The prompt is a text message of the word "Rosebud." An instruction can be sent over the first channel to be displayed on the PC such as "A prompt has been sent to you.  After the red light appears on your screen, face the
webcam and provide your response to the prompt." Still another security feature lies in the fact that it is not readily apparent from an instruction how the prompt should be received.  Someone intercepting the instruction would not readily know whether
the prompt was sent to a web browser, in an e-mail, or to a mobile device, for example.
<br/><br/> After step 340, a claimant receives the prompt and acts accordingly to produce some biometric response.  For example, the claimant can speak to a microphone, present her face or another body part to a camera, make a gesture in front of a camera,
press her finger on a fingerprint scanner, present her eye to a retinal scanner, write on a touch-sensitive pad, or combinations of these.  The biometric response is therefore some product of the claimant's actions such as a voice data, a fingerprint
scan, retinal scan, or an image of the person's face or body part, for example.  The biometric response can comprise unprocessed data, partially processed data, or can be completely reduced to a template, for example.
<br/><br/> The method 300 further comprises the step 350 of receiving the biometric response to the prompt.  The biometric response can be received from the same device that received the prompt, or in other embodiments from the same device that sent the
claimant target.  The biometric response may even be received from a third device over some third channel, in some embodiments.
<br/><br/> Step 360 comprises determining a match between the biometric response and a biometric template associated with the prompt sent over the second channel.  In a simple example, the biometric template comprises a facial recognition template of a
user and the biometric response comprises a segment of streaming video that includes frames showing the claimant's face.  Here, determining the match comprises extracting a facial recognition template of the claimant's face from the frames of the video
segment and comparing that facial recognition template to the original facial recognition template of the user.
<br/><br/> It will be appreciated, moreover, that step 360 can comprise matching more than one biometric template to the biometric response.  For instance, in the above example, the segment of streaming video can also include the claimant saying a phrase. 
Here, a voice template can be extracted in addition to extracting a facial recognition template.  In this example a match can be determined between a voice template and the voice in the video, and a match can be determined between a face template and the
face in the video.
<br/><br/> In various embodiments, determining the match between the biometric response and the biometric signature comprises determining a figure of merit that characterizes the agreement between the biometric response and the biometric template, and then
comparing that figure of merit to a threshold.  If the figure of merit exceeds the threshold, or in some instances equals or exceeds the threshold, then the match has been determined.  Where more than one biometric template is compared to the biometric
response, in some embodiments, a figure of merit for each biometric template is calculated and each figure of merit is compared to the relevant threshold.
<br/><br/> In those embodiments where the biometric response comprises a vocal response from the claimant, determining the match between the biometric response and the biometric template in step 360 can comprise performing voice recognition on the
biometric response to determine whether the correct word or words were spoken.  Voice recognition has the benefit of being less computationally intensive than voice identification, therefore, a useful screen can be to employ voice recognition to
determine whether the correct word or words are present in a biometric response.
<br/><br/> If the match cannot be determined, an optional step of the method 300 comprises repeating method 300 beginning at step 320, preferably by selecting a different prompt in step 330 than in the previous iteration.  Another optional step if the
match cannot be determined comprises establishing a live interview between the claimant and a customer service representative.  The customer service representative, in some instances, has the authority to authenticate the claimant based on the interview. As noted previously, the customer service representative may be able to employ biometric templates that are not associated with any of the prompts to decide whether to authenticate the claimant.
<br/><br/> FIG. 4 shows an exemplary embodiment 400 of the authentication system 110 (FIG. 1).  The authentication system 400 of FIG. 4 comprises logic 410 configured to enroll users, login authentication logic 420 configured to authenticate claimants, and
optionally inter-user authentication logic 430 configured to authenticate one user to another.  In various embodiments, logics 410, 420, and 430 each can comprise hardware, firmware, software stored on a computer readable medium, or combinations thereof. Logics 410, 420, and 430 may include a computing system such as an integrated circuit, a microprocessor, a personal computer, server, distributed computing system, communication device, network device, or the like.  For example, logics 410, 420, and 430
can be implemented by separate software modules executed on a common server.  In other embodiments, logics 410, 420, and 430 can be implemented on different computing systems.  Logics 410, 420, and 430 can also be at least partially integrated together.
<br/><br/> The authentication system 400 can also comprise, as part of the logics 410, 420, and 430 or separate therefrom, volatile and/or non-volatile memory such as random access memory (RAM), dynamic random access memory (DRAM), static random access
memory (SRAM), magnetic media, optical media, nano-media, a hard drive, a compact disk, a digital versatile disc (DVD), and/or other devices configured for storing digital or analog information.  Logic 410 can comprise, for instance, volatile and/or
non-volatile memory as the computer readable medium on which software is stored for performing the methods described herein.  Other volatile and/or non-volatile memory can comprise databases or other means for maintaining information about enrolled users
including prompts, biometric templates, biometric responses supplied in response to prompts, device addresses, and the like that are accessed by the logics 410, 420, and 430.  Such information can be created and revised by login authentication logic 420
and accessed by enrollment logic 410 and inter-user authentication logic 430.
<br/><br/> The authentication system 400 can also comprise communications logic (not shown) that allows the logics 410, 420, and 430 to communicate, for example, with the first device 120 (FIG. 1) over the first communication channel 130 (FIG. 1) and the
second device 140 (FIG. 1) over the second communication channel 150 (FIG. 1).  In some embodiments the communications logic allows the login authentication logic 420 to interface with multiple devices in parallel to support the simultaneous enrollment
of multiple users.  At the same time, the communications logic allows the logic 410 to independently interface with multiple other devices to support the simultaneous authentication of multiple claimants.
<br/><br/> The enrollment logic 410 is configured to enroll a user by performing an enrollment method such as method 200 (FIG. 2).  In an exemplary embodiment, the enrollment logic 410 is configured to associate the user with a user ID, associate the user
ID and with a device address, associate a plurality of prompts with the user ID, and associate a number of biometric templates each with one of the plurality of prompts.  The enrollment logic 410, in some embodiments, is configured to associate the
plurality of prompts with the user ID by presenting a set of pre-defined prompts to the user and receiving a selection of the plurality of prompts from the set.  In additional embodiments, the enrollment logic 410 is further configured to allow the user
to create a personalized prompt.  The enrollment logic 410 can also comprise a computer readable medium that stores software instructions for performing these steps.
<br/><br/> The login authentication logic 420 is configured to authenticate a claimant by performing an authentication method such as method 300 (FIG. 3) before providing the claimant with access to a particular account in a social network, in some
embodiments.  In an exemplary embodiment, the login authentication logic 420 is configured to receive a claimant target over a first channel, retrieve a device address associated with a user ID, send a prompt from the plurality of prompts to a device
associated with the device address over a second channel, receive a biometric response to the prompt, and determine a match between the biometric response and a biometric template associated with the prompt.  In some embodiments the claimant target
comprises the user ID, while in other embodiments the authentication logic is further configured to determine the user ID from the claimant target.  The authentication logic is further configured to send a key, in some instances, where the key can be
used for encryption and/or creating a watermark.  In some of these embodiments the prompt includes the key when sent.  Encryption and watermarking are described in greater detail below.  The login authentication logic 420 can also comprise a computer
readable medium that stores software instructions for performing these steps.
<br/><br/> The inter-user authentication logic 430 is configured to authenticate one user to another.  For example, a first user sends an invitation to a second user.  The second user recognizes the screen name of the first user as one used by a personal
friend.  Still, the nature of the invitation seems odd to the second user, so the second user requests authentication of the first user.  The authentication logic 430 receives the request and in response sends to the second user at least a portion of
either a biometric response of the first user, or at least a portion of a biometric template of the first user.  The portion of the biometric response can be, for example, part of the biometric response given to the login authentication logic 420 during
the most recent login by the first user.  The portion of the biometric template of the first user can be, for example, all or part of the biometric template of the user that was acquired in step 250 and not associated with a prompt.  The second user can
then see, for example, a video of the first user and confirm that it is the personal friend.
<br/><br/> Similarly, the second user may not recognize the screen name of the first user, but the first user is certified.  Again, the inter-user authentication logic 430 receives a request for authentication of the first user and sends in response at
least a portion of either a biometric response of the first user, or at least a portion of a biometric template.  By viewing the content from the inter-user authentication logic 430, the second user can better decide whether to accept the invitation from
the first user.
<br/><br/> FIG. 5 shows an exemplary authentication method 500 that can be performed, for example, by a claimant such as to access an on-line account in a social network.  The method 500 comprises a step 510 of submitting a claimant target over a first
channel, a step 520 of receiving a prompt on a device, and a step 530 of submitting a biometric response to the prompt.  In method 500, one of the two steps of receiving the prompt and submitting the biometric response is performed over a second channel. In some embodiments, the claimant performing the method 500 only has to perform these three steps to be authenticated.  As was the case with the enrollment method 200, it should be appreciated that method 500 can also be performed in the absence of a
trusted individual acting on behalf of the on-line community.  In other words, whereas prior authentication systems rely on the presence of a trusted individual to assess authenticity, in method 500 the claimant does not need to interact with a trusted
individual but can interact instead merely with a computing system.
<br/><br/> In step 510, the claimant submits the claimant target, such as the user ID, to an authentication system, for example, or to some intermediary such as a merchant that then relays the claimant target to the authentication system.  Since the method
500 can be performed by a claimant seeking to complete an electronic transaction from home, work, or in public, in step 510 the claimant can submit the claimant target from a PC at home, from a kiosk in a shopping mall, or from at a terminal at a store
check-out, for example.  The claimant can submit the claimant target, according to various embodiments, by entering numbers and/or letters with a keyboard or keypad, swiping a magnetic card through a card reader, bringing an RFID tag within range of an
RFID reader, writing with a stylus on a touch-sensitive pad, placing a finger on a fingerprint reader, speaking within range of a microphone, smiling for a camera, combinations thereof, and so forth.
<br/><br/> Then, in step 520, the claimant receives a prompt on a device that the claimant has, or has ready access to.  The device that receives the prompt may be a hand-held device such as a cell phone, PDA, or smart phone, or the device can be some
other communication device such as a PC, and so forth, as described above.  As also previously noted, examples of the prompt include a text message, e-mail, an Instant Message, an audio recording, a video, or synthesized speech.  In some embodiments, the
prompt includes a warning that if the recipient of the prompt is not seeking authentication, then an unauthorized authentication attempt is in progress and to contact the Administrator.
<br/><br/> Next, in step 530, the claimant submits a biometric response to the prompt.  The claimant can submit the biometric response, according to various embodiments, by writing with a stylus on a touch-sensitive pad, placing a finger on a fingerprint
reader, placing one eye in proximity to an iris scanner, speaking within range of a microphone, speaking to a camera, combinations thereof, and so forth.
<br/><br/> In method 500 one of the two steps of receiving the prompt 520 and submitting the biometric response 530 is performed over a second channel.  For example, the claimant can submit the claimant target from a PC over a first channel in step 510,
and receive the prompt with a cell phone over a second channel in step 520.  Here, the claimant can provide the biometric response in step 530 over either the first channel or the second channel, in different embodiments.  In another example, the
claimant submits the claimant target from the PC over the first channel in step 510, the claimant receives the prompt on the PC again over the first channel (e.g., the prompt can be the following text message: "say your mother's maiden name"), the
claimant's cell phone rings, and in step 530 the claimant submits the biometric response over the cell phone, here the second channel.
<br/><br/> It will be appreciated that a method performed by an authentication system in this last example is a variant of the method 300 (FIG. 3) described above.  In this variant, rather than sending the prompt over the second channel to the device
associated with the device address in the step 340, a second channel is instead established to a device associated with the device address.  Subsequently, rather than receiving a biometric response to the prompt in the step 350 over an unspecified
channel, instead a biometric response to the prompt is specifically received over the second channel.
<br/><br/> Additional security features that can be incorporated are further described below.  For example, any of the electronic communications described herein can be encrypted according to well known encryption protocols.  As another example, a
watermark can be added to any biometric response sent to the authentication system.  For instance, a webcam comprising a camera and a microphone can be set with a key.  The key is transmitted to the user either through a secure channel or a separate
channel so that unauthorized users would not be aware of the key.  The watermark can be based at least in part on the key.  For instance, image data can be altered by discrete cosine transform (DCT) coefficients based on the key.  Of course, other
algorithms can be similarly employed.  Audio data can likewise be watermarked.  The key used for watermarking can also be the same key employed for encryption, in some embodiments.
<br/><br/> In the previous example, the key for the watermark can be transmitted to the claimant at the time of authentication for still further security.  For instance, the prompt received over the second channel can include the key (e.g., "Please enter
the following key to your webcam, wait for the red light, and then say your birth date.").  For still further security, the webcam (or any other device for recording a biometric response) can include a dedicated keypad for entering the key, where the
keypad is not otherwise connected to any computing system.  Here, there is no electronic way to intercept the key between the device that receives the key and the keypad of the webcam.  For still further security the possible keys would be non-repeating
so that a fraudulent authentication attempt can be determined by detecting the use of a previously used key.  Even additional security can be achieved by having keys expire within a period of time, such as 30 seconds, after being issued.
<br/><br/> In some embodiments, the biometric entry device (e.g., webcam, fingerprint reader, etc.) does not have a dedicated keypad to enter a key.  In some of these embodiments, the key can be entered through a shared keypad or keyboard.  For example, a
PC with an integrated webcam would allow the key to be entered on the PC's keyboard.  Here, the PC can include logic that when activated, connects the keyboard to the biometric entry device and simultaneously disconnects the keyboard from the computer
and disables the ability of other programs running on the PC to access key press notifications, thus rendering spyware ineffective.  In some of these embodiments, the logic can render an onscreen prompt to enter the key for the biometric entry device. 
For further security, the logic can echo keystrokes and codes as asterisks or other characters so as not to expose the actual keystrokes.
<br/><br/> In another embodiment, where a webcam or similar device acquires the biometric response, two video streams can be produced.  The first video stream is neither encrypted nor watermarked and is displayed on a screen for the benefit of the
claimant, while the second stream is encrypted and/or watermarked and sent to the authentication system.  Here, anyone observing the displayed first video stream would not be able to infer that the second video stream is watermarked and/or encrypted. 
Having the first video stream provides the claimant with the ability to center her image in the field of view of the camera.  Here, allowing the claimant to see her displayed image can potentially expose the image data to being captured with spyware.  To
avoid this, a further security feature comprises replacing the raw video image of the claimant with a placement indicator, such as an avatar.  In this way, the claimant can center herself in the field of view by watching a representation of the claimant
on the screen.
<br/><br/> A still further security feature is achieved through hybrid prompts.  A hybrid prompt is a prompt that the user selected during enrollment that is modified during authentication.  For instance, the user during enrollment selects the prompt "Say
your favorite movie." Subsequently, during authentication, the claimant receives the hybrid prompt "Say you favorite movie, then say spark plug." Here, the original prompt has been modified to also ask for random words or a random phrase.  Voice
recognition can then be employed to determine whether the words added to the original prompt were spoken in the biometric response.  If so, voice identification can be applied to the portion of the biometric response that includes the response to the
original prompt.  Furthermore, that portion of the biometric response that includes the added random words can be saved as further biometric templates from the user.
<br/><br/> FIG. 6 is a flow-chart representation of an exemplary method 600 for preventing a user from making certain misrepresentations in a social network.  The method 600 comprises the step 210 of method 200 (FIG. 2) and additionally comprises a step
610 of associating the user ID with a biometric template of a first user.  Step 610 can comprise the steps 230 and 240 of method 200, in some embodiments.  Method 600 also comprises a step 620 of providing a prompt to the first user and storing a
biometric response of the first user thereto in association with the user ID.  Step 620 can comprise the steps 340 and 350 of method 300 (FIG. 3), in some embodiments.  It will be appreciated that various embodiments of method 600 can include some or all
of the other steps of methods 200 and 300.  Each user of the social network that follows the steps 210, 610, and 620 provides the social network with a user ID associated with two biometric samples, one recorded as a template, the other provided in
response to a prompt, for example, while logging into the social network to access an account.  It will be understood that in some embodiments, only the biometric template or the biometric response needs to be associated with the user ID.
<br/><br/> Method 600 also comprises a step 630 of receiving a request from a second user of the social network to authenticate the first user of the social network.  Here, the second user may wish to verify certain representations made by the first user. 
For instance, the second user can request authentication of the first user to verify that the first user is not an imposter impersonating the person associated with a particular screen name.  In other instances, the second user can request authentication
of the first user to verify that representations made by the first user about age, gender, personal appearance, and so forth are legitimate.
<br/><br/> Method 600 also comprises a step 640 of sending to the second user at least a portion of the biometric response of the first user, or at least a portion of the biometric template of the first user.  In those embodiments in which only the
biometric template or the biometric response is associated with the user ID, step 640 reduces to sending at least a portion of whichever biometric sample was associated with the user ID.  It will be appreciated that for certain purposes either of the
biometric response or the biometric template may be more relevant.  For example, to verify that a user is not an imposter, the biometric response from the most recent login event would be more relevant than a biometric template recorded when the an
account was first established.  Steps 630 and 640 can be performed by the inter-user authentication logic 430 (FIG. 4) in some embodiments.
<br/><br/> FIG. 7 is a flow-chart representation of an exemplary method 700 for maintaining a social network.  The method 700 comprises a step 710 of enrolling users in the social network, a step 720 of certifying enrolled users, and a step 730 of
indicating to users of the social network which other users are certified.  Here, the step 710 of enrolling users includes storing in association with a user ID for each enrolled user a voice template, a facial recognition template, the user's gender,
and/or the user's age.  The step 720 of certifying enrolled users is performed by using the voice template or the facial recognition template to verify the gender and/or age of each certified enrolled user.
<br/><br/> Step 730 comprises indicating to users of the social network which other users are certified.  This can be achieved, for example, by a visual indicator associated with screen names or screen images of certified users.  For instance, a screen
names of certified users and/or their screen images (e.g., an image displayed in association with content and/or communications from a user) can be highlighted is various ways.  Alternatively, or in addition, an icon can be displayed in association with
certified users' screen names and/or screen images to indicate the certified status.
<br/><br/> An optional step 740 further comprises restricting some users to communicate only with certified users.  This can comprise, for example, restricting those users to communicate only with certified users that match a criterion like a gender or an
age or age range.  Step 740 can be implemented, for instance, in the context of parental controls so that a child is restricted to communicating with, and exchanging content with, only those other users that are certified to be children below a certain
age or within a specified range of ages.
<br/><br/> As noted previously with respect to methods 200 and 500, the present invention provides authentication of individuals without resort to a trusted individual to act on behalf of the organization, on-line community, social network, or the like. 
Instead, collection of biometric templates and biometric responses and the comparisons between them are performed by computing systems in these embodiments.  Thus, it will be understood that the absence of a trusted individual is not restricted to being
a feature of only embodiments of methods 200 and 500 but can also be a feature of embodiments of other methods described herein.
<br/><br/> While some prior art systems do not require a trusted individual, such systems are susceptible to being fooled.  A fingerprint recognition system, for example, can be fooled by a quality replica of a person's finger, or in the extreme case, by
the amputated finger itself.  Such a system merely verifies that a correct match was obtained but does not guarantee that the person being given access to an account (or to a secured space, or to a control system, for other examples) is truly the
authorized person.  Enrollment in a fingerprint recognition system, moreover, can be accomplished with an artificially generated fingerprint, for example, unless a trusted individual is present at the time of enrollment.  As noted above,
username/password login combinations can be guessed or stolen, so these also merely verify that a correct match was obtained, not that the person using the login combination is the authorized individual.  Similarly, voice samples and other biometric data
can be intercepted and replayed to defeat more sophisticated methods, so these also merely verify that a correct match was obtained, not that the person using the login combination is the authorized individual.  Additionally, without a trusted individual
present at enrollment, enrollment can be based on recording of other people's voices, and so forth.
<br/><br/> The present invention will be recognized, therefore, as providing automated user enrollment, without a trusted individual, that positively ties the enrolling user to an account or other form of record, though the enrolling user may or may not
still remain anonymous behind a fabricated screen name or other ID.  The present invention can also, in some embodiments, verify certain representations made by the enrolling user during the enrollment, again without the involvement of a trusted
individual.  The present invention also provides automated authentication upon login that the individual logging in is not an imposter, again without the involvement of a trusted individual.  The present invention can also provide biometric samples from
either or both of the enrollment and any login event of a first user to a second user to authenticate the first user to the second user.
<br/><br/> In the foregoing specification, the invention is described with reference to specific embodiments thereof, but those skilled in the art will recognize that the invention is not limited thereto.  Various features and aspects of the
above-described invention may be used individually or jointly.  Further, the invention can be utilized in any number of environments and applications beyond those described herein without departing from the broader spirit and scope of the specification. 
The specification and drawings are, accordingly, to be regarded as illustrative rather than restrictive.  It will be recognized that the terms "comprising," "including," and "having," as used herein, are specifically intended to be read as open-ended
terms of art.
<br/><br/><center><b>* * * * *</b></center>
<hr/>
   <center>
   <a href="http://pdfpiw.uspto.gov/.piw?Docid=09311466&amp;homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%2526r%3D833%2526f%3DG%2526l%3D50%2526d%3DPTXT%2526s1%3Dfacebook%2526p%3D17%2526OS%3Dfacebook%2526RS%3Dfacebook&amp;PageNum=&amp;Rtype=&amp;SectionNum=&amp;idkey=NONE&amp;Input=View+first+page"><img alt="[Image]" border="0" src="/netaicon/PTO/image.gif" valign="middle"/></a>
   <table>
   <tbody><tr><td align="center"><a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/ShowShoppingCart?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D833%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209311466"><img alt="[View Shopping Cart]" border="0" src="/netaicon/PTO/cart.gif" valign="middle"/></a>
   <a href="http://ebiz1.uspto.gov/vision-service/ShoppingCart_P/AddToShoppingCart?docNumber=9311466&amp;backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-adv.htm%26r%3D833%26f%3DG%26l%3D50%26d%3DPTXT%26s1%3Dfacebook%26p%3D17%26OS%3Dfacebook&amp;backLabel1=Back%20to%20Document%3A%209311466">
   <img alt="[Add to Shopping Cart]" border="0" src="/netaicon/PTO/order.gif" valign="middle"/></a>
   </td></tr>
   <tr><td align="center">
     <a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=833&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=16&amp;Query=facebook"><img alt="[PREV_LIST]" border="0" src="/netaicon/PTO/prevlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=833&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;Query=facebook"><img alt="[HIT_LIST]" border="0" src="/netaicon/PTO/hitlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=833&amp;f=S&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=18&amp;Query=facebook"><img alt="[NEXT_LIST]" border="0" src="/netaicon/PTO/nextlist.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=832&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[PREV_DOC]" border="0" src="/netaicon/PTO/prevdoc.gif" valign="MIDDLE"/></a>
<a href="/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&amp;r=834&amp;f=G&amp;l=50&amp;d=PTXT&amp;s1=facebook&amp;p=17&amp;OS=facebook"><img alt="[NEXT_DOC]" border="0" src="/netaicon/PTO/nextdoc.gif" valign="MIDDLE"/></a>

   <a href="#top"><img alt="[Top]" border="0" src="/netaicon/PTO/top.gif" valign="middle"/></a>
   </td></tr>
   </tbody></table>
   <a name="bottom"></a>
   <a href="/netahtml/PTO/index.html"><img alt="[Home]" border="0" src="/netaicon/PTO/home.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-bool.html"><img alt="[Boolean Search]" border="0" src="/netaicon/PTO/boolean.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/search-adv.htm"><img alt="[Manual Search]" border="0" src="/netaicon/PTO/manual.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/srchnum.htm"><img alt="[Number Search]" border="0" src="/netaicon/PTO/number.gif" valign="middle"/></a>
   <a href="/netahtml/PTO/help/help.htm"><img alt="[Help]" border="0" src="/netaicon/PTO/help.gif" valign="middle"/></a>
   </center>

</coma></body></html>